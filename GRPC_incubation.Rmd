---
title: "GRPC Incubation"
author: "Ian Hoppe"
date: "`r format( Sys.Date(), '%B %d, %Y' )`"
output:
  bookdown::html_document2:
    theme: lumen
    highlight: tango
    number_sections: FALSE
    toc: TRUE
    toc_float: TRUE
bibliography: [ refs.bib, pkgs.bib ]
link-citations: TRUE
csl: ecology.csl
---

```{r initializR, include = FALSE}

knitr::opts_chunk$set( "echo" = FALSE,
                       "message" = FALSE,
                       "warning" = FALSE )

```

```{r pkgR}

library( tidyverse )
library( lubridate )
library( SDMTools )
library( maptools )
library( mapdata )
library( leaflet )
library( raster )
library( rgeos )
library( rgdal )
library( ggmap )
library( MuMIn )       # AICc
library( broom )
library( maps )
library( grid )
library( lme4 )        # (g)lmer, etc.
library( MASS )
library( ggsn )        # scalebar and north
library( sp )

knitr::write_bib( x = c( "MASS", "SDMTools", "lme4", "MuMIn" ), 
                  file = "pkgs.bib" )

```

```{r functionR}

# calculates relative humidity (%) from temperature and dew point (in degrees Celsius)
get.rh <- function( .temp, .td ){
  rh <- 100 * ( exp( ( 17.625 * .td ) / ( 243.04 + .td ) ) / exp( ( 17.625 * .temp ) / ( 243.04 + .temp ) ) )
  return( rh )
}

# calculates saturation vapor pressure (in kPa) from temperature (in degrees Celsius)
# based on eq. 5.1 in Abtew and Melesse (2013)
get.es <- function( .temp ){
  es <- 0.611 * exp( ( 17.27 * .temp ) / ( .temp + 237.3 ) )
  return( es )
}

# calculates vapor pressure deficit (in kPa) from temperature (in degrees Celsius) and relative humidity (%)
# based on eq. 5.3 in Abtew and Melesse (2013)
get.vpd <- function( .temp, .rh ){
  es <- get.es( .temp )
  vpd <- es * ( 1 - ( .rh / 100 ) )
  return( vpd )
}

# adapts fortify.sp methods for SpatialLines objects (surely this was an oversight!)
fortify.SL <- function( model, data, ... ){
  plyr::ldply( model@lines, fortify )
}

# ccheck compiles modelwise diagnostics for convergence and failure of merMods.
ccheck <- function( .mm ){
  
  if( is.list( .mm ) ){
    
    fail <- sapply( .mm, function( .x ) !is.null( .x@optinfo$conv$lme4$messages ) )
    relgrad <- sapply( .mm, function( .x ) max( abs( with( .x@optinfo$derivs, solve( Hessian, gradient ) ) ) ) )
    gfail <- relgrad >= 0.001
    minT <- sapply( .mm, function( .x ) min( getME( .x, "theta" )[ getME( .x, "lower" ) == 0 ] ) )
    singular <- minT <= 0.000001
    
    results <- data.frame( mod = names( fail ), 
                           fail = fail, 
                           relgrad = relgrad, 
                           gfail = gfail, 
                           minT = minT, 
                           singular = singular)
    
  }else{
    
    fail <- !is.null( .mm@optinfo$conv$lme4$messages )
    relgrad <- max( abs( with( .mm@optinfo$derivs, solve( Hessian, gradient ) ) ) )
    gfail <-  relgrad >= 0.001
    minT <- min( getME( .mm, "theta" )[ getME( .mm, "lower" ) == 0 ] )
    singular <- minT <= 0.000001
    
    results <- data.frame( fail = fail, 
                           relgrad = relgrad, 
                           gfail = gfail, 
                           minT = minT, 
                           singular = singular )
    
  }
  
  return( results )
  
}

# convCheckR does ccheck better.
convCheckR <- function( .lmer ){
  
  if( is.list( .lmer ) ){
    
    nObs <- sapply( .lmer, function( .mm ) getME( .mm, "N" ) )
    names( nObs ) <- gsub( "\\.N$", "", names( nObs ) )
    nObs.true <- sapply( .lmer, function( .mm ) nrow( eval( .mm@call$data ) ) )
    nFE <- sapply( .lmer, function( .mm ) length( getME( .mm, "beta" ) ) )
    theta <- sapply( .lmer, function( .mm ) getME( .mm, "theta" ) )
    nRE <- sapply( theta, length )
    
    Warn_rescale <- sapply( .lmer, function( .mm ) any( grepl( "rescale", 
                                                               .mm@optinfo$conv$lme4$messages, 
                                                               ignore.case = TRUE ) ) )
    Warn_grad <- sapply( .lmer, function( .mm ) any( grepl( "grad", 
                                                            .mm@optinfo$conv$lme4$messages, 
                                                            ignore.case = TRUE ) ) )
    Warn_unID <- sapply( .lmer, function( .mm ) any( grepl( "unidentifiable", 
                                                            .mm@optinfo$conv$lme4$messages, 
                                                            ignore.case = TRUE ) ) )
    
    lowerBound <- sapply( .lmer, function( .mm ) getME( .mm, "lower" ) )
    singular <- map2_lgl( .x = theta, 
                          .y = lowerBound, 
                          .f = function( .tt, .ll ) min( .tt[ .ll == 0 ] ) < 1e-5 )
    
    derivs <- lapply( .lmer, function( .mm ) .mm@optinfo$derivs )
    sc.grad <- sapply( derivs, function( .dd ) with( .dd, solve( Hessian, gradient ) ) )
    max.abs.sc.grad <- sapply( sc.grad, function( .gg ) max( abs( .gg ) ) )
    large.abs.max.sc.grad <- max.abs.sc.grad > 0.001
    par.min.grad <- map2_dbl( .x = sc.grad, 
                              .y = derivs, 
                              .f = function( .sc, .dd ) max( pmin( abs( .sc ), abs( .dd$gradient ) ) ) )
    large.par.min.grad <- par.min.grad > 0.001
    
    diagnostic <- data.frame( nObs = nObs, 
                              nObs.true = nObs.true, 
                              nFE = nFE, 
                              nRE = nRE, 
                              singular = singular, 
                              MaxGrad = max.abs.sc.grad, 
                              LargeMaxGrad = large.abs.max.sc.grad, 
                              ParGrad = par.min.grad, 
                              LargeParGrad = large.par.min.grad, 
                              WarnGrad = Warn_grad, 
                              UnID = Warn_unID, 
                              Rescale = Warn_rescale )
    
  }else{
    
    nObs <- getME( .lmer, "N" )
    nObs.true <- nrow( eval( .lmer@call$data ) )
    nFE <- length( getME( .lmer, "beta" ) )
    theta <- getME( .lmer, "theta" )
    nRE <- length( theta )
    
    Warn_rescale <- any( grepl( "rescale", 
                                .lmer@optinfo$conv$lme4$messages, 
                                ignore.case = TRUE ) )
    Warn_grad <- any( grepl( "grad", 
                             .lmer@optinfo$conv$lme4$messages, 
                             ignore.case = TRUE ) )
    Warn_unID <- any( grepl( "unidentifiable", 
                             .lmer@optinfo$conv$lme4$messages, 
                             ignore.case = TRUE ) )
    
    lowerBound <- getME( .lmer, "lower" )
    singular <- min( theta[ lowerBound == 0 ] ) < 1e-5
    
    derivs <- .lmer@optinfo$derivs
    sc.grad <- with( derivs, solve( Hessian, gradient ) )
    max.abs.sc.grad <- max( abs( sc.grad ) )
    large.abs.max.sc.grad <- max.abs.sc.grad > 0.001
    par.min.grad <- max( pmin( abs( sc.grad ), abs( derivs$gradient ) ) )
    large.par.min.grad <- par.min.grad > 0.001
    
    diagnostic <- data.frame( nObs = nObs, 
                              nObs.true = nObs.true, 
                              nFE = nFE, 
                              nRE = nRE, 
                              singular = singular, 
                              MaxGrad = max.abs.sc.grad, 
                              LargeMaxGrad = large.abs.max.sc.grad, 
                              ParGrad = par.min.grad, 
                              LargeParGrad = large.par.min.grad, 
                              WarnGrad = Warn_grad, 
                              UnID = Warn_unID, 
                              Rescale = Warn_rescale )
    
  }
  
  return( diagnostic )
  
}

# fetch.RE returns the random-effects structure(s) from a merMod as a character vector
fetch.RE <- function( .mm, as.form = FALSE ){
  .rhs <- as.character( .mm@call$formula[[ 3 ]] )
  .fe <- .rhs[ 2 ]
  .re <- stringr::str_extract_all( .fe, "\\([\\w\\s\\.]+\\|[\\w\\s\\.]+\\)" )[[ 1 ]]
  .re <- c( .re, .rhs[ 3 ] )
  if( as.form ) .re <- paste( .re, collapse = " + " )
  return( .re )
}

# fetch.FE returns the fixed-effects component(s) from a merMod as a character vector
fetch.FE <- function( .mm ){
  .rhs <- as.character( .mm@call$formula[[ 3 ]] )
  .fe <- stringr::str_split_fixed( .rhs[ 2 ], "\\ \\+\\ \\([\\w\\s\\.]+\\|", n = 2 )[ 1 ]
  return( .fe )
}

# Calculate standardized [deviance] residuals for objects of class "merMod" produced by lme4::(g)lmer.
std.resid.glmer <- function( .glmer ){
  
  if( !any( c( isLMM( .glmer ), isGLMM( .glmer ) ) ) ){
    warning( "wrong class" )
  }else{
  
  dev.resid <- residuals( .glmer, type = "deviance" )
    
  # Calculate residual mean square of model variance (based on Table 5.5 [p. 68] of Zuur et al. 2007).
  ms <- sum( dev.resid^2 ) / df.residual( .glmer )
  
  # Calculate standardized residuals (based on eqn. of p. 65 in Zuur et al. 2007).
  std.resid <- dev.resid / sqrt( abs( ms * ( 1 - hatvalues( .glmer ) ) ) )
  
  return( std.resid )
  
  }
  
}

# Function to call from lme4::bootMer for making multiple predictions (to generate confidence limits).
boot.fitter <- function( .mm ){
  predict( .mm, newdata = nd, re.form = ~0 )
}

# Function to give a tidy data.frame with model estimates, including a column with the model name. Based on a fn of the same name by A J Tyre.
tidy_w_name <- function( .m, .n ){
  df <- tidy( .m )
  df$name <- .n
  df
}

# From stamod::qres.binom, adapted for .glmerMod objects
qres2 <- function( .glmm ){
  p <- fitted( .glmm )
  y <- .glmm@resp$y
  n <- .glmm@resp$n
  y <- n * y
  a <- pbinom( y - 1, n, p )
  b <- pbinom( y, n, p )
  u <- runif( n = length( y ), min = a, max = b )
  qnorm( u )
}

# Function to find the mode of a data vector. Picks the first in case of tie.
find.mode <- function( .dv ){
  uniq <- unique( .dv )
  uniq[ which.max( tabulate( match( .dv, uniq ) ) ) ]
}

```

```{r impoRt}

#### Load off-bout files. #####

# Identify all the individual nest files and give them fRiendly names.
hatchFiles <- sapply( X = list.files( path = "data/bouts/Hatch-Times" ),
                      FUN = function( .nn ) gsub( pattern = "\\w*\\s*-\\s*(\\w+)\\s*-\\s*(201[0-9]{1})\\.csv",
                                                  replacement = "hatch_\\1_\\2",
                                                  x = .nn ) )
failFiles <- sapply( X = list.files( path = "data/bouts/Fail-Times" ),
                     FUN = function( .nn ) gsub( pattern = "\\w*\\s*-\\s*(\\w+)\\s*-\\s*(201[0-9]{1})\\.csv",
                                                 replacement = "fail_\\1_\\2",
                                                 x = .nn ) )

# Read in the 'hatched' nest files.
hatches <- list()
for( i in 1:length( hatchFiles ) ){
  fl <- paste( "data/bouts/Hatch-Times/", names( hatchFiles[ i ] ), sep = "" )
  hatches[[ hatchFiles[[ i ]] ]] <- read.csv( fl, na.strings = "", stringsAsFactors = FALSE )
  names( hatches[[ hatchFiles[[ i ]] ]] ) <- gsub( pattern = "(\\w*)\\.(\\w*)[\\.s?\\.]*",
                                                   replacement = "\\1\\2",
                                                   x = names( hatches[[ hatchFiles[[ i ]] ]] ) )
  hatches[[ hatchFiles[[ i ]] ]]$fate_id_year <- hatchFiles[[ i ]]
}

# Read in the 'failed' nest files.
fails <- list()
for( i in 1:length( failFiles ) ){
  fl <- paste( "data/bouts/Fail-Times/", names( failFiles[ i ] ), sep = "" )
  fails[[ failFiles[[ i ]] ]] <- read.csv( fl, na.strings = "", stringsAsFactors = FALSE )
  names( fails[[ failFiles[[ i ]] ]] ) <- gsub( pattern = "(\\w*)\\.(\\w*)[\\.s?\\.]*",
                                                replacement = "\\1\\2",
                                                x = names( fails[[ failFiles[[ i ]] ]] ) )
  fails[[ failFiles[[ i ]] ]]$fate_id_year <- failFiles[[ i ]]
}

##### Initial processing of off-bout data. #####

# Make a master by-event data.frame. Remove 'warming' observations, focusing just on off-bouts.
bouts <- do.call( what = "rbind",
                  args = c( hatches, fails ) ) %>%
  separate( fate_id_year, c( "fate", "id", "year" ), sep = "_" ) %>%
  filter( Event == "Off-bout" ) %>%
  dplyr::select( -Event )

# Try to make things lubridate-fRiendly.
bouts$EventStart <- with( bouts, mdy_hm( paste( Date, EventStart ), tz = "America/Chicago" ) )

#### <DECISION> ####
# Accept the EventStart as the time of incubation initiation, but use 'Secs' as duration. Refresh EventEnd accordingly. (Second option goes with original EventEnd.)
# Range of differences between values (Secs - (EventEnd-EventStart)): -14494 s -- 850 s
bouts$EventEnd <- with( bouts, EventStart + duration( Secs, "seconds" ) )
# bouts$EventEnd <- with( bouts, mdy_hm( paste( Date, EventEnd ), tz = "America/Chicago" ) )
#### </DECISION> ####

bouts$Date <- with( bouts, mdy( Date, tz = "America/Chicago" ) )
bouts$EventDuration <- with( bouts, dseconds( EventStart %--% EventEnd ) )

# ## Negative durations actually occured over midnight. Correct the date and recalculate the duration.
# ## This bit became unnecessary when using the measured ('Secs') durations.
# inds <- which( bouts$EventDuration < as.duration( 0 ) )
# bouts$EventEnd[ inds ] <- bouts$EventEnd[ inds ] + days( 1 )
# bouts$EventDuration[ inds ] <- with( bouts, dseconds( EventStart[ inds ] %--% EventEnd[ inds ] ) )
#
# ## Do you have the same time that I have?
#
# # 200 observations differ by ± 1s, for a total of 12s (R calc. 12s > Excel calc.)
# bouts$secTest <- with( bouts, EndTime - BeginTime )
# bouts$secDiff <- with( bouts, secTest - Secs )
# length( bouts$secDiff[ which( bouts$secDiff != 0 ) ] ) # 200
# range( bouts$secDiff[ which( bouts$secDiff != 0 ) ] ) # -1 1
# sum( bouts$secDiff[ which( bouts$secDiff != 0 ) ] ) # 12
#
# # 910 observations differ by ± 0.6s, for a total of 2.8s (R calc. 12s > Excel calc.)
# bouts$minTest <- with( bouts, Secs / 60 )
# bouts$minDiff <- with( bouts, minTest - Mins )
# length( bouts$minDiff[ which( bouts$minDiff != 0 ) ] ) # 910
# range( bouts$minDiff[ which( bouts$minDiff != 0 ) ] ) * 60 # -0.6 0.6
# sum( bouts$minDiff[ which( bouts$minDiff != 0 ) ] ) * 60 # 2.8
#
# # 1543 observations differ by ± 18s, for a total of 626s (R calc. 626s < Excel calc.)
# bouts$hrTest <- with( bouts, Secs / 3600 )
# bouts$hrDiff <- with( bouts, hrTest - Hrs )
# length( bouts$hrDiff[ which( bouts$hrDiff != 0 ) ] ) # 1543
# range( bouts$hrDiff[ which( bouts$hrDiff != 0 ) ] ) * 3600 # -18 18
# sum( bouts$hrDiff[ which( bouts$hrDiff != 0 ) ] ) * 3600 # -626

# Remove those likely to be erroneously identified (i.e., those ≤ 10 minutes in duration [n = 13]).
bouts <- bouts %>%
  filter( EventDuration > duration( 10, "minutes" ) )

##### Construction of derived data.frames. #####

# Make a by-nest*day data.frame.
dayBouts <- bouts %>%
  group_by( id, Date ) %>%
  summarize( Secs = sum( Secs ),
             Mins = sum( Mins ),
             Hrs = sum( Hrs ),
             Bouts = n(),
             fate = unique( fate ) )

# Make a by-nest data.frame.
nests <- bouts %>%
  group_by( id ) %>%
  summarize( Mins = sum( Mins ),
             Bouts =  n(),
             MeanBouts = n() / length( unique( Date ) ),
             MeanMins_day = sum( Mins ) / length( unique( Date ) ), 
             MeanMins_bout = sum( Mins ) / Bouts, 
             startDate = min( Date ),
             finDate = max( Date ),
             fate = unique( fate ) )

##### Reading-in of ancillary data. #####

# Add geographic information to nest data. Create a categorical variable indicating whether or not a turbine exists within 1km of the nest.
nestPos <- read.csv( "data/NestDistance.csv", stringsAsFactors = FALSE )
nests <- inner_join( nestPos, nests, by = c( "Nest" = "id" ) ) %>% 
  mutate( Turbine_within_1km = as.factor( Turbine_Distance_m <= 1000 ) )

# Add vegetation information to nest data.
nestVeg <- read.csv( "data/NestVeg.csv", na.strings = "N/A", stringsAsFactors = FALSE ) %>% 
  mutate( EcologicalSite = gsub( pattern = "\\s", replacement = "", x = EcologicalSite ) )
nests <- inner_join( nestVeg, nests, by = c( "NestID" = "Nest" ) ) %>%
  rename( measDate = Date ) %>%
  mutate( measDate = mdy( measDate, tz = "America/Chicago" ) ) %>% 
  dplyr::select( c( 1:5, 12, 54, 60:75 ) )

vegKey <- data.frame( Term = c( "VOR", "VH", "LD", "PIE", "CS", "FORB", "SHR", "ANN", "CACT", "BG", "LIT", "SD", "PB", "WSB", "WSR", "WS" ),
                      Definition = c( "Visual obstruction reading",
                                      "Live vegetation height",
                                      "Litter depth",
                                      "Cow-pie",
                                      "Cool-season grasses",
                                      "Forbs",
                                      "Shrubs",
                                      "Annuals",
                                      "Cacti",
                                      "Bare ground",
                                      "Litter",
                                      "Standing dead vegetation",
                                      "Plant base",
                                      "Warm-season bunch grasses",
                                      "Warm-season rhizomatous grasses",
                                      "All warm-season grasses" ),
                      Unit = c( "dm", "cm", "cm", rep( "%", 13 ) ) )

# Add iButton and nest-fate information to the nest data. Calculate date of incubation initiation, if known (hatched nests).
nestFate <- read.csv( file = "data/NestFate.csv", na.strings = "N/A", stringsAsFactors = FALSE ) %>%
  mutate( Date_Nest_Found = mdy( Date_Nest_Found, tz = "America/Chicago" ),
          Date_iButton_Start = mdy( Date_iButton_Start, tz = "America/Chicago" ),
          Date_iButton_End = mdy( Date_iButton_End, tz = "America/Chicago" ),
          Date_Nest_End = mdy( Date_Nest_End, tz = "America/Chicago" ),
          NestFate_Uncertain = grepl( "\\?", paste( Nest_Success, Nest_Predated, Nest_Abandoned ) ),
          Nest_Success = ifelse( grepl( "Y", Nest_Success, ignore.case = TRUE ), 1, 0 ),
          Nest_Predated = ifelse( grepl( "Y", Nest_Predated, ignore.case = TRUE ), "Yes", ifelse( grepl( "N", Nest_Predated, ignore.case = TRUE ), "No" , "Unk" ) ),
          Nest_Abandoned = ifelse( grepl( "Y", Nest_Abandoned, ignore.case = TRUE ), "Yes", ifelse( grepl( "N", Nest_Abandoned, ignore.case = TRUE ), "No", "Unk" ) ) )
nests <- inner_join( nests, nestFate, by = c( "NestID", "UTM_E", "UTM_N", "measDate" = "Date_iButton_Start" ) ) %>%
  mutate( Date_Incubation_Initiated = Date_Nest_End - duration( 27, "days" ) )

# On one occasion (nest #1163A) an off-bout was recorded more than 28 days prior to the estimated hatching date. In that case, set the date of estimated incubation initiation back to the date of the earliest recorded off-bout for that nest.
nests$Date_Incubation_Initiated[ which( nests$Date_Incubation_Initiated > nests$startDate ) ] <- nests$startDate[ which( nests$Date_Incubation_Initiated > nests$startDate ) ]

# Also, the date of incubation initiation is not known for un-hatched nests.
nests$Date_Incubation_Initiated[ which( nests$Nest_Success != 1 ) ] <- NA

##### Nest-age calculations. #####

# Calculate nest age for each day of off-bout data for each nest, if available.
dayBouts$NestAge <- NA
for( i in 1:nrow( dayBouts ) ){
  nestId <- dayBouts$id[ i ]
  initDate <- with( nests, Date_Incubation_Initiated[ which( NestID == nestId ) ] )
  dayBouts$NestAge[ i ] <- with( dayBouts, as.numeric( Date[ i ] - initDate ) )
}

# Calculate nest age for each off-bout, if available.
bouts$NestAge <- NA
for( j in 1:nrow( bouts ) ){
  nestId <- bouts$id[ j ]
  initDate <- with( nests, Date_Incubation_Initiated[ which( NestID == nestId ) ] )
  bouts$NestAge[ j ] <- with( bouts, as.numeric( Date[ j ] - initDate ) )
}

##### Load iButton temperature data. #####

if( !exists( "iTemps" ) ){
  
  if( length( fl <- list.files( pattern = "iTemps.RData", recursive = TRUE ) ) > 0 ){
    load( fl )
  } else {
    
    # Read in iButton temperature data.
    iTemps <- read.csv( "data/iButton/Ainsworth_iButtonMaster.csv", stringsAsFactors = FALSE ) %>%
      mutate( DateTime = mdy_hms( DateTime, tz = "America/Chicago" ) )
    
    # Create a new column that will hold the incubation interval.
    iTemps$NestInterval <- ymd_hms( "1900-01-01 00:00:00", tz = "America/Chicago" ) %--% ymd_hms( "1900-01-01 00:00:01", tz = "America/Chicago" )
    for( nID in unique( iTemps$NestID ) ){
      nestInt <- with( filter( nests, NestID == nID ), measDate %--% Date_Nest_End )
      iTemps$NestInterval[ iTemps$NestID == nID ] <- nestInt
    }
    
    # Filter out temperature observations made outside the incubation window.
    iTemps <- iTemps %>%
      filter( DateTime %within% NestInterval )
    
    # Create a nest-by-nest list of data.frames specifying the off-bout intervals. Split it into a by-nest list of data.frames.
    offBouts <- bouts %>%
      mutate( offTimes = EventStart %--% EventEnd,
              boutNum = paste( id, seq_along( id ), sep = "_" ) ) %>%
      dplyr::select( id, boutNum, offTimes )
    offBouts <- split( x = offBouts,
                       f = offBouts$id )
    
    # Create a new column in the iTemp data.frame indicating whether or not the hen was on the nest at the time the measurement was made.
    iTemps$onNest <- NA
    for( o in 1:nrow( iTemps ) ){
      tempObs <- iTemps[ o, ]
      iTemps$onNest[ o ] <- !any( iTemps$DateTime[ o ] %within% offBouts[[ iTemps$NestID[ o ] ]]$offTimes )
      
    }
    save( iTemps, file = "data/iTemps.RData" )
  }
  
}

##### More ancillary data! #####

# Read in weather data.
weather <- read.csv( "data/AinsworthAmbientALL.csv", na.strings = " ", stringsAsFactors = FALSE ) %>%
  mutate( Date = mdy( Date, tz = "America/Chicago" ),
          Time = mdy_hm( paste( "01-01-2014", Time ), tz = "America/Chicago" ),
          DateTime = mdy_hm( DateTime, tz = "America/Chicago" ),
          DryBulbCelsius = as.numeric( DryBulbCelsius ), 
          DewPointCelsius = as.numeric( DewPointCelsius ), 
          RelativeHumidity = get.rh( DryBulbCelsius, DewPointCelsius ), 
          WindSpeed = as.numeric( WindSpeed ), 
          StationPressure = as.numeric( StationPressure ), 
          VPD = get.vpd( DryBulbCelsius, RelativeHumidity ) ) %>%
  arrange( DateTime )

# Using linear interpolation, estimate the approximate ambient temperature and vapor pressure deficit at the moment of off-bout initiation.
bouts$AmbientTemp <- NA
bouts$preBoutNestTemp <- NA
bouts$VPD <- NA
bouts$WindSpeed <- NA
bouts$Pressure <- NA
for( b in 1:nrow( bouts ) ){
  
  # Extract the start time of the off-bout.
  boutStart <- bouts$EventStart[ b ]
  
  # Isolate the weather data from the same year and pull out the two weather records closest in time to the start of the off-bout.
  boutWeather <- weather %>% 
    dplyr::select( DateTime, DryBulbCelsius, WindSpeed, StationPressure, VPD ) %>% 
    filter( year( DateTime ) == year( boutStart ) ) %>%
    arrange( abs( DateTime - boutStart ) )
  boutWeather <- boutWeather[ 1:2, ]
  
  # Interpolate the ambient temperature and VPD based on the two nearest weather records. If the two nearest records are to one side (temporally) of the off-bout initiation time, the ambient temperature and VPD are taken to be the recorded temperature and calculated VPD at the time nearest the start time (rule=2).
  bouts$AmbientTemp[ b ] <- approx( x = boutWeather$DateTime,
                                    y = boutWeather$DryBulbCelsius,
                                    xout = boutStart, 
                                    rule = 2 )$y
  
  bouts$VPD[ b ] <- approx( x = boutWeather$DateTime, 
                            y = boutWeather$VPD, 
                            xout = boutStart, 
                            rule = 2 )$y
  
  bouts$WindSpeed[ b ] <- approx( x = boutWeather$DateTime, 
                                  y = boutWeather$WindSpeed, 
                                  xout = boutStart, 
                                  rule = 2 )$y
  
  # # Too many NAs.
  # bouts$Pressure[ b ] <- approx( x = boutWeather$DateTime, 
  #                                y = boutWeather$StationPressure, 
  #                                xout = boutStart, 
  #                                rule = 2 )$y
  
  # Isolate nest temperature data from the nest on the day of the off-bout.
  nestWeather <- iTemps %>% 
    dplyr::select( DateTime, Temperature, NestID ) %>% 
    filter( NestID == bouts$id[ b ], 
            year( DateTime ) == year( boutStart ), 
            yday( DateTime ) == yday( boutStart ), 
            DateTime < boutStart ) %>% 
    arrange( boutStart - DateTime )
  
  # Take the pre-off-bout nest temperature to be the last recorded temperature before the start of the off-bout.
  bouts$preBoutNestTemp[ b ] <- nestWeather$Temperature[ 1 ]
  
}

# Calculate the signed difference between the pre-off-bout nest temperature and the ambient temperature at the time of off-bout initiation.
bouts$TempDiff <- with( bouts, preBoutNestTemp - AmbientTemp )

##### Master data.frame. #####

# Make a data.frame containing both nest-specific and event-specific information. Nest-specific data are repeated!!!
fullBouts <- left_join( x = bouts, 
                        y = nests, 
                        by = c( "id" = "NestID", "fate" = "fate" ) ) %>% 
  rename( Mins = Mins.x, 
          TotalMinsOff = Mins.y ) %>% 
  mutate( fID = factor( id ), 
          Jday = yday( EventStart ), 
          EventStart_dl = EventStart, 
          EventStart_yl = EventStart, 
          fYear = factor( year ) )

# Adding dateless and yearless columns for the time data should make things simpler (I hope).
year( fullBouts$EventStart_dl ) <- year( fullBouts$EventStart_yl ) <- 2014
yday( fullBouts$EventStart_dl ) <- 1

```

```{r astRonomy}

# Read in 2013 sunrise/sunset times for Ainsworth (from USNO, Astronomical Applications Department, Washington, D.C., USA; accessed 20 Dec 2016)
sun2013 <- read.table( file = "data/astronomy/sun2013.txt", header = TRUE, sep = "" ) %>%
  gather( key = Month_Sun,
          value = Time,
          -Dy, na.rm = TRUE ) %>%
  separate( col = Month_Sun,
            into = c( "Month", "Sun" ),
            sep = "_" ) %>%
  spread( key = Sun,
          value = Time )

# Read in 2013 civil twilight times for Ainsworth (from USNO, Astronomical Applications Department, Washington, D.C., USA; accessed 20 Dec 2016)
twi2013 <- read.table( file = "data/astronomy/twilight2013.txt", header = TRUE, sep = "" ) %>%
  gather( key = Month_Sun,
          value = Time,
          -Dy, na.rm = TRUE ) %>%
  separate( col = Month_Sun,
            into = c( "Month", "Sun" ),
            sep = "_" ) %>%
  spread( key = Sun,
          value = Time )

# Combine 2013 astronomical data.
sun2013 <- inner_join( x = sun2013,
                       y = twi2013,
                       by = c( "Month", "Dy" ) )
sun2013$Year <- 2013
sun2013 <- sun2013[ , c( 7, 2, 1, 3:6 ) ]
names( sun2013 )[ 3:7 ] <- c( "Day", "Sunrise", "Sunset", "TwilightBegin", "TwilightEnd" )

# Read in 2014 sunrise/sunset times for Ainsworth (from USNO, Astronomical Applications Department, Washington, D.C., USA; accessed 20 Dec 2016)
sun2014 <- read.table( file = "data/astronomy/sun2014.txt", header = TRUE, sep = "" ) %>%
  gather( key = Month_Sun,
          value = Time,
          -Dy, na.rm = TRUE ) %>%
  separate( col = Month_Sun,
            into = c( "Month", "Sun" ),
            sep = "_" ) %>%
  spread( key = Sun,
          value = Time )

# Read in 2014 civil twilight times for Ainsworth (from USNO, Astronomical Applications Department, Washington, D.C., USA; accessed 20 Dec 2016)
twi2014 <- read.table( file = "data/astronomy/twilight2014.txt", header = TRUE, sep = "" ) %>%
  gather( key = Month_Sun,
          value = Time,
          -Dy, na.rm = TRUE ) %>%
  separate( col = Month_Sun,
            into = c( "Month", "Sun" ),
            sep = "_" ) %>%
  spread( key = Sun,
          value = Time )

# Combine 2014 astronomical data.
sun2014 <- inner_join( x = sun2014,
                       y = twi2014,
                       by = c( "Month", "Dy" ) )
sun2014$Year <- 2014
sun2014 <- sun2014[ , c( 7, 2, 1, 3:6 ) ]
names( sun2014 )[ 3:7 ] <- c( "Day", "Sunrise", "Sunset", "TwilightBegin", "TwilightEnd" )

# Compile all (2013+2014) astronomical data.
sun <- bind_rows( sun2013, sun2014 )
sun$Month <- as.integer( gsub( "X", "", sun$Month ) )
sun$Sunrise <- gsub( pattern = "([1-9]{1})([0-9]{2})",
                     replacement = "\\1:\\2",
                     x = sun$Sunrise )
sun$Sunset <- gsub( pattern = "([0-9]{2})([0-9]{2})",
                    replacement = "\\1:\\2",
                    x = sun$Sunset )
sun$TwilightBegin <- gsub( pattern = "([1-9]{1})([0-9]{2})",
                           replacement = "\\1:\\2",
                           x = sun$TwilightBegin )
sun$TwilightEnd <- gsub( pattern = "([0-9]{2})([0-9]{2})",
                         replacement = "\\1:\\2",
                         x = sun$TwilightEnd )

# Teach R to recognize the dates and times.
sun$Date <- with( sun, ymd( paste( Year, Month, Day, sep = "-" ), tz = "America/Chicago" ) )
sun <- sun[ order( year( sun$Date ), yday( sun$Date ) ), c( 8, 4:7 ) ]
row.names( sun ) <- NULL

sun$Sunrise <- with( sun, ymd_hm( paste( ymd( Date ), Sunrise, sep = " " ), tz = "America/Chicago" ) )
sun$Sunset <- with( sun, ymd_hm( paste( ymd( Date ), Sunset, sep = " " ), tz = "America/Chicago" ) )
sun$TwilightBegin <- with( sun, ymd_hm( paste( ymd( Date ), sun$TwilightBegin, sep = " " ), tz = "America/Chicago" ) )
sun$TwilightEnd <- with( sun, ymd_hm( paste( ymd( Date ), TwilightEnd, sep = " " ), tz = "America/Chicago" ) )

# Make correction for Daylight Saving Time (not done in the original USNO data.)
dstInts <- data.frame( dst2013 = ymd( "2013-03-10", tz = "America/Chicago" ) %--% ymd( "2013-11-03", tz = "America/Chicago" ),
                       dst2014 = ymd( "2014-03-09", tz = "America/Chicago" ) %--% ymd( "2014-11-02", tz = "America/Chicago" ) )
sun$DSTcorrection <- with( sun,
                           ifelse( Date %within% dstInts$dst2013 | Date %within% dstInts$dst2014, 1, 0 ) )
sun$DSTcorrection <- hours( sun$DSTcorrection )

sun$Sunrise <- sun$Sunrise + sun$DSTcorrection
sun$Sunset <- sun$Sunset + sun$DSTcorrection
sun$TwilightBegin <- sun$TwilightBegin + sun$DSTcorrection
sun$TwilightEnd <- sun$TwilightEnd + sun$DSTcorrection

sun <- dplyr::select( sun, -DSTcorrection )

# Set all time columns to same date for ease of handling.
year( sun$Sunrise ) <- 2014
year( sun$Sunset ) <- 2014
year( sun$TwilightBegin ) <- 2014
year( sun$TwilightEnd ) <- 2014
yday( sun$Sunrise ) <- 1
yday( sun$Sunset ) <- 1
yday( sun$TwilightBegin ) <- 1
yday( sun$TwilightEnd ) <- 1

# Make a list of all the unique dates on which off-bouts occurred.
dates2013 <- unique( bouts$Date )[ which( year( unique( bouts$Date ) ) == 2013 ) ]
dates2014 <- unique( bouts$Date )[ which( year( unique( bouts$Date ) ) == 2014 ) ]

# Calculate the overall (2013 & 2014) mean sunrise/sunset and twilight beginning and ending times across all dates on which off-bouts occurred. Mirror the twilight times around the sunrise/sunset.
astro <- sun %>%
  filter( Date %in% c( dates2013, dates2014 ) ) %>%
  summarize( Sunrise = mean( Sunrise ),
             Sunset = mean( Sunset ),
             TwilightBegin = mean( TwilightBegin ),
             TwilightEnd = mean( TwilightEnd ) ) %>%
  rename( DawnBegin = TwilightBegin,
          DuskEnd = TwilightEnd ) %>%
  mutate( DawnEnd = Sunrise + ( Sunrise - DawnBegin ),
          DuskBegin = Sunset - ( DuskEnd - Sunset ) ) %>%
  dplyr::select( 3, 1, 5:6, 2, 4 )

# Interestingly, the attributes (class and tzone) become mixed up during the final mutate. This led to problems in the creation of twiPoly.
attributes( astro$DawnEnd ) <- attributes( astro$DawnBegin )
attributes( astro$DuskBegin ) <- attributes( astro$DuskEnd )

# Construct a data.frame with vertices for a polygon to denote twilight times in a freq(bout.initiation) ~ time.of.day histogram.
dawnPoly <- astro %>%
  dplyr::select( contains( "Dawn" ) ) %>%
  gather( key = Event,
          value = Time,
          everything() )
dawnPoly <- dawnPoly %>%
  bind_rows( dawnPoly[ 2:1, ] ) %>%
  bind_cols( data.frame( Y = c( 0, 0, Inf, Inf ) ) ) %>%
  mutate( Event = "Dawn" )

duskPoly <- astro %>%
  dplyr::select( contains( "Dusk" ) ) %>%
  gather( key = Event,
          value = Time,
          everything() )
duskPoly <- duskPoly %>%
  bind_rows( duskPoly[ c( 2, 1 ), ] ) %>%
  bind_cols( data.frame( Y = c( 0, 0, Inf, Inf ) ) ) %>%
  mutate( Event = "Dusk" )

twiPoly <- bind_rows( dawnPoly, duskPoly )

# xintercepts for the sunrise/sunset lines of the same histogram.
sunLine <- astro %>%
  dplyr::select( contains( "Sun" ) ) %>%
  gather( key = Event,
          value = Time,
          everything() )

```

```{r weatheR}

# Join weather and astronomical data, make indicator variables denoting whether weather recordings are made during daylight and twilight hours.
weatherSun <- weather %>%
  filter( Date %in% c( dates2013, dates2014 ) ) %>%
  inner_join( sun, by = "Date" ) %>%
  group_by( Date ) %>%
  mutate( Daylight = Time %within% ( Sunrise %--% Sunset ),
          Twilight = Time %within% ( TwilightBegin %--% TwilightEnd ) )

# Summarize temperature by month.
monthTemps <- weatherSun %>%
  ungroup() %>%
  group_by( Month, Day ) %>%
  summarize( HighTemp = max( DryBulbCelsius, na.rm = TRUE ),
             LowTemp = min( DryBulbCelsius, na.rm = TRUE ) ) %>%
  ungroup() %>%
  group_by( Month ) %>%
  summarize( Avg_HighTemp = mean( HighTemp ),
             Low_HighTemp = min( HighTemp ),
             High_HighTemp = max( HighTemp ),
             Avg_LowTemp = mean( LowTemp ),
             Low_LowTemp = min( LowTemp ),
             High_LowTemp = max( LowTemp ) )

```

```{r fReqExploR, eval = FALSE, include = FALSE}

incRange <- ggplot( data = nests, 
                    aes( x = yday( measDate ), 
                         xend = yday( Date_Nest_End ), 
                         y = NestID, 
                         yend = NestID, 
                         colour = as.factor( Nest_Success ) ) ) +
  geom_segment( size = 4 ) + 
  labs( x = "Ordinal date", 
        colour = "Nest fate" ) + 
  scale_colour_discrete( labels = c( "0" = "Fail", 
                                     "1" = "Hatch" ) ) + 
  theme_classic()

```

```{r fReqManipulatoR}

# Define the size of the timeblocks.
blockSize <- duration( .b <- 3, "hours" )

timeRounder <- function( .POSIX, .blkSz = 3, .ud = c( "floor", "ceiling" ) ){
  .hvec <- seq( 6 - ( .blkSz / 2 ), 0, by = -.blkSz )
  .hvec <- seq( .hvec[ length( .hvec ) ], 24, by = .blkSz )
  .m <- minute( .POSIX ) / 60
  .h <- hour( .POSIX ) + .m
  .btw <- rep( .hvec[ abs( .hvec - .h ) < .blkSz ], length = 2 )
  .ud <- match.arg( .ud, c( "floor", "ceiling" ) )
  .h <- switch( .ud, 
                "floor" = .btw[ 1 ], 
                "ceiling" = .btw[ 2 ] )
  hour( .POSIX ) <- .fh <- floor( .h )
  .m <- ( .h - .fh ) * 60
  minute( .POSIX ) <- .m
  second( .POSIX ) <- 0
  .POSIX
}

# Extract the earliest and latest recorded off-bout initiation times for each nest. Create a sequence of timeblocks for each nest from 01:30:00 on the date of the first recorded off-bout through 01:29:59 on the day after the last recorded off-bout.

freqData <- plyr::ddply( .data = fullBouts, 
                         .variables = "id", 
                         .fun = function( .df ){
                           
                           .id <- unique( .df$id )                       # for each nest,
                           
                           .start <- filter( nests, NestID == .id )      # record starts on date of first iButton off-bout record
                           # .start <- parse_date_time( x = paste( .start$measDate, .start$Time ), 
                           #                            order = c( "%Y-%m-%d %H:%M", "%Y-%m-%d %H:%M:%S" ), 
                           #                            tz = "America/Chicago" )
                           .start <- timeRounder( min( .df$EventStart ), .b, "floor" )
                           .end <- timeRounder( max( .df$EventStart ), .b, "ceiling" )                # and ends on the date after the last record
                           .starts <- seq( from = .start, 
                                           to = .end, 
                                           by = blockSize )
                           .ends <- .starts + ( blockSize - duration( 1, "second" ) )
                           .ints <- .starts %--% .ends
                           
                           inds <- lapply( X = .ints,                    # index the respective off-bout observations
                                           FUN = function( .i ) which( .df$EventStart %within% .i ) )
                           numBouts <- sapply( inds, length )            # the number of off-bouts during the block is the length of the index vector
                           
                           .dur <- sapply( inds, function( .nn ) mean( .df$Mins[ .nn ] ) ) # grab the (mean) duration of any bout(s) that occurred
                           .dur[ is.nan( .dur ) ] <- NA
                           
                           nTemps <- iTemps %>%
                             filter( NestID == .id,
                                     onNest )
                           iInds <- lapply( X = .ints,
                                            FUN = function( .i ) which( nTemps$DateTime %within% .i ) )
                           .nestTemp <- sapply( iInds, function( .nn ) mean( nTemps$Temperature[ .nn ] ) )
                           
                           # Collect weather and sun data.
                           wsInds <- lapply( X = .ints, 
                                             FUN = function( .i ) which( weatherSun$DateTime %within% .i ) )
                           .temp <- sapply( X = wsInds, FUN = function( .i ) mean( weatherSun$DryBulbCelsius[ .i ], na.rm = TRUE ) )
                           .windspeed <- sapply( X = wsInds, FUN = function( .i ) mean( weatherSun$WindSpeed[ .i ], na.rm = TRUE ) )
                           .pressure <- sapply( X = wsInds, FUN = function( .i ) mean( weatherSun$StationPressure[ .i ], na.rm = TRUE ) )
                           .precip <- sapply( X = wsInds, FUN = function( .i ) mean( weatherSun$HourlyPrecip[ .i ], na.rm = TRUE ) )
                           .vpd <- sapply( X = wsInds, FUN = function( .i ) mean( weatherSun$VPD[ .i ], na.rm = TRUE ) )
                           
                           .precip[ is.nan( .precip ) ] <- 0
                           
                           data.frame( blockStart = .starts, 
                                       blockEnd = .ends, 
                                       numBouts = numBouts, 
                                       Mins = .dur, 
                                       AmbientTemp = .temp, 
                                       NestTemp = .nestTemp,
                                       TempDiff = .nestTemp - .temp,
                                       WindSpeed = .windspeed, 
                                       AirPressure = .pressure, 
                                       Precipitation = .precip, 
                                       VPD = .vpd ) } ) %>% 
  mutate( blockID = as.factor( hour( blockStart ) ), 
          fID = as.factor( id ), 
          fYear = as.factor( year( blockStart ) ), 
          Jday = yday( blockStart ), 
          Date = ymd( date( blockStart ), tz = "America/Chicago" ) ) %>% 
  left_join( y = dplyr::select( nests, 
                                NestID, contains( "Distance", ignore.case = TRUE ), Nest_Success, Nest_Predated, VOR_AVG, Date_Incubation_Initiated ), 
             by = c( "id" = "NestID" ) ) %>% 
  mutate( NestAge = as.numeric( difftime( Date, Date_Incubation_Initiated, units = "days" ) ) )

```

```{r tRends, eval = FALSE, include = FALSE}

######### Explore the data, looking for potential trends. #########

####### Bout duration vs. distance-to-XXX. #######

##### TURBINES #####
# By individual bout. Certainly a decrease in spread with distance, and a fitted-line decline, but hard to tell without the smoothed line.
allBouts.tb <- ggplot( arrange( fullBouts, Turbine_Distance_m ), 
                       aes( x = Turbine_Distance_m, 
                            y = Mins ) ) + 
  geom_point( alpha = 0.4 ) + 
  geom_smooth( colour = "grey24" ) +
  theme_classic() + 
  labs( x = "Distance to nearest wind turbine (m)", 
        y = "Off-bout duration (min)" )

# By average bout duration / nest. Decline in duration with distance is more evident; but many fewer datapoints.
meanBouts.tb <- ggplot( arrange( nests, Turbine_Distance_m ), 
                        aes( x = Turbine_Distance_m, 
                             y = MeanMins_bout ) ) + 
  geom_point( alpha = 0.4 ) + 
  #geom_smooth( colour = "grey24" ) + 
  theme_classic() + 
  labs( x = "Distance to nearest wind turbine (m)", 
        y = "Mean off-bout duration (min)" )

##### ROADS #####
# By individual bout. Fairly flat---with an ever-so-slight increase in duration with distance.
allBouts.rd <- ggplot( arrange( fullBouts, Roads_Distance_m ), 
                       aes( x = Roads_Distance_m, 
                            y = Mins ) ) + 
  geom_point( alpha = 0.4 ) + 
  geom_smooth( colour = "grey24" ) +
  theme_classic() + 
  labs( x = "Distance to nearest road (m)", 
        y = "Off-bout duration (min)" )

# By average bout duration / nest. Noise. Meh.
meanBouts.rd <- ggplot( arrange( nests, Roads_Distance_m ), 
                        aes( x = Roads_Distance_m, 
                             y = MeanMins_bout ) ) + 
  geom_point( alpha = 0.4 ) + 
  geom_smooth( colour = "grey24" ) +
  theme_classic() + 
  labs( x = "Distance to nearest road (m)", 
        y = "Mean off-bout duration (min)" )

##### WATER #####
# By individual bout. Similar to roads, with a bump--in the road.
allBouts.h2o <- ggplot( arrange( fullBouts, Water_Distance_m ), 
                        aes( x = Water_Distance_m, 
                             y = Mins ) ) + 
  geom_point( alpha = 0.4 ) + 
  geom_smooth( colour = "grey24" ) +
  theme_classic() + 
  labs( x = "Distance to nearest water source (m)", 
        y = "Off-bout duration (min)" )

# By average bout duration / nest.
meanBouts.h2o <- ggplot( arrange( nests, Water_Distance_m ), 
                     aes( x = Water_Distance_m, 
                          y = MeanMins_bout ) ) + 
  geom_point( alpha = 0.4 ) + 
  geom_smooth( colour = "grey24" ) +
  theme_classic() + 
  labs( x = "Distance to nearest water source (m)", 
        y = "Mean off-bout duration (min)" )

##### TREES #####
# By individual bout.
allBouts.tr <- ggplot( arrange( fullBouts, Water_Distance_m ), 
                       aes( x = Water_Distance_m, 
                            y = Mins ) ) + 
  geom_point( alpha = 0.4 ) + 
  geom_smooth( colour = "grey24" ) +
  theme_classic() + 
  labs( x = "Distance to nearest tree (m)", 
        y = "Off-bout duration (min)" )

# By average bout duration / nest.
meanBouts.tr <- ggplot( arrange( nests, Water_Distance_m ), 
                        aes( x = Water_Distance_m, 
                             y = MeanMins_bout ) ) + 
  geom_point( alpha = 0.4 ) + 
  #geom_smooth( colour = "grey24" ) + 
  theme_classic() + 
  labs( x = "Distance to nearest tree (m)", 
        y = "Mean off-bout duration (min)" )

####### Bout duration vs. weather. #######

##### TEMPERATURE DIFFERENCE #####
tdiff <- ggplot( arrange( fullBouts, TempDiff ), 
                 aes( x = TempDiff, 
                      y = Mins ) ) + 
  geom_point( alpha = 0.4 ) + 
  geom_smooth( method = "lm", 
               se = FALSE, 
               aes( group = id, 
                    colour = id ) ) +
  theme_classic() + 
  labs( x = "Temperature difference (°C)", 
        y = "Off-bout duration (min)" )

##### WIND SPEED #####
windspeed <- ggplot( arrange( fullBouts, WindSpeed ), 
                     aes( x = WindSpeed, 
                          y = Mins ) ) + 
  geom_point( alpha = 0.4 ) + 
  geom_smooth( method = "lm", 
               se = FALSE, 
               aes( group = id, 
                    colour = id ) ) +
  theme_classic() + 
  labs( x = "Wind speed (mph)", 
        y = "Off-bout duration (min)" )

####### Bout duration vs. time. #######

##### ORDINAL DATE #####
oday <- ggplot( arrange( fullBouts, Jday ), 
                aes( x = Jday, 
                     y = Mins ) ) + 
  geom_smooth( method = "lm", 
               se = FALSE, 
               aes( group = id, 
                    colour = id ) ) + 
  geom_point( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Ordinal date", 
        y = "Off-bout duration (min)" )

##### TIME OF DAY #####
tday <- ggplot( arrange( fullBouts, EventStart_dl ), 
                aes( x = EventStart_dl, 
                     y = Mins ) ) + 
  geom_point( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Time", 
        y = "Off-bout duration (min)" ) + 
  facet_wrap( ~id )

##### NEST AGE #####
nage <- ggplot( arrange( fullBouts, NestAge ), 
                aes( x = NestAge, 
                     y = Mins ) ) + 
  geom_point( alpha = 0.4 ) + 
  theme_classic() + 
  geom_smooth( method = "lm", 
               se = FALSE, 
               aes( group = id, 
                    colour = id ) ) + 
  geom_smooth( method = "lm" ) + 
  labs( x = "Nest age (d)", 
        y = "Off-bout duration (min)" )

####### Bout duration vs. hen incubation habits. #######
tmo <- ggplot( arrange( fullBouts, MeanBouts ), 
               aes( x = MeanBouts, 
                    y = Mins ) ) + 
  geom_point( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Mean number of bouts taken per day of incubation", 
        y = "Off-bout duration (min)" )

####### End Explore. #######

```

###**ABSTRACT** {#abstract}

###**KEY WORDS** {#keywords}

###**INTRODUCTION** {#intro}

```{r INTROnotes, eval = FALSE, include = FALSE}
# --clear, referenced, logical progression to primary objectives

# --concise synthesis of current and historical literature specific to the main topic
# ----justify why the research was necessary and conducted

# --clear and succinct statement of objectives and hypotheses

#### INCLUDE

# --rel. low rainfall and rapid infiltration (sandy soils) make for a dry landscape [NE Nat Leg Plan]-->water stress
```

###**STUDY AREA** {#studyarea}

```{r mapR}

# Define the target projection.
targProj <- "+init=epsg:4326 +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"

ainsworth <- SpatialPoints( coords = data.frame( long = -99.858233, lat = 42.547944 ), 
                            proj4string = CRS( targProj ) )

##### Import Spatial Layers. #####

# Create a SpatialPointsDataFrame with the nest data.
nestLocs <- nests[ , c( "UTM_E", "UTM_N" ) ]
nestsSPDF <- spTransform( SpatialPointsDataFrame( coords = nestLocs,
                                                  data = nests,
                                                  proj4string = CRS( "+init=epsg:32610 +proj=utm +zone=14 +datumWGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0" ) ), 
                          targProj )

### Read in the landscape shapefiles.
# Turbines
turbines.shp <- spTransform( readOGR( dsn = "data/distribution/Landscape", 
                                      layer = "wind_turbines" ), 
                             targProj )
# # Water
# water.shp <- spTransform( readOGR( dsn = "data/distribution/Landscape", 
#                                   layer = "Water" ), 
#                          targProj )
# # Major roads
# roads_major.shp <- spTransform( readOGR( dsn = "data/distribution/Landscape", 
#                                          layer = "major_rds" ), 
#                                 targProj )
# # Roads
# roads_minor.shp <- spTransform( readOGR( dsn = "data/distribution/Landscape", 
#                                          layer = "Roads" ), 
#                                 targProj )
# # Trees
# trees.shp <- spTransform( readOGR( dsn = "data/distribution/Landscape", 
#                                    layer = "Trees" ), 
#                           targProj )

# Import the GRPC range .dbf (cropped and converted to a shapefile in ArcGIS on a separate machine by Weldon Hoppe) (original from USGS Gap Analysis Program).
GRPC_range <- spTransform( readOGR( dsn = "data/distribution/GRPC_range/GPC_Range_NE", 
                                    layer = "GPC_Range_NE" ), 
                           targProj )


##### Import Spatial Areas. #####

### Grab map data for country, state, and county maps.

# Country
usa <- map_data( "state" )
USbox <- with( usa, 
               data.frame( xmin = floor( min( long ) ), 
                           xmax = ceiling( max( long ) ), 
                           ymin = floor( min( lat ) ), 
                           ymax = ceiling( max( lat ) ) ) )

# State
nebraska <- map_data( "county", "nebraska" )
NE_poly <- SpatialPolygons( Srl = list( NE_outline = Polygons( srl = list( Polygon( coords = filter( usa, region == "nebraska" )[ , c( "long", "lat" ) ], 
                                                                                    hole = FALSE ) ), 
                                                               ID = "NE_outline" ) ), 
                            proj4string = CRS( targProj ) )

# County
brownCo <- nebraska %>%
  filter( subregion == "brown" )
brown_poly <- SpatialPolygons( Srl = list( brown_outline = Polygons( srl = list( Polygon( coords = brownCo[ , c( "long", "lat" ) ], 
                                                                                          hole = FALSE ) ), 
                                                                     ID = "brown_outline" ) ), 
                               proj4string = CRS( targProj ) )

##### Spatial Data Manipulation. #####

# Prepare the range and landscape data for plotting with ggplot2 and find the intersection between each layer and the relevant spatial extent.
GRPC_range.dfc <- fortify( gIntersection( spgeom1 = GRPC_range, spgeom2 = NE_poly ) )

# water.shp@data$id <- rownames( water.shp@data )
# water.dfc <- fortify( gIntersection( spgeom1 = water.shp, spgeom2 = brown_poly ) ) %>% 
#   mutate( type = "water" )
# water.dfcsa <- fortify( crop( x = water.shp, y = nestsSPDF ), region = "id" ) %>% 
#   mutate( type = "water" )
# trees.shp@data$id <- rownames( trees.shp@data )
# trees.dfc <- fortify( gIntersection( spgeom1 = trees.shp, spgeom2 = brown_poly ) ) %>% 
#   mutate( type = "trees" )
# trees.dfcsa <- fortify( crop( x = trees.shp, y = nestsSPDF ), region = "id" ) %>% 
#   mutate( type = "trees" )
# 
# # Create a master landcover data.frame, and one cropped to include just the study area.
# cover.dfc <- bind_rows( water.dfc, trees.dfc )
# cover.dfcsa <- bind_rows( water.dfcsa, trees.dfcsa )
# 
# roads_major.shp@data$id <- rownames( roads_major.shp@data )
# roads_major.dfc <- fortify.SL( gIntersection( spgeom1 = roads_major.shp, spgeom2 = brown_poly ) ) %>% 
#   mutate( type = "major" )
# roads_major.dfcsa <- fortify.SL( crop( x = roads_major.shp, y = nestsSPDF ) ) %>% 
#   mutate( type = "major" )
# roads_minor.shp@data$id <- rownames( roads_minor.shp@data )
# roads_minor.dfc <- fortify.SL( gIntersection( spgeom1 = roads_minor.shp, spgeom2 = brown_poly ) ) %>% 
#   mutate( type = "minor" )
# roads_minor.dfcsa <- fortify.SL( crop( x = roads_minor.shp, y = nestsSPDF ) ) %>% 
#   mutate( type = "minor" )
# 
# # Create a master roads data.frame, and one cropped to include just the study area.
# roads.dfc <- bind_rows( roads_major.dfc, roads_minor.dfc )
# roads.dfcsa <- bind_rows( roads_major.dfcsa, roads_minor.dfcsa )

##### Map Creation. #####

# Country
USmap <- ggplot( data = usa, 
                 aes( x = long, 
                      y = lat, 
                      group = group ) ) + 
  geom_rect( data = USbox, 
             inherit.aes = FALSE, 
             aes( xmin = xmin - ( 0.05 * ( xmax - xmin ) ), 
                  xmax = xmax + ( 0.05 * ( xmax - xmin ) ), 
                  ymin = ymin - ( 0.05 * ( ymax - ymin ) ), 
                  ymax = ymax + ( 0.05 * ( ymax - ymin ) ) ), 
             alpha = 0, 
             colour = "black" ) + 
  geom_polygon( fill = "white", 
                colour = "black", 
                size = 0.25 ) + 
  geom_polygon( data = filter( usa, region == "nebraska" ) ) + 
  coord_fixed( ratio = 1.4 ) + 
  theme_classic() + 
  theme( line = element_blank(), 
         text = element_blank() ) + 
  scalebar( data = usa, 
            location = "bottomleft", 
            st.size = 3, 
            dist = 500, 
            dd2km = TRUE, 
            model = "WGS84" )

# State
NEmap <- ggplot( data = nebraska,
                 aes( x = long,
                      y = lat,
                      group = group ) ) +
  geom_polygon( fill = "white",
                colour = "black", 
                size = 0.25 ) + 
  geom_polygon( data = GRPC_range.dfc, 
                aes( group = group ), 
                alpha = 0.6 ) + 
  geom_polygon( data = filter( nebraska, subregion == "brown" ) ) + 
  coord_fixed( ratio = 1.3 ) +
  theme_classic() +
  theme( line = element_blank(),
         text = element_blank(),
         plot.background = element_rect( fill = "transparent",
                                         colour = "transparent" ),
         panel.background = element_rect( fill = "transparent",
                                          colour = "transparent" ) ) + 
  scalebar( data = nebraska, 
            dist = 50, 
            st.dist = 0.04, 
            dd2km = TRUE, 
            model = "WGS84", 
            anchor = c( x = -102.6, y = 40.85 ), 
            st.size = 3 ) + 
  north( data = nebraska, 
         location = "bottomleft", 
         scale = 0.2, 
         symbol = 3 )

# County
brownMap <- ggplot( data = brownCo,
                    aes( x = long,
                         y = lat,
                         group = group ) ) +
  geom_polygon( fill = "white",
                colour = "black", 
                size = 0.25 ) + 
  # geom_polygon( data = cover.dfc,
  #               inherit.aes = FALSE,
  #               aes( x = long,
  #                    y = lat,
  #                    group = interaction( group, type ),
  #                    fill = type ) ) +
  # geom_path( data = roads.dfc, 
  #            alpha = 0.4, 
  #            aes( group = interaction( group, type ) ) ) +
  geom_point( data = data.frame( turbines.shp@coords ),
              inherit.aes = FALSE,
              aes( x = coords.x1,
                   y = coords.x2 ),
              shape = 4, 
              size = 1 ) +
  geom_point( data = data.frame( nestsSPDF@coords ),
              inherit.aes = FALSE,
              aes( x = UTM_E,
                   y = UTM_N ), 
              shape = 1 ) + 
  geom_point( data = data.frame( ainsworth@coords ), 
              inherit.aes = FALSE, 
              aes( x = long, 
                   y = lat ), 
              shape = 20 ) + 
  geom_text( data = data.frame( ainsworth@coords ), 
             inherit.aes = FALSE, 
             aes( x = long, 
                  y = lat ), 
             label = "Ainsworth", 
             nudge_x = 0.055, 
             nudge_y = 0.015 ) + 
  coord_fixed( ratio = 1.3 ) +
  scale_fill_grey() + 
  theme_classic() +
  theme( line = element_blank(),
         axis.title = element_blank(), 
         axis.text = element_blank(), 
         plot.background = element_rect( fill = "transparent",
                                         colour = "transparent" ),
         panel.background = element_rect( fill = "transparent",
                                          colour = "transparent" ) ) + 
  scalebar( data = brownCo, 
            dist = 5, 
            dd2km = TRUE, 
            model = "WGS84", 
            height = 0.01, 
            anchor = c( x = -100, y = 42.07 ), 
            st.size = 3 ) + 
  north( data = brownCo, 
         location = "topright", 
         symbol = 3 )

# Study area
SAmap <- ggplot( data = data.frame( turbines.shp@coords ), 
                 aes( x = coords.x1, 
                      y = coords.x2 ) ) + 
  # geom_polygon( aes( group = interaction( group, type ),
  #                    fill = type ) ) +
  # geom_path( data = roads.dfcsa, 
  #            aes( group = interaction( group, type ) ), 
  #            alpha = 0.4 ) + 
  geom_point( shape = 8 ) +
  geom_point( data = data.frame( nestsSPDF@coords ), 
              inherit.aes = FALSE, 
              aes( x = UTM_E, 
                   y = UTM_N ) ) + 
  coord_fixed( ratio = 1.3 ) + 
  scale_fill_grey() + 
  theme_classic() + 
  theme( line = element_blank(), 
         axis.text = element_blank(), 
         axis.title = element_blank() )

```

```{r BrownCo}
brownMap
ggsave( "brownMap.pdf", plot = brownMap, device = "pdf", path = "figures/", height = 15, width = 9, units = "cm" )
```

```{r triMapFiguRe}


grid.newpage()
v1 <- viewport( x = 0.5, y = 0.75, width = 1, height = 1 )
v2 <- viewport( x = 0.2, y = 0.15, width = 0.39, height = 0.3 )
v3 <- viewport( x = 0.75, y = 0.25, width = 0.4, height = 0.52 )
print( NEmap, vp = v1 )
print( USmap, vp = v2 )
print( brownMap, vp = v3 )

```

```{r mapCalcs}

# Calculate the area of the study area.
mcp <- SpatialPolygons( list( Polygons( list( Polygon( nestLocs[ chull( nestLocs ), ] ) ), 
                                        ID = "nestMCP" ) ), 
                        proj4string = CRS( "+init=epsg:32610 +proj=utm +zone=14 +datumWGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0" ) ) # coordinates for the minimum convex polygon subtending the 30 nests

mcp.t_utm <- spTransform( mcp.t <- SpatialPolygons( list( Polygons( list( Polygon( turbines.shp@coords[ chull( turbines.shp@coords ), ] ) ), 
                                                                    ID = "turbineMCP" ) ), 
                                                    proj4string = CRS( targProj ) ), 
                          CRS( "+init=epsg:32610 +proj=utm +zone=14 +datumWGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0" ) )


areaKm2 <- mcp@polygons[[1]]@Polygons[[1]]@area / 1e6
prettyAreaKm2 <- plyr::round_any( x = areaKm2, accuracy = 5, f = round )

area.Km2.t <- mcp.t_utm@polygons[[1]]@Polygons[[1]]@area / 1e6

centroid <- coordinates( spTransform( mcp, CRS( targProj ) ) )
centroid.t <- coordinates( mcp.t )

```

```{r climateCalcs}

FtoC <- function( .F ){
  ( .F - 32 ) / 1.8
}

climate <- read.csv( "data/climate.csv", stringsAsFactors = FALSE )
climateSI <- climate %>%
  transmute( Month = Month,
             Precip.mm = Total_Normal_Precipitation_inches * 25.4,
             MeanMaxTemp.C = FtoC( Mean_Normal_Max_Temperature_F ),
             MeanMinTemp.C = FtoC( Mean_Normal_Min_Temperature_F ),
             MeanAvgTemp.C = FtoC( Mean_Normal_Avg_Temperature_F ) )

totPrecip <- c( inches = sum( climate$Total_Normal_Precipitation_inches ), mm = sum( climateSI$Precip.mm ) )
breedingPeriod <- range( month( fullBouts$Date ) )
breedingPrecip.percent <- ( sum( climate$Total_Normal_Precipitation_inches[ breedingPeriod[ 1 ]:breedingPeriod[ 2 ] ] ) / totPrecip[ 1 ] ) * 100

minTemp <- which.min( climate$Mean_Normal_Min_Temperature_F )
minTemp <- list( Month = climate$Month[ minTemp ], Fahr = climate$Mean_Normal_Min_Temperature_F[ minTemp ], Cels = climateSI$MeanMinTemp.C[ minTemp ] )

maxTemp <- which.max( climate$Mean_Normal_Max_Temperature_F )
maxTemp <- list( Month = climate$Month[ maxTemp ], Fahr = climate$Mean_Normal_Max_Temperature_F[ maxTemp ], Cels = climateSI$MeanMaxTemp.C[ maxTemp ] )

mayTemp <- which( climate$Month == "May" )
mayTemp <- list( Fahr = climate$Mean_Normal_Avg_Temperature_F[ mayTemp ], Cels = climateSI$MeanAvgTemp.C[ mayTemp ] )

juneTemp <- which( climate$Month == "June" )
juneTemp <- list( Fahr = climate$Mean_Normal_Avg_Temperature_F[ juneTemp ], Cels = climateSI$MeanAvgTemp.C[ juneTemp ] )

julyTemp <- which( climate$Month == "July" )
julyTemp <- list( Fahr = climate$Mean_Normal_Avg_Temperature_F[ julyTemp ], Cels = climateSI$MeanAvgTemp.C[ julyTemp ] )


# # Wind data--easier just to get the same information (i.e., that the study area is in a class 4 wind power potential zone) from the Wind Energy Resource Atlas.
# wind <- readOGR( dsn = "data/Nebraska_Wind_High_Resolution", layer = "nebraska_50mwind" )
# wind@data$id <- rownames( wind@data )
# wind <- spTransform( wind, CRS( targProj ) )
# windData <- data.frame( wind )
# 
# brownWind <- na.omit( cbind( wind %over% brown_poly, windData ) )
# 
# brownWind.pts <- fortify( wind[ wind$id %in% unique( brownWind$id ), ], region = "id" )

```

During the 2013 and 2014 breeding seasons (May--July), we monitored prairie-chicken nests in a `r prettyAreaKm2`-km$^2$ area centered at `r round(abs(centroid[2]),2)`°N, `r round(abs(centroid[1]),2)`°W in Brown county, Nebraska, USA (Figure \@ref(fig:BrownCo)). The area is part of the Nebraska Sandhills, a 50,000-km$^2$ region spanning the north-central portion of the state and dominated by dunes of sandy soil stabilized by mixed-grass prairie and interspersed with shallow lakes and wetlands [@schneider2011]. Between 1981 and 2010, the area received an average of `r round(totPrecip[1],2)` in (`r round(totPrecip[2])` mm) of precipitation annually, of which `r round(breedingPrecip.percent,1)`% fell during the breeding season [(May--July; [@hprcc2017]. Temperatures ranged from an average monthly low of `r round(minTemp$Fahr,1)`°F (`r round(minTemp$Cels,1)`°C) in `r minTemp$Month` to an average monthly high of `r round(maxTemp$Fahr,1)`°F (`r round(maxTemp$Cels,1)`°C) in `r maxTemp$Month` [@hprcc2017]. Average monthly temperatures during the breeding season were `r round(mayTemp$Fahr,1)`°F (`r round(mayTemp$Cels,1)`°C) in May, `r round(juneTemp$Fahr,1)`°F (`r round(juneTemp$Cels,1)`°C) in June, and `r round(julyTemp$Fahr,1)`°F (`r round(julyTemp$Cels,1)`°C) in July [@hprcc2017]. Throughout the Sandhills, annual average wind speeds ranged from 7.0 to 7.5 m/s at a height of 50 m [@elliott1986].

The study site encompasses a wind energy facility owned and operated by the Nebraska Public Power District since 2005 [@nppd2017]. The facility is centered at `r round(abs(centroid.t[2]),2)`°N, `r round(abs(centroid.t[1]),2)`°W,  and covers a total area of `r round(area.Km2.t,1)` km$^2$. Each of the 36 turbines at the facility occupies a footprint of approximately 0.5 acres (0.2 ha), stands 70 m tall at the hub, and has a rotor diameter of 82 m [@nppd2017]. The turbines operate intermittently, at an estimated 40% of the full capacity (1.65 MW/turbine) [@nppd2017].

###**METHODS** {#methods}

```{r METHODSnotes, eval = FALSE, include = FALSE}
# --characteristics
# ----concise
# ----active voice
# --include
# ----study duration
# ----sampling protocols
# ----dates
# ----research or experimental design
# ----data analyses
# ----animal welfare protocols (at end)
```

####**Field Methods** {#fieldmethods}

We fitted female prairie-chickens with necklace-style very high frequency (VHF) radio transmitters (**<< model no.? >>**; Advanced Telemetry Systems Inc., Isanti, MN, USA) during the pre-nesting period and identified their locations five to seven times per week by radio telemetry (see @olney2015). When the location of an individual hen went unchanged over a three-day period, we approached the location on foot to determine whether a nest was present. Upon locating nests, we recorded the coordinates with a handheld global positioning system (GPS) device (Etrex Vista, Garmin International Inc., Olathe, KS, USA). At a subset of the nests, we also placed Thermochron$^{\circledR}$ iButton$^{\circledR}$ temperature loggers (model DS1922L; Maxim Integrated, Dallas, TX, USA; hereafter iButtons) at the nest edge to record nest temperature at four-minute intervals. Each iButton was wrapped in a fine mesh cloth, tied to a thick wire pushed into the ground, and concealed with nesting material. The iButtons were placed variously before or after clutch completion (and initiation of incubation) depending upon when the nest was located, and were retrieved after the eggs hatched or the nest failed (or was abandoned).

Throughout the incubation period, we monitored each nest daily from a distance of at least 30 m. When a hen was found to be away from her nest on three consecutive days, we again approached the nest on foot to assess the nest fate. We evaluated nest fates based on the presence and disposition of eggshells in the nest bowl as well as signs of predator activity nearby. For nests that successfully hatched, we calculated the approximate date of initiation of incubation based on a 28-day incubation period (**<< citation? Birds of NA? I don't have access to this resource. >>**). This date served as the basis for determining the nest age as used in the off-bout analysis.

At least five days after first locating each nest (or on the estimated date of clutch completion), we returned to conduct vegetation sampling at the nest site. With a Robel pole placed at the center of the nest bowl, we performed a visual obstruction reading (VOR) from each of the four cardinal directions [@robel1970]. The average VOR for each nest was calculated as the arithmetic mean of the four readings. In addition, we accessed weather data (including ambient temperature, precipitation, and wind speed) recorded every 20 min at the nearby Ainsworth Regional Airport (**<< source? NRCC? >>**). **<< Methods on spatial data? >>** For additional details concerning field methods, as well as analyses and discussion of nesting and brooding ecology, see Olney Harrison [-@olney2015].

####**Data Analyses** {#datamethods}

We uploaded readings from each iButton using 1-wire software developer's kit for Windows (version 4.00; Maxim Integrated, Dallas, TX, USA). After converting the files into an appropriate format using Rhythm [@cooper2005], we **<< manually? >>** identified off-bouts and measured their duration from the temperature data in Raven Pro (version 1.5; Cornell Lab of Ornithology, Ithaca, NY, USA). We defined an off-bout as the time interval elapsing between the temperature recording just prior to the bird's departure from the nest (indicated by a sudden decrease in temperature in the time-series) until the time of the recording made just prior to her return (indicated by a sharp rise in temperature). Because the precise signature of off-bouts varied, we based our classification on the following criteria: (1) a minimum duration of 10 minutes, (2) a total temperature difference of at least 2°C, and (3) a minimum initial absolute slope in the temperature--time plot of 0.1°C/minute (0.4°C between sequential recordings). **<< These criteria are from Cole's poster (w/ #1 modified based on discussion w/ EJ); should I instead just cite the poster? >>**

Because iButtons sample temperature instantaneously rather than continuously, off-bout identification and duration measurements are subject to error that is inversely proportional to the sampling rate [@cooper2005]. We configured iButtons to log temperatures at 4-minute intervals; therefore, the maximum possible error in a single duration measurement (assuming it is correctly identified) is 8 minutes. This error is small compared to the mean measured off-bout duration and in relation to actual variation among off-bout durations ($\bar{x}$ = `r round(mean(bouts$Mins),1)` ± `r round(sd(bouts$Mins),1)` min [SD]). **<< Does this belong in the results? >>**

```{r METHODSnotes2, eval = FALSE, include = FALSE}

# --note that nest age was not calculable for all nests
# --note about derivation of wind speed and ambient temperature by linear interpolation

# --sampling rate = 1 / 4 min.
# --each off-bout duration estimate therefore has associated error ~T: [@cooper2005]
# ----µ = 0 min
# ----SD ~= 0.408 * 4 min (1.632 min)
# ----max. value = 4 min

# --compare sampling error to spread of actual distribution:
# ----with( fullBouts, mean( Mins ) ) # 43.27428
# ----with( fullBouts, sd( Mins ) ) # 24.11489
# ----max. sampling error (4 min) is 9.2% and 16.6% of the magnitude of the true mean and sd

```

```{r nestRsuccess, eval = FALSE, include = FALSE}

ns.mod_day <- glm( Nest_Success ~ MeanMins_day + Turbine_within_1km, data = nests, family = "binomial" )
ns.mod_bout <- glm( Nest_Success ~ MeanMins_bout + Turbine_within_1km, data = nests, family = "binomial" )

```

-----

```{r DURlm, eval = FALSE, include = FALSE}

bcMminTransform <- boxcox( MeanMins_day ~ Turbine_Distance_m + Roads_Distance_m + Nest_Success + VOR_AVG + yday( startDate ), 
                           data = nests, 
                           plotit = FALSE )
lMmin_est <- bcMminTransform$x[ which.max( bcMminTransform$y ) ]
nests$tMeanMins_day <- ifelse( test = rep( lMmin_est != 0, length( nests$MeanMins_day ) ), 
                               yes = nests$MeanMins_day^( -2 ), 
                               n = log( nests$MeanMins_day))


dur.lm_mods <- list( int = tMeanMins_day ~ 1, 
                     tbd = tMeanMins_day ~ Turbine_Distance_m, 
                     rdd = tMeanMins_day ~ Roads_Distance_m, 
                     nsx = tMeanMins_day ~ Nest_Success, 
                     vor = tMeanMins_day ~ VOR_AVG, 
                     std = tMeanMins_day ~ startDate, 
                     dist = tMeanMins_day ~ Turbine_Distance_m + Roads_Distance_m, 
                     envr = tMeanMins_day ~ Turbine_Distance_m + Roads_Distance_m + VOR_AVG, 
                     nest = tMeanMins_day ~ Nest_Success + startDate, 
                     nostd = tMeanMins_day ~ Turbine_Distance_m + Roads_Distance_m + Nest_Success + VOR_AVG, 
                     global = tMeanMins_day ~ Turbine_Distance_m + Roads_Distance_m + Nest_Success + VOR_AVG + startDate )

dur.lm_fits <- lapply( X = dur.lm_mods, 
                       FUN = function( .ff ) lm( .ff, data = nests ) )

dur.lm_forms <- gsub( pattern = "\\s{2,}", 
                      replacement = " ", 
                      x = sapply( X = sapply( X = dur.lm_mods, FUN = function( .ff ) deparse( .ff[[ 3 ]] ) ), 
                                  FUN = function( .ff ) paste( .ff, collapse = "" ) ) )
dur.lm_aicc <- sapply( X = dur.lm_fits, FUN = AICc )
dur.lm_delt <- dur.lm_aicc- min( dur.lm_aicc )
dur.lm_Awgt <- exp( -0.5 * dur.lm_delt )
dur.lm_Awgt <- dur.lm_Awgt / sum( dur.lm_Awgt )
dur.lm_K <- sapply( X = dur.lm_fits, FUN = function( .mm ) length( .mm$coefficients ) )

dur.lm_selection <- data.frame( Model = dur.lm_forms,  
                                AICc = dur.lm_aicc, 
                                DAICc = dur.lm_delt, 
                                Awgt = dur.lm_Awgt, 
                                K = dur.lm_K )[ order( dur.lm_delt ), ]

dur.lm_test <- augment( dur.lm_fits[[ "global" ]] )

rVf_dur.lm <- ggplot( dur.lm_test, aes( x = .fitted, y = .resid ) ) + 
  geom_hline( yintercept = 0, linetype = "dashed" ) + geom_smooth( colour = "grey24" ) + 
  geom_point() + theme_classic() + labs( x = "Fitted values", y = "Residuals" )

y <- quantile( x = dur.lm_test$.std.resid, probs = c( 0.25, 0.75 ) )
x <- qnorm( p = c( 0.25, 0.75 ) )
slope <- diff( y ) / diff( x )
int = y[ 1L ] - ( slope * x[ 1L ] )

qq_dur.lm <- ggplot( dur.lm_test, aes( sample = .std.resid ) ) + 
  geom_qq() + geom_abline( slope = slope, intercept = int, colour = "tomato2" ) + 
  theme_classic() + labs( x = "Theoretical quantiles", y = "Standardized residuals" )

sl_dur.lm <- ggplot( dur.lm_test, aes( .fitted, sqrt( abs( .std.resid ) ) ) ) + 
  geom_hline( yintercept = 1, linetype = "dashed" ) + geom_smooth( colour = "grey24" ) + 
  geom_point() + theme_classic() + labs( x = "Fitted values", y = "√|Standardized residuals|" )

lev_dur.lm <- ggplot( dur.lm_test, aes( .hat, .std.resid, size = .cooksd ) ) + 
  geom_hline( yintercept = 0, colour = "grey" ) + geom_vline( xintercept = 0, colour = "grey" ) + 
  geom_point() + theme_classic() + labs( x = "Leverage", y = "Standardized residuals", size = "Cook's distance" ) + 
  theme( legend.position = "bottom" ) 

cowplot::plot_grid( rVf_dur.lm, qq_dur.lm, sl_dur.lm, lev_dur.lm, nrow = 2, labels = "AUTO" )

```

-----

```{r exploRe, eval = FALSE, include = FALSE}

#### Transformations. ####

# For the duration response, a log-transformation looks pretty good. It's bounded at zero and never assumes a value of zero, so this seems like a good approach. The response also isn't discrete, so a Poisson error distribution is not an option.
hist( fullBouts$Mins )
hist( log( fullBouts$Mins ) )

hist( fullBouts$EventStart_dl, breaks = "mins" )

#### Correlations. ####

# Predictors of interest (as named in 'fullBouts')
intVars <- c( "Mins", "NestAge", "AmbientTemp", "preBoutNestTemp", "VPD", "TempDiff", "WindSpeed", "VOR_AVG", "VH_AVG", "Turbine_Distance_m", "Roads_Distance_m", "Trees_Distance_m", "Water_Distance_m", "MeanMins_bout", "Nest_Success", "Jday" )

# # This is rather ugly, and it took quite a while to render. Moreover, the density of the points in most of the scatterplots makes it look as though correlations are pretty strong, when the actual coefficient is fairly low. Perhaps this is an indication that I should be using the Spearman rank correlation coefficient rather than the Pearson method. Most of the highly-correlated pairs are expected, though (e.g., VPD with AmbientTemp, AmbientTemp with TempDiff, etc.), so maybe I'll just focus on selecting variables from among those groups.
# GGally::ggpairs( dplyr::select( fullBouts, one_of( vv ) ) )

# Make a data.frame containing only the variables of interest.
varData <- fullBouts %>% 
  dplyr::select( one_of( intVars ) )

# Find the (Pearson) correlations among those variables, omitting pairwise incomplete observations.
corMat <- round( cor( varData, use = "pairwise.complete.obs" ), 3 )

# Original was busy. Paring things down.
corMat[ lower.tri( corMat, diag = TRUE ) ] <- NA

# Now pick out the arbitrarily highly-correlated pairs of variables.
hiCorrs <- data.frame( which( abs( corMat ) >= 0.5, arr.ind = TRUE ) ) %>% 
  rowwise() %>% 
  mutate( Var1 = intVars[ row ], 
          Var2 = intVars[ col ], 
          PearsonR = corMat[ row, col ] )
# with( fullBouts, cor( NestAge, Jday, use = "pairwise.complete.obs" ) )
# with( fullBouts, cor( NestAge, AmbientTemp, use = "pairwise.complete.obs" ) )
# with( fullBouts, cor( AmbientTemp, Jday, use = "pairwise.complete.obs" ) )

## Try the Spearman Rank Correlation Coefficient (tests for monotonic, rather than mere linear, associations). ##

# Find the (Spearman) correlations among those variables, omitting pairwise incomplete observations.
scorMat <- round( cor( varData, method = "spearman", use = "pairwise.complete.obs" ), 3 )

# Original was busy. Paring things down.
scorMat[ lower.tri( scorMat, diag = TRUE ) ] <- NA

# Now pick out the arbitrarily highly-correlated pairs of variables.
hiScorrs <- data.frame( which( abs( scorMat ) >= 0.5, arr.ind = TRUE ) ) %>% 
  rowwise() %>% 
  mutate( Var1 = intVars[ row ], 
          Var2 = intVars[ col ], 
          SpearmanR = scorMat[ row, col ] )
# with( fullBouts, cor( NestAge, Jday, method = "spearman", use = "pairwise.complete.obs" ) )
# with( fullBouts, cor( NestAge, AmbientTemp, method = "spearman", use = "pairwise.complete.obs" ) )
# with( fullBouts, cor( AmbientTemp, Jday, method = "spearman", use = "pairwise.complete.obs" ) )

# with( fullBouts, plot( VH_AVG, VOR_AVG ) )

## Summary: There are certainly strong correlations where I'd expect them (among AmbientTemp, TempDiff, and VPD). Picking just one of those seems like a good idea, and I would imagine TempDiff and/or VPD are more proximally important in governing off-bout decision making in chickens. Their correlation with one another isn't *so* strong (Pearson's r = -0.536, Spearman's rho = -0.521), but they're definitely related to one another. VPD is more like AmbientTemp than is TempDiff, so maybe I'll choose TempDiff, as the variable that's least alike relative to the others.
```

```{r DURcoRrs}

vars_DUR <- c( "Nest age" = "NestAge", 
               "Temperature difference" = "TempDiff", 
               "VOR" = "VOR_AVG", 
               "Wind speed" = "WindSpeed", 
               "Distance to nearest turbine" = "Turbine_Distance_m", 
               "Distance to nearest road" = "Roads_Distance_m", 
               "Distance to nearest water source" = "Water_Distance_m", 
               "Ordinal date" = "Jday" )

var.corrs_DUR <- data.frame( t( combn( x = vars_DUR, m = 2 ) ), stringsAsFactors = FALSE )
yr.wilcox_DUR <- data.frame( X1 = vars_DUR, X2 = "fYear", stringsAsFactors = FALSE )

Pcorrs_DUR <- with( var.corrs_DUR, map2( .x = as.list( X1 ), 
                                         .y = as.list( X2 ), 
                                         .f = function( xx, yy ) cor.test( x = fullBouts[ , xx ], 
                                                                           y = fullBouts[ , yy ], 
                                                                           alternative = "two.sided", 
                                                                           method = "pearson" ) ) )
Scorrs_DUR <- with( var.corrs_DUR, map2( .x = as.list( X1 ), 
                                         .y = as.list( X2 ), 
                                         .f = function( xx, yy ) cor.test( x = fullBouts[ , xx ], 
                                                                           y = fullBouts[ , yy ], 
                                                                           alternative = "two.sided", 
                                                                           method = "spearman", 
                                                                           exact = FALSE ) ) )
Ytests_DUR <- with( yr.wilcox_DUR, map2( .x = as.list( X1 ), 
                                         .y = as.list( X2 ), 
                                         .f = function( xx, yy ) wilcox.test( fullBouts[ , xx ] ~ fullBouts[ , yy ], 
                                                                              alternative = "two.sided" ) ) )

var.corrs_DUR <- var.corrs_DUR %>% 
  mutate( PearsonR = sapply( Pcorrs_DUR, function( .htest ) .htest$estimate ), 
          PearsonP = sapply( Pcorrs_DUR, function( .htest ) .htest$p.value ), 
          SpearmanR = sapply( Scorrs_DUR, function( .htest ) .htest$estimate ), 
          SpearmanP = sapply( Scorrs_DUR, function( .htest ) .htest$p.value ) )

yr.wilcox_DUR <- yr.wilcox_DUR %>% 
  mutate( X1 = sapply( X = X1, FUN = function( .nn ) names( vars_DUR )[ vars_DUR %in% .nn ] ), 
          WilcoxonW = sapply( Ytests_DUR, function( .htest ) .htest$statistic ), 
          WilcoxonP = sapply( X = sapply( Ytests_DUR, function( .htest ) .htest$p.value ), 
                              FUN = function( .pp ) ifelse( .pp < 0.0001, "**<0.0001**", 
                                                            ifelse( .pp < 0.001, "**<0.001**", 
                                                                    ifelse( .pp < 0.01, "**<0.01**", 
                                                                            ifelse( .pp < 0.05, paste( "**", round( .pp, 3 ), "**", sep = "" ), 
                                                                                    as.character( round( .pp, 3 ) ) ) ) ) ) ) ) %>% 
  dplyr::select( -X2 )

corrs.table_DUR <- var.corrs_DUR %>% 
  dplyr::select( -starts_with( "Pearson" ) ) %>% 
  mutate( X1 = sapply( X = X1, FUN = function( .nn ) names( vars_DUR )[ vars_DUR %in% .nn ] ), 
          X2 = sapply( X = X2, FUN = function( .nn ) names( vars_DUR )[ vars_DUR %in% .nn ] ), 
          SpearmanP = sapply( X = SpearmanP, FUN = function( .pp ) ifelse( .pp < 0.0001, "**<0.0001**", 
                                                                           ifelse( .pp < 0.001, "**<0.001**", 
                                                                                   ifelse( .pp < 0.01, "**<0.01**", 
                                                                                           ifelse( .pp < 0.05, paste( "**", round( .pp, 3 ), "**", sep = "" ), 
                                                                                                   as.character( round( .pp, 3 ) ) ) ) ) ) ) )

# knitr::kable( x = corrs.table_DUR, 
#               format = "pandoc", 
#               digits = 3, 
#               col.names = c( "", "", "Spearman's $\\rho$", "*p*" ), 
#               caption = "Spearman's rank correlation coefficients for all covariates considered for inclusion in the models. We calculated estimates for Spearman's $\\rho$ using an asymptotic *t* approximation.")
# 
# knitr::kable( x = yr.wilcox_DUR, 
#               format = "pandoc", 
#               digits = 3, 
#               col.names = c( "", "Wilcoxon's *W*", "*p*" ), 
#               caption = "Results of tests for between-year differences in the continuous covariates using the two-sided Wilcoxon rank-sum test with continuity correction." )

```

```{r FREQcoRrs}

vars_FREQ <- c( "Nest age" = "NestAge", 
                "Ambient temperature" = "AmbientTemp", 
                "VOR" = "VOR_AVG", 
                "Wind speed" = "WindSpeed", 
                "Precipitation" = "Precipitation", 
                "Distance to nearest turbine" = "Turbine_Distance_m", 
                "Distance to nearest road" = "Roads_Distance_m", 
                "Distance to nearest water source" = "Water_Distance_m", 
                "Ordinal date" = "Jday" )

var.corrs_FREQ <- data.frame( t( combn( x = vars_FREQ, m = 2 ) ), stringsAsFactors = FALSE )
yr.wilcox_FREQ <- data.frame( X1 = vars_FREQ, X2 = "fYear", stringsAsFactors = FALSE )
tm.kruskal_FREQ <- data.frame( X1 = vars_FREQ, X2 = "blockID", stringsAsFactors = FALSE )

Pcorrs_FREQ <- with( var.corrs_FREQ, map2( .x = as.list( X1 ), 
                                           .y = as.list( X2 ), 
                                           .f = function( xx, yy ) cor.test( x = freqData[ , xx ], 
                                                                             y = freqData[ , yy ], 
                                                                             alternative = "two.sided", 
                                                                             method = "pearson" ) ) )
Scorrs_FREQ <- with( var.corrs_FREQ, map2( .x = as.list( X1 ), 
                                           .y = as.list( X2 ), 
                                           .f = function( xx, yy ) cor.test( x = freqData[ , xx ], 
                                                                             y = freqData[ , yy ], 
                                                                             alternative = "two.sided", 
                                                                             method = "spearman", 
                                                                             exact = FALSE ) ) )
Ytests_FREQ <- with( yr.wilcox_FREQ, map2( .x = as.list( X1 ), 
                                           .y = as.list( X2 ), 
                                           .f = function( xx, yy ) wilcox.test( freqData[ , xx ] ~ freqData[ , yy ], 
                                                                                alternative = "two.sided" ) ) )

Ttests_FREQ <- with( tm.kruskal_FREQ, map2( .x = as.list( X1 ), 
                                            .y = as.list( X2 ), 
                                            .f = function( xx, yy ) kruskal.test( freqData[ , xx ] ~ freqData[ , yy ] ) ) )
names( Ttests_FREQ ) <- tm.kruskal_FREQ$X1

var.corrs_FREQ <- var.corrs_FREQ %>% 
  mutate( PearsonR = sapply( Pcorrs_FREQ, function( .htest ) .htest$estimate ), 
          PearsonP = sapply( Pcorrs_FREQ, function( .htest ) .htest$p.value ), 
          SpearmanR = sapply( Scorrs_FREQ, function( .htest ) .htest$estimate ), 
          SpearmanP = sapply( Scorrs_FREQ, function( .htest ) .htest$p.value ) )

yr.wilcox_FREQ <- yr.wilcox_FREQ %>% 
  mutate( X1 = sapply( X = X1, FUN = function( .nn ) names( vars_FREQ )[ vars_FREQ %in% .nn ] ), 
          WilcoxonW = sapply( Ytests_FREQ, function( .htest ) .htest$statistic ), 
          WilcoxonP = sapply( X = sapply( Ytests_FREQ, function( .htest ) .htest$p.value ), 
                              FUN = function( .pp ) ifelse( .pp < 0.0001, "**<0.0001**", 
                                                            ifelse( .pp < 0.001, "**<0.001**", 
                                                                    ifelse( .pp < 0.01, "**<0.01**", 
                                                                            ifelse( .pp < 0.05, paste( "**", round( .pp, 3 ), "**", sep = "" ), 
                                                                                    as.character( round( .pp, 3 ) ) ) ) ) ) ) ) %>% 
  dplyr::select( -X2 )

tm.kruskal_FREQ <- tm.kruskal_FREQ %>% 
  mutate( X1 = sapply( X = X1, FUN = function( .nn ) names( vars_FREQ )[ vars_FREQ %in% .nn ] ), 
          KruskalX2 = sapply( Ttests_FREQ, function( .htest ) .htest$statistic ), 
          KruskalDf = sapply( Ttests_FREQ, function( .htest ) .htest$parameter ), 
          KruskalP = sapply( X = sapply( Ttests_FREQ, function( .htest ) .htest$p.value ), 
                             FUN = function( .pp ) ifelse( .pp < 0.0001, "**<0.0001**", 
                                                           ifelse( .pp < 0.001, "**<0.001**", 
                                                                   ifelse( .pp < 0.01, "**<0.01**", 
                                                                           ifelse( .pp < 0.05, paste( "**", round( .pp, 3 ), "**", sep = "" ), 
                                                                                   as.character( round( .pp, 3 ) ) ) ) ) ) ) ) %>% 
  dplyr::select( -X2 )

corrs.table_FREQ <- var.corrs_FREQ %>% 
  dplyr::select( -starts_with( "Pearson" ) ) %>% 
  mutate( X1 = sapply( X = X1, FUN = function( .nn ) names( vars_FREQ )[ vars_FREQ %in% .nn ] ), 
          X2 = sapply( X = X2, FUN = function( .nn ) names( vars_FREQ )[ vars_FREQ %in% .nn ] ), 
          SpearmanP = sapply( X = SpearmanP, FUN = function( .pp ) ifelse( .pp < 0.0001, "**<0.0001**", 
                                                                           ifelse( .pp < 0.001, "**<0.001**", 
                                                                                   ifelse( .pp < 0.01, "**<0.01**", 
                                                                                           ifelse( .pp < 0.05, paste( "**", round( .pp, 3 ), "**", sep = "" ), 
                                                                                                   as.character( round( .pp, 3 ) ) ) ) ) ) ) )

# knitr::kable( x = corrs.table_FREQ, 
#               format = "pandoc", 
#               digits = 3, 
#               col.names = c( "", "", "Spearman's $\\rho$", "*p*" ), 
#               caption = "Spearman's rank correlation coefficients for all covariates considered for inclusion in the models. We calculated estimates for Spearman's $\\rho$ using an asymptotic *t* approximation.")
# 
# knitr::kable( x = yr.wilcox_FREQ, 
#               format = "pandoc", 
#               digits = 3, 
#               col.names = c( "", "Wilcoxon's *W*", "*p*" ), 
#               caption = "Results of tests for between-year differences in the continuous covariates using the two-sided Wilcoxon rank-sum test with continuity correction." )
# 
# knitr::kable( x = tm.kruskal_FREQ, 
#               format = "pandoc", 
#               digits = 3, 
#               col.names = c( "", "Kruskal-Wallis $\\chi^2$", "*p*" ), 
#               caption = "Results of tests for between-time-block differences in the continuous covariates using the Kruskal-Wallis rank-sum test.")

```

*Off-bout duration*.—

```{r DURranef}

globalMinsMod <- "Mins ~ fYear + NestAge * TempDiff + VOR_AVG + WindSpeed * Turbine_Distance_m + Roads_Distance_m + Water_Distance_m * Jday"

# Histograms suggest and Box-Cox power transformation confirms a log-transformation on the duration variable might not be a bad thing. Done.
bcMinTransform <- boxcox( as.formula( globalMinsMod ), 
                          data = fullBouts, 
                          plotit = FALSE )
l_est.dur <- bcMinTransform$x[ which.max( bcMinTransform$y ) ]
fullBouts$tMins <- ifelse( test = rep( l_est.dur != 0, length( fullBouts$Mins ) ), 
                           yes = fullBouts$Mins^l_est.dur, 
                           no = log( fullBouts$Mins ) )

globalMinsMod <- paste( "t", globalMinsMod, sep = "" )

dur.ranef <- list( int = lmer( as.formula( paste( globalMinsMod, " + ( 1 | fID )", sep = "" ) ), data = fullBouts ), 
                   year = lmer( as.formula( paste( globalMinsMod, " + ( fYear - 1 | fID )", sep = "" ) ), data = fullBouts ),
                   year.int = lmer( as.formula( paste( globalMinsMod, " + ( fYear | fID )", sep = "" ) ), data = fullBouts ),
                   year_int = lmer( as.formula( paste( globalMinsMod, " + ( 1 | fID ) + ( fYear - 1 | fID )", sep = "" ) ), data = fullBouts ),
                   age = lmer( as.formula( paste( globalMinsMod, " + ( NestAge - 1 | fID )", sep = "" ) ), data = fullBouts ), 
                   age.int = lmer( as.formula( paste( globalMinsMod, " + ( NestAge | fID )", sep = "" ) ), data = fullBouts ), 
                   age_int = lmer( as.formula( paste( globalMinsMod, " + ( 1 | fID ) + ( NestAge - 1 | fID )", sep = "" ) ), data = fullBouts ), 
                   # age.temp = lmer( as.formula( paste( globalMinsMod, " + ( NestAge * TempDiff - 1 | fID )", sep = "" ) ), data = fullBouts ), 
                   # age.temp.int = lmer( as.formula( paste( globalMinsMod, " + ( NestAge * TempDiff | fID )", sep = "" ) ), data = fullBouts ), 
                   # age.temp_int = lmer( as.formula( paste( globalMinsMod, " + ( 1 | fID ) + ( NestAge * TempDiff - 1 | fID )", sep = "" ) ), data = fullBouts ), 
                   temp = lmer( as.formula( paste( globalMinsMod, " + ( TempDiff - 1 | fID )", sep = "" ) ), data = fullBouts ), 
                   temp.int = lmer( as.formula( paste( globalMinsMod, " + ( TempDiff | fID )", sep = "" ) ), data = fullBouts ), 
                   temp_int = lmer( as.formula( paste( globalMinsMod, " + ( 1 | fID ) + ( TempDiff - 1 | fID )", sep = "" ) ), data = fullBouts ), 
                   vor = lmer( as.formula( paste( globalMinsMod, " + ( VOR_AVG - 1 | fID )", sep = "" ) ), data = fullBouts ),
                   vor.int = lmer( as.formula( paste( globalMinsMod, " + ( VOR_AVG | fID )", sep = "" ) ), data = fullBouts ),
                   vor_int = lmer( as.formula( paste( globalMinsMod, " + ( 1 | fID ) + ( VOR_AVG - 1 | fID )", sep = "" ) ), data = fullBouts ),
                   wind = lmer( as.formula( paste( globalMinsMod, " + ( WindSpeed - 1 | fID )", sep = "" ) ), data = fullBouts ), 
                   wind.int = lmer( as.formula( paste( globalMinsMod, " + ( WindSpeed | fID )", sep = "" ) ), data = fullBouts ), 
                   wind_int = lmer( as.formula( paste( globalMinsMod, " + ( 1 | fID ) + ( WindSpeed - 1 | fID )", sep = "" ) ), data = fullBouts ), 
                   turb = lmer( as.formula( paste( globalMinsMod, " + ( Turbine_Distance_m - 1 | fID )", sep = "" ) ), data = fullBouts ),
                   turb.int = lmer( as.formula( paste( globalMinsMod, " + ( Turbine_Distance_m | fID )", sep = "" ) ), data = fullBouts ),
                   turb_int = lmer( as.formula( paste( globalMinsMod, " + ( 1 | fID ) + ( Turbine_Distance_m - 1 | fID )", sep = "" ) ), data = fullBouts ),
                   road = lmer( as.formula( paste( globalMinsMod, " + ( Roads_Distance_m - 1 | fID )", sep = "" ) ), data = fullBouts ),
                   road.int = lmer( as.formula( paste( globalMinsMod, " + ( Roads_Distance_m | fID )", sep = "" ) ), data = fullBouts ),
                   road_int = lmer( as.formula( paste( globalMinsMod, " + ( 1 | fID ) + ( Roads_Distance_m - 1 | fID )", sep = "" ) ), data = fullBouts ),
                   h2o = lmer( as.formula( paste( globalMinsMod, " + ( Water_Distance_m - 1 | fID )", sep = "" ) ), data = fullBouts ),
                   h2o.int = lmer( as.formula( paste( globalMinsMod, " + ( Water_Distance_m | fID )", sep = "" ) ), data = fullBouts ),
                   h2o_int = lmer( as.formula( paste( globalMinsMod, " + ( 1 | fID ) + ( Water_Distance_m - 1 | fID )", sep = "" ) ), data = fullBouts ),
                   # h2o.Jday = lmer( as.formula( paste( globalMinsMod, " + ( Water_Distance_m * Jday - 1 | fID )", sep = "" ) ), data = fullBouts ),
                   # h2o.Jday.int = lmer( as.formula( paste( globalMinsMod, " + ( Water_Distance_m * Jday | fID )", sep = "" ) ), data = fullBouts ),
                   # h2o.Jday_int = lmer( as.formula( paste( globalMinsMod, " + ( 1 | fID ) + ( Water_Distance_m * Jday - 1 | fID )", sep = "" ) ), data = fullBouts ),
                   Jday = lmer( as.formula( paste( globalMinsMod, " + ( Jday - 1 | fID )", sep = "" ) ), data = fullBouts ), 
                   Jday.int = lmer( as.formula( paste( globalMinsMod, " + ( Jday | fID )", sep = "" ) ), data = fullBouts ), 
                   Jday_int = lmer( as.formula( paste( globalMinsMod, " + ( 1 | fID ) + ( Jday - 1 | fID )", sep = "" ) ), data = fullBouts ) )


# CC <- convCheckR( dur.ranef ) # ≥50 warnings! Many suggestions to re-scale variables (understandable: VOR ranges 0.25--3, road distance ranges 30--2500)
# UnID:         all turb, all road, all h2o, all Jday
# LargeMaxGrad: year, year.int, turb.int, turb_int, road.int, h2o.int, Jday.int
# LargeParGrad: turb.int, turb_int, road.int, h2o.int, Jday.int
# Singular:     vor.int, vor_int, turb.int, road_int, h2o.int, h2o_int, Jday_int

# Try scaling and centering continuous variables.

csfullBouts <- fullBouts %>% 
  mutate( NestAge = ( NestAge - mean( NestAge, na.rm = TRUE ) ) / sd( NestAge, na.rm = TRUE ), 
          TempDiff = ( TempDiff - mean( TempDiff, na.rm = TRUE ) ) / sd( TempDiff, na.rm = TRUE ), 
          VOR_AVG = ( VOR_AVG - mean( VOR_AVG, na.rm = TRUE ) ) / sd( VOR_AVG, na.rm = TRUE ), 
          WindSpeed = ( WindSpeed - mean( WindSpeed, na.rm = TRUE ) ) / sd( WindSpeed, na.rm = TRUE ), 
          Turbine_Distance_m = ( Turbine_Distance_m - mean( Turbine_Distance_m, na.rm = TRUE ) ) / sd( Turbine_Distance_m, na.rm = TRUE ), 
          Roads_Distance_m = ( Roads_Distance_m - mean( Roads_Distance_m, na.rm = TRUE ) ) / sd( Roads_Distance_m, na.rm = TRUE ), 
          Water_Distance_m = ( Water_Distance_m - mean( Water_Distance_m, na.rm = TRUE ) ) / sd( Water_Distance_m, na.rm = TRUE ), 
          Jday = ( Jday - mean( Jday, na.rm = TRUE ) ) / sd( Jday, na.rm = TRUE ) )

dur.ranef_cs <- lapply( X = dur.ranef,
                        FUN = function( .mm ) update( .mm, data = csfullBouts ) )

# CC <- convCheckR( dur.ranef_cs ) # Much better (3 warnings; still apparent issues with gradients, Hessians, etc.(?))
# # UnID:         year.int
# # LargeMaxGrad: all year
# # LargeParGrad: NONE!
# # Singular:     vor.int, vor_int, turb_int, road.int, road_int, h2o.int, h2o_int

# # Try additional iterations.
# 
# dur.ranef_cs.plus <- lapply( X = dur.ranef_cs,
#                              FUN = function( .mm ) update( .mm,
#                                                            start = getME( .mm, c( "theta", "fixef" ) ),
#                                                            control = lmerControl( optCtrl = list( maxfun = 2e4 ) ) ) )
# 
# CC <- convCheckR( dur.ranef_cs.plus ) # 2 warnings (UnID/large eigenvalue/rescale)
# # UnID:         year.int, year_int
# # LargeMaxGrad: all year
# # LargeParGrad: NONE!
# # Singular:     vor.int, vor_int, turb_int, road.int, road_int, h2o.int, h2o_int

# # Let's try a different optimizer. BOBYQA?
# 
# dur.ranef_cs.plus.bobyqa <- lapply( X = dur.ranef_cs,
#                                     FUN = function( .mm ) update( .mm,
#                                                                   control = lmerControl( optimizer = "bobyqa",
#                                                                                          optCtrl = list( maxfun = 2e4 ) ) ) )
# 
# CC <- convCheckR( dur.ranef_cs.plus.bobyqa ) # back to same 3 warnings as with _cs
# # UnID:         year.int
# # LargeMaxGrad: all year
# # LargeParGrad: NONE!
# # Singular:     vor.int, vor_int, turb_int, road.int, road_int, h2o.int, h2o_int

# # Perhaps not. Nelder-Mead?
# 
dur.ranef_cs.plus.neldermead <- lapply( X = dur.ranef_cs,
                                        FUN = function( .mm ) update( .mm,
                                                                      # start = getME( .mm, c( "theta", "fixef" ) ),
                                                                      control = lmerControl( optimizer = "Nelder_Mead",
                                                                                             optCtrl = list( maxfun = 2e4 ) ) ) )
# 
# CC <- convCheckR( dur.ranef_cs.plus.neldermead ) # 3 warnings. More admonitions to rescale variables; model unidentifiable, large eigenvalue ratio, the like.
# UnID:         year.int, year_int
# LargeMaxGrad: year, year_int, wind
# LargeParGrad: wind
# Singular:     vor_int, turb_int, road.int, road_int, h2o.int, h2o_int

# ## The following analysis evaluated the neldermead fit when it started from the optimized parameters from the original _cs fit. I'm not sure that's a good approach, so I've removed that specification (see the call to update above). This throws a few more warnings of the same sort, but estimates are generally the same (although notably, the AICc rankings differ--but the top-ranked model is the same).
# 
# CC <- convCheckR( dur.ranef_cs.plus.neldermead ) # Better! Just 5 warnings; 3 rescales and a paired unable to evaluate/degenerate Hessian
# # UnID:         year, year.int, turb_int
# # LargeMaxGrad: year, year.int, year_int, turb_int, h2o.Jday_int
# # LargeParGrad: NONE!
# # Singular:     vor.int, vor_int, road_int, all h2o but h2o, all h2o.Jday but h2o.Jday

# # # Let's try optimx's nlminb optimizer.
# # 
# # library( optimx )
# # dur.ranef_cs.plus.nlminb <- lapply( X = dur.ranef_cs,
# #                                     FUN = function( .mm ) update( .mm,
# #                                                                   # start = getME( .mm, c( "theta", "fixef" ) ),
# #                                                                   control = lmerControl( optimizer = "optimx",
# #                                                                                          optCtrl = list( method = "nlminb",
# #                                                                                                          maxit = 2e5 ) ) ) )
# # 
# # CC <- convCheckR( dur.ranef_cs.plus.nlminb ) # 5 warnings; large eigenvalue/unidentifiable; rescale
# # # UnID:         year_int
# # # LargeMaxGrad: year_int, turb.int
# # # LargeParGrad: NONE!
# # # Singular:     vor.int, vor_int, road.int, road_int, h2o.int, h2o_int

# I'll go with the Nelder-Mead optimizer.
dur.ranef_fit <- dur.ranef_cs.plus.neldermead

```

```{r DURranefSelection}

dur.ranef_aicc <- sapply( X = dur.ranef_fit, FUN = AICc )
dur.ranef_delta <- dur.ranef_aicc - min( dur.ranef_aicc )
dur.ranef_wts <- exp( -0.5 * dur.ranef_delta )
dur.ranef_wts <- dur.ranef_wts / sum( dur.ranef_wts )
dur.ranef_LL <- sapply( X = dur.ranef_fit, FUN = logLik )
dur.ranef_K <- sapply( X = dur.ranef_fit, FUN = function( .mm ) nobs( .mm ) - df.residual( .mm ) )
dur.ranef_REs <- sapply( X = dur.ranef_fit, FUN = function( .mm ) fetch.RE( .mm, as.form = TRUE ) )
dur.ranef_nFE <- sapply( X = dur.ranef_fit, FUN = function( .mm ) length( getME( .mm, "fixef" ) ) )
dur.ranef_nRE <- sapply( X = dur.ranef_fit, FUN = function( .mm ) length( getME( .mm, "theta" ) ) )

dur.ranef_selection <- data.frame( Model = names( dur.ranef_aicc ), 
                                   RE = dur.ranef_REs, 
                                   AICc = dur.ranef_aicc, 
                                   DeltaAICc = dur.ranef_delta, 
                                   AWt = dur.ranef_wts, 
                                   LL = dur.ranef_LL, 
                                   K = dur.ranef_K, 
                                   nFE = dur.ranef_nFE, 
                                   nRE = dur.ranef_nRE )[ order( dur.ranef_delta ), ]

dur.ranef_selection.abbrev <- dur.ranef_selection %>% 
  filter( DeltaAICc <= 10 )

# Happily, all the models with DeltaAICc ≤ 10 are non-singular, have good gradients, and are identifiable.

# Top-ranked model (by Delta AICc) has the following random-effects structure: (1 | fID) + (NestAge - 1 | fID)
# Contenders have Delta AICc 0.657 (NestAge | fID), 3.264 (1 | fID) + (Jday - 1 | fID), 4.312 (Jday | fID), 8.429 (1 | fID) + (TempDiff - 1 | fID)...
dur.ranef_topMod <- dur.ranef_fit[[ which.min( dur.ranef_delta ) ]]

```

We created (generalized) linear mixed models ([G]LMMs) of off-bout duration and frequency using nest (hen) ID as a grouping factor in the random-effects structure. Using this multi-level approach enabled us to consider as potential covariates variables which were constant for all observations (*i.e.*, off-bouts) at a particular nest (*e.g.*, average VOR and distance to nearest wind turbine) together with those that varied between observations (*e.g.*, wind speed, nest age, and temperature). When considering covariates to include in these models, we assessed correlations between continuous predictors using Spearman's rank correlation coefficient ($\rho$), and between continuous and categorical predictors using the Kruskal-Wallis rank sum test (when the categorical predictor had >2 levels) or the Mann-Whitney *U* test (when the categorical predictor had 2 levels). **<< discardment?? >>**

A Box-Cox power transformation of off-bout duration suggested that the variable was approximately log-normally distributed (maximum likelihood estimate for $\lambda$ = `r l_est.dur`). We therefore used a Gaussian error distribution and identity link function to model the natural-log-transformed duration. We considered the following covariates in models of log-transformed off-bout duration: year (as a categorical variable with two levels); nest age (days since the initiation of incubation); average VOR; wind speed; ordinal date; the signed difference between the ambient temperature (measured at the Ainsworth airport) and that of the nest just prior to off-bout initiation; and the distances from the nest to the nearest turbine, road, and water source. In addition, we considered the possibility for first-order interactions between nest age and ambient--nest temperature difference, between wind speed and the distance to the nearest wind turbine, and between ordinal date and the distance to the nearest water source.

We modeled off-bout frequency as the log-likelihood that a hen initiated an off-bout during a particular 3-hour block of time during the recording period (*i.e.*, from the time of the first recorded off-bout until the nest was presumed to have hatched or failed). Because hens either did (probability = 1) or did not (probability = 0) initiate off-bouts during each block, this approach assumed a Bernoulli error distribution and used a logit link function to model the response. In addition to the variables listed above for the off-bout duration model (but using ambient temperature only rather than the ambient--nest temperature difference), we also considered precipitation and time of day as potential influences on the frequency of off-bout initation. For the latter model, we considered the possibility of first-order interactions between nest age and ambient temperature, between wind speed and the distance to the nearest wind turbine, between turbine distance and time block, between wind speed and time block, and between the distance to the nearest water source and ordinal date.

To improve model convergence, we centered all continuous covariates on their respective means and scaled them by one standard deviation prior to fitting. We also used sum-to-zero contrasts on categorical predictors having >2 levels (*i.e.*, time block). Using a global (maximal) fixed-effects structure, we fit models with different random-effects strctures and selected among them using Akaike's Information Criterion with a second-order correction for small sample size (AIC$_c$; [@anderson2008]) following the procedure described by Zuur et al. [-@zuur2009] for selecting the most parsimonious mixed-effects model. To inform our model-selection procedure, we ranked comparable models according to their $\Delta$AIC$_c$ values and calculated model weights (or Akaike weights) as described by Zuur et al. [-@zuur2009]. The LMMs of off-bout duration were fit using restricted maximum likelihood (REML) to minimize bias in the random-effects estimates [@zuur2009]. We then selected a fixed-effects structure using the top-ranked random effects structure and maximum likelihood (ML) methods. Whereas Zuur et al. [-@zuur2009] recommend selecting the optimal fixed-effects structure by stepwise backwards selection from the global model, we compared this approach with one using AIC$_c$-based model selection for the off-bout duration analysis, and used only AIC$_c$-based selection to select the best fixed-effects structure for the off-bout frequency model.

We performed all calculations and statistical procedures in R (version 3.3.1; R Foundation for Statistical Computing, Vienna, Austria) using the package lme4 [@R-lme4] for functionality associated with mixed-effects modeling.

-----

```{r DURfixefAICcTrials}

# Trial for AICc-based selection on the fixed-effects (to compare with backwards elimination/dropwise selection).
# Create the candidate model set.
dur.fixef_forms <- list( int = tMins ~ 1 + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         fyr = tMins ~ fYear + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         nag = tMins ~ NestAge + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         tdf = tMins ~ TempDiff + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         vor = tMins ~ VOR_AVG + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         wnd = tMins ~ WindSpeed + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         trb = tMins ~ Turbine_Distance_m + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         rdd = tMins ~ Roads_Distance_m + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         h2o = tMins ~ Water_Distance_m + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         jdy = tMins ~ Jday + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         nag.tdf = tMins ~ NestAge * TempDiff + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         wnd.trb = tMins ~ WindSpeed * Turbine_Distance_m + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         h2o.jdy = tMins ~ Water_Distance_m * Jday + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         nag_tdf = tMins ~ NestAge + TempDiff + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         wnd_trb = tMins ~ WindSpeed + Turbine_Distance_m + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         h2o_jdy = tMins ~ Water_Distance_m + Jday + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         weather = tMins ~ TempDiff + WindSpeed + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         wea.trb = tMins ~ TempDiff + WindSpeed + Turbine_Distance_m + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         nt_w.t = tMins ~ NestAge * TempDiff + WindSpeed + Turbine_Distance_m + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         nt_wt = tMins ~ NestAge * TempDiff + WindSpeed * Turbine_Distance_m + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         n.t_wt = tMins ~ NestAge + TempDiff + WindSpeed * Turbine_Distance_m + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         n.t_t_hm = tMins ~ NestAge + TempDiff + Turbine_Distance_m + Water_Distance_m * Jday + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         n.t_t_h.j = tMins ~ NestAge + TempDiff + Turbine_Distance_m + Water_Distance_m + Jday + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         whole = tMins ~ NestAge * TempDiff + VOR_AVG + WindSpeed * Turbine_Distance_m + Water_Distance_m + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         no.int = tMins ~ fYear + NestAge + TempDiff + VOR_AVG + WindSpeed + Turbine_Distance_m + Roads_Distance_m + Water_Distance_m + Jday + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                         global = tMins ~ fYear + NestAge * TempDiff + VOR_AVG + WindSpeed * Turbine_Distance_m + Roads_Distance_m + Water_Distance_m * Jday + ( 1 | fID ) + ( NestAge - 1 | fID ) )

# Fit the candidate models using the fit structure established in chunk:DURranef
dur.fixef_fits <- lapply( X = dur.fixef_forms, 
                          FUN = function( .ff ) lmer( .ff, 
                                                      data = csfullBouts, 
                                                      control = lmerControl( optimizer = "bobyqa", 
                                                                             optCtrl = list( maxfun = 2e4 ) ), 
                                                      REML = FALSE ) )

# For each model, calculate:
dur.fixef_aicc <- sapply( X = dur.fixef_fits, FUN = AICc ) # AICc
dur.fixef_delt <- dur.fixef_aicc - min( dur.fixef_aicc ) # DeltaAICc
dur.fixef_wgts <- exp( -0.5 * dur.fixef_delt ) # Akaike weight
dur.fixef_wgts <- dur.fixef_wgts / sum( dur.fixef_wgts )
dur.fixef_LL <- sapply( X = dur.fixef_fits, FUN = logLik )
dur.fixef_K <- sapply( X = dur.fixef_fits, FUN = function( .mm ) nobs( .mm ) - df.residual( .mm ) )
dur.fixef_FEs <- sapply( X = dur.fixef_fits, FUN = function( .mm ) fetch.FE( .mm ) ) # fixed-effects structure
dur.fixef_nFE <- sapply( X = dur.fixef_fits, FUN = function( .mm ) length( getME( .mm, "fixef" ) ) ) # number of fixed-effects parameters
dur.fixef_nRE <- sapply( X = dur.fixef_fits, FUN = function( .mm ) length( getME( .mm, "theta" ) ) ) # number of random-effects parameters

# Make a model selection table.
dur.fixef_selection <- data.frame( Model = names( dur.fixef_fits ), 
                                   FE = dur.fixef_FEs, 
                                   AICc = dur.fixef_aicc, 
                                   DeltaAICc = dur.fixef_delt, 
                                   AWt = dur.fixef_wgts, 
                                   LL = dur.fixef_LL, 
                                   K = dur.fixef_K, 
                                   nFE = dur.fixef_nFE, 
                                   nRE = dur.fixef_nRE )[ order( dur.fixef_delt ), ]

# Make an abbreviated model selection table.
dur.fixef_selection.abbrev <- dur.fixef_selection %>% 
  filter( DeltaAICc <= 10 )

# Pick the top model.
dur.mod_aicc <- update( dur.fixef_fits[[ which.min( dur.fixef_delt ) ]], 
                        REML = TRUE )

```

```{r DURpredictRnestAgeTrial, eval = FALSE, include = FALSE}

dur.predict_aicc.na <- expand.grid( NestAge = ( 0:28 - mean( fullBouts$NestAge, na.rm = TRUE ) ) / sd( fullBouts$NestAge, na.rm = TRUE ), 
                                    TempDiff = 0, 
                                    WindSpeed = 0 )

dur.predict_aicc.na <- dur.predict_aicc.na %>%
  mutate( .fitted = predict( dur.mod_aicc, 
                             newdata = dur.predict_aicc.na, re.form = ~0, 
                             type = "response" ), 
          NestAge_r = ( NestAge * sd( fullBouts$NestAge, na.rm = TRUE ) ) + mean( fullBouts$NestAge, na.rm = TRUE ), 
          TempDiff_r = mean( fullBouts$TempDiff, na.rm = TRUE ), 
          WindSpeed_r = mean( fullBouts$WindSpeed, na.rm = TRUE ), 
          .mu = exp( .fitted ) )

dur.predict_aicc.na.plot <- ggplot( data = dur.predict_aicc.na, 
                                    aes( x = NestAge_r, 
                                         y = .mu ) ) + 
  geom_line() + 
  theme_classic() + 
  labs( x = "Nest age (d)", 
        y = "Off-bout duration (min)" )

dur.predict_aicc.na.plot

```

```{r DURpredictRtempDiffTrial}

nd <- data.frame( TempDiff = ( seq( from = floor( min( fullBouts$TempDiff, na.rm = TRUE ) ), 
                                    to = ceiling( max( fullBouts$TempDiff, na.rm = TRUE ) ), 
                                    by = 0.5 ) - mean( fullBouts$TempDiff, na.rm = TRUE ) ) / sd( fullBouts$TempDiff, na.rm = TRUE ), 
                  WindSpeed = 0 )

dur.predict_aicc.boot.td <- bootMer( x = dur.mod_aicc, 
                                     FUN = boot.fitter, 
                                     nsim = 1000 )

dur.predict_aicc.boot.tdCI <- t( apply( X = dur.predict_aicc.boot.td$t, 
                                     MARGIN = 2, 
                                     FUN = quantile, 
                                     probs = c( 0.025, 0.975 ) ) )

dur.predict_aicc.td <- nd %>%
  mutate( .fitted = predict( dur.mod_aicc, 
                             newdata = nd, 
                             re.form = ~0, 
                             type = "response" ), 
          lo.95 = dur.predict_aicc.boot.tdCI[ , 1 ],
          hi.95 = dur.predict_aicc.boot.tdCI[ , 2 ],
          TempDiff_r = ( TempDiff * sd( fullBouts$TempDiff, na.rm = TRUE ) ) + mean( fullBouts$TempDiff, na.rm = TRUE ), 
          WindSpeed_r = ( WindSpeed * sd( fullBouts$WindSpeed, na.rm = TRUE ) ) + mean( fullBouts$WindSpeed, na.rm = TRUE ), 
          .mu = exp( .fitted ), 
          lo.95_r = exp( lo.95 ), 
          hi.95_r = exp( hi.95 ) )

dur.predict_aicc.td.plot <- ggplot( data = dur.predict_aicc.td, 
                                    aes( x = TempDiff_r, 
                                         y = .mu ) ) + 
  geom_ribbon( aes( ymin = lo.95_r, 
                    ymax = hi.95_r ), 
               alpha = 0.4 ) + 
  geom_line() + 
  # geom_point( data = fullBouts,
  #             inherit.aes = FALSE,
  #             aes( x = TempDiff,
  #                  y = Mins ),
  #             alpha = 0.4 ) +
  theme_classic() + 
  labs( x = "Temperature difference (°C)", 
        y = "Off-bout duration (min)" ) + 
  theme( text = element_text( size = 12 ) ) + 
  scale_x_continuous( breaks = seq( -5, 20, by = 5 ) ) + 
  scale_y_continuous( breaks = seq( 25, 60, by = 5 ) )

dur.predict_aicc.td.plot

# ggsave( "dur_temp.pred.pdf", plot = dur.predict_aicc.td.plot, device = "pdf", path = "figures/", 
#         width = 15, height = 15, units = "cm" )

```

```{r DURpredictRwindSpeedTrial}

nd <- data.frame( TempDiff = 0, 
                  WindSpeed = ( seq( from = floor( min( fullBouts$WindSpeed, na.rm = TRUE ) ), 
                                     to = ceiling( max( fullBouts$WindSpeed, na.rm = TRUE ) ), 
                                     by = 0.5 ) - mean( fullBouts$WindSpeed, na.rm = TRUE ) ) / sd( fullBouts$WindSpeed, na.rm = TRUE ) )

dur.predict_aicc.boot.ws <- bootMer( x = dur.mod_aicc, 
                                     FUN = boot.fitter, 
                                     nsim = 1000 )

dur.predict_aicc.boot.wsCI <- t( apply( X = dur.predict_aicc.boot.ws$t, 
                                     MARGIN = 2, 
                                     FUN = quantile, 
                                     probs = c( 0.025, 0.975 ) ) )

dur.predict_aicc.ws <- nd %>%
  mutate( .fitted = predict( dur.mod_aicc, 
                             newdata = nd, 
                             re.form = ~0, 
                             type = "response" ), 
          lo.95 = dur.predict_aicc.boot.wsCI[ , 1 ],
          hi.95 = dur.predict_aicc.boot.wsCI[ , 2 ],
          TempDiff_r = ( TempDiff * sd( fullBouts$TempDiff, na.rm = TRUE ) ) + mean( fullBouts$TempDiff, na.rm = TRUE ), 
          WindSpeed_r = ( WindSpeed * sd( fullBouts$WindSpeed, na.rm = TRUE ) ) + mean( fullBouts$WindSpeed, na.rm = TRUE ), 
          .mu = exp( .fitted ), 
          lo.95_r = exp( lo.95 ), 
          hi.95_r = exp( hi.95 ) )

dur.predict_aicc.ws.plot <- ggplot( data = dur.predict_aicc.ws, 
                                    aes( x = WindSpeed_r, 
                                         y = .mu ) ) + 
  geom_ribbon( aes( ymin = lo.95_r,
                    ymax = hi.95_r ),
               alpha = 0.4 ) +
  geom_line() + 
  # geom_point( data = fullBouts,
  #             inherit.aes = FALSE,
  #             aes( x = WindSpeed,
  #                  y = Mins ),
  #             alpha = 0.4 ) +
  theme_classic() + 
  labs( x = "Wind speed (mph)", 
        y = "Off-bout duration (min)" ) + 
  theme( text = element_text( size = 12 ) ) + 
  scale_x_continuous( breaks = seq( 0, 31, by = 5 ) ) + 
  scale_y_continuous( breaks = seq( 25, 45, by = 5 ) )

dur.predict_aicc.ws.plot

# ggsave( "dur_wind.pred.pdf", plot = dur.predict_aicc.ws.plot, device = "pdf", path = "figures/",
#         width = 15, height = 15, units = "cm" )

```

-----

```{r DURfixefSelection, eval = FALSE, include = FALSE}

# ## ITERATION 1: ##
# 
# dur.fixef <- lmerTest::lmer( tMins ~ fYear + NestAge * TempDiff + VOR_AVG + WindSpeed * Turbine_Distance_m + Roads_Distance_m + Water_Distance_m * Jday + ( 1 | fID ) + ( NestAge - 1 | fID ),
#                              data = csfullBouts,
#                              control = lmerControl( optimizer = "Nelder_Mead",
#                                                     optCtrl = list( maxfun = 2e4 ) ),
#                              REML = FALSE )
# 
# lmerTest::summary( dur.fixef ) # least significant term: VOR_AVG (p=0.982374)

# ## ITERATION 2: ##
# 
# dur.fixef <- lmerTest::lmer( tMins ~ fYear + NestAge * TempDiff + WindSpeed * Turbine_Distance_m + Roads_Distance_m + Water_Distance_m * Jday + ( 1 | fID ) + ( NestAge - 1 | fID ),
#                              data = csfullBouts,
#                              control = lmerControl( optimizer = "Nelder_Mead",
#                                                     optCtrl = list( maxfun = 2e4 ) ),
#                              REML = FALSE )
# 
# lmerTest::summary( dur.fixef ) # least significant term: Water_Display_m:Jday (p=0.85356)

# ## ITERATION 3: ##
# 
# dur.fixef <- lmerTest::lmer( tMins ~ fYear + NestAge * TempDiff + WindSpeed * Turbine_Distance_m + Roads_Distance_m + Water_Distance_m + Jday + ( 1 | fID ) + ( NestAge - 1 | fID ),
#                              data = csfullBouts,
#                              control = lmerControl( optimizer = "Nelder_Mead",
#                                                     optCtrl = list( maxfun = 2e4 ) ),
#                              REML = FALSE )
# 
# lmerTest::summary( dur.fixef ) # least significant term: Jday (p=0.84101)

# ## ITERATION 4: ##
# 
# dur.fixef <- lmerTest::lmer( tMins ~ fYear + NestAge * TempDiff + WindSpeed * Turbine_Distance_m + Roads_Distance_m + Water_Distance_m + ( 1 | fID ) + ( NestAge - 1 | fID ),
#                              data = csfullBouts,
#                              control = lmerControl( optimizer = "Nelder_Mead",
#                                                     optCtrl = list( maxfun = 2e4 ) ),
#                              REML = FALSE )
# 
# lmerTest::summary( dur.fixef ) # least significant term: WindSpeed:Turbine_Distance_m (p=0.54062)

# ## ITERATION 5: ##
# 
# dur.fixef <- lmerTest::lmer( tMins ~ fYear + NestAge * TempDiff + WindSpeed + Turbine_Distance_m + Roads_Distance_m + Water_Distance_m + ( 1 | fID ) + ( NestAge - 1 | fID ),
#                              data = csfullBouts,
#                              control = lmerControl( optimizer = "Nelder_Mead",
#                                                     optCtrl = list( maxfun = 2e4 ) ),
#                              REML = FALSE )
# 
# lmerTest::summary( dur.fixef ) # least significant term: fYear (p=0.26574)

# ## ITERATION 6: ##
# 
# dur.fixef <- lmerTest::lmer( tMins ~ NestAge * TempDiff + WindSpeed + Turbine_Distance_m + Roads_Distance_m + Water_Distance_m + ( 1 | fID ) + ( NestAge - 1 | fID ),
#                              data = csfullBouts,
#                              control = lmerControl( optimizer = "Nelder_Mead",
#                                                     optCtrl = list( maxfun = 2e4 ) ),
#                              REML = FALSE )
# 
# lmerTest::summary( dur.fixef ) # least significant term: Water_Distance_m (p=0.35557)

# ## ITERATION 7: ##
# 
# dur.fixef <- lmerTest::lmer( tMins ~ NestAge * TempDiff + WindSpeed + Turbine_Distance_m + Roads_Distance_m + ( 1 | fID ) + ( NestAge - 1 | fID ),
#                              data = csfullBouts,
#                              control = lmerControl( optimizer = "Nelder_Mead",
#                                                     optCtrl = list( maxfun = 2e4 ) ),
#                              REML = FALSE )
# 
# lmerTest::summary( dur.fixef ) # least significant term: NestAge:TempDiff (p=0.25279)

# ## ITERATION 8: ##
# 
# dur.fixef <- lmerTest::lmer( tMins ~ NestAge + TempDiff + WindSpeed + Turbine_Distance_m + Roads_Distance_m + ( 1 | fID ) + ( NestAge - 1 | fID ),
#                              data = csfullBouts,
#                              control = lmerControl( optimizer = "Nelder_Mead",
#                                                     optCtrl = list( maxfun = 2e4 ) ),
#                              REML = FALSE )
# 
# lmerTest::summary( dur.fixef ) # least significant term: Turbine_Distance_m (p=0.173862)

# ## ITERATION 9: ##
# 
# dur.fixef <- lmerTest::lmer( tMins ~ NestAge + TempDiff + WindSpeed + Roads_Distance_m + ( 1 | fID ) + ( NestAge - 1 | fID ),
#                              data = csfullBouts,
#                              control = lmerControl( optimizer = "Nelder_Mead",
#                                                     optCtrl = list( maxfun = 2e4 ) ),
#                              REML = FALSE )
# 
# lmerTest::summary( dur.fixef ) # least significant term: NestAge (p=0.147815)

# ## ITERATION 10: ##
# 
# dur.fixef <- lmerTest::lmer( tMins ~ TempDiff + WindSpeed + Roads_Distance_m + ( 1 | fID ) + ( NestAge - 1 | fID ),
#                              data = csfullBouts,
#                              control = lmerControl( optimizer = "Nelder_Mead",
#                                                     optCtrl = list( maxfun = 2e4 ) ),
#                              REML = FALSE )
# 
# lmerTest::summary( dur.fixef ) # least significant term: Roads_Distance_m (p=0.115303)

# ## ITERATION 11: ##
# 
dur.fixef <- lmerTest::lmer( tMins ~ TempDiff + WindSpeed + ( 1 | fID ) + ( NestAge - 1 | fID ),
                             data = csfullBouts,
                             control = lmerControl( optimizer = "Nelder_Mead",
                                                    optCtrl = list( maxfun = 2e4 ) ),
                             REML = FALSE )
# 
# lmerTest::summary( dur.fixef ) # least significant term: WindSpeed (p=0.009488)

dur.mod_be <- update( dur.fixef, REML = TRUE )

```

```{r DURpredictRnestAge, eval = FALSE, include = FALSE}

dur.predict_na <- expand.grid( NestAge = ( 0:28 - mean( fullBouts$NestAge, na.rm = TRUE ) ) / sd( fullBouts$NestAge, na.rm = TRUE ), 
                               TempDiff = 0, 
                               WindSpeed = 0 )

dur.predict_na <- dur.predict_na %>%
  mutate( .fitted = predict( dur.mod_be, 
                             newdata = dur.predict_na, re.form = ~0, 
                             type = "response" ), 
          NestAge_r = ( NestAge * sd( fullBouts$NestAge, na.rm = TRUE ) ) + mean( fullBouts$NestAge, na.rm = TRUE ), 
          TempDiff_r = mean( fullBouts$TempDiff, na.rm = TRUE ), 
          WindSpeed_r = mean( fullBouts$WindSpeed, na.rm = TRUE ), 
          .mu = exp( .fitted ) )

dur.predict_na.plot <- ggplot( data = dur.predict_na, 
                               aes( x = NestAge_r, 
                                    y = .mu ) ) + 
  geom_line() + 
  theme_classic() + 
  labs( x = "Nest age (d)", 
        y = "Off-bout duration (min)" )

dur.predict_na.plot

```

```{r DURpredictRtempDiff, eval = FALSE, include = FALSE}

nd <- data.frame( TempDiff = ( seq( from = floor( min( fullBouts$TempDiff, na.rm = TRUE ) ), 
                                    to = ceiling( max( fullBouts$TempDiff, na.rm = TRUE ) ), 
                                    by = 0.5 ) - mean( fullBouts$TempDiff, na.rm = TRUE ) ) / sd( fullBouts$TempDiff, na.rm = TRUE ), 
                  WindSpeed = 0 )

dur.predict_boot <- bootMer( x = dur.mod_be, 
                             FUN = boot.fitter, 
                             nsim = 1000 )

dur.predict_bootCI <- t( apply( X = dur.predict_boot$t, 
                                MARGIN = 2, 
                                FUN = quantile, 
                                probs = c( 0.025, 0.975 ) ) )

dur.predict_td <- nd %>%
  mutate( .fitted = predict( dur.mod_be, 
                             newdata = nd, 
                             re.form = ~0, 
                             type = "response" ), 
          lo.95 = dur.predict_bootCI[ , 1 ],
          hi.95 = dur.predict_bootCI[ , 2 ],
          TempDiff_r = ( TempDiff * sd( fullBouts$TempDiff, na.rm = TRUE ) ) + mean( fullBouts$TempDiff, na.rm = TRUE ), 
          WindSpeed_r = ( WindSpeed * sd( fullBouts$WindSpeed, na.rm = TRUE ) ) + mean( fullBouts$WindSpeed, na.rm = TRUE ), 
          .mu = exp( .fitted ), 
          lo.95_r = exp( lo.95 ), 
          hi.95_r = exp( hi.95 ) )

dur.predict_td.plot <- ggplot( data = dur.predict_td, 
                               aes( x = TempDiff_r, 
                                    y = .mu ) ) + 
  geom_ribbon( aes( ymin = lo.95_r, 
                    ymax = hi.95_r ), 
               alpha = 0.4 ) + 
  geom_line() + 
  geom_point( data = fullBouts, 
              inherit.aes = FALSE, 
              aes( x = TempDiff, 
                   y = Mins ), 
              alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Temperature difference (°C)", 
        y = "Off-bout duration (min)" )

dur.predict_td.plot

```

```{r DURpredictRwindSpeed, eval = FALSE, include = FALSE}

nd <- data.frame( TempDiff = 0, 
                  WindSpeed = ( seq( from = floor( min( fullBouts$WindSpeed, na.rm = TRUE ) ), 
                                    to = ceiling( max( fullBouts$WindSpeed, na.rm = TRUE ) ), 
                                    by = 0.5 ) - mean( fullBouts$WindSpeed, na.rm = TRUE ) ) / sd( fullBouts$WindSpeed, na.rm = TRUE ) )

dur.predict_boot <- bootMer( x = dur.mod_be, 
                             FUN = boot.fitter, 
                             nsim = 1000 )

dur.predict_bootCI <- t( apply( X = dur.predict_boot$t, 
                                MARGIN = 2, 
                                FUN = quantile, 
                                probs = c( 0.025, 0.975 ) ) )

dur.predict_ws <- nd %>%
  mutate( .fitted = predict( dur.mod_be, 
                             newdata = nd, 
                             re.form = ~0, 
                             type = "response" ), 
          lo.95 = dur.predict_bootCI[ , 1 ],
          hi.95 = dur.predict_bootCI[ , 2 ],
          TempDiff_r = ( TempDiff * sd( fullBouts$TempDiff, na.rm = TRUE ) ) + mean( fullBouts$TempDiff, na.rm = TRUE ), 
          WindSpeed_r = ( WindSpeed * sd( fullBouts$WindSpeed, na.rm = TRUE ) ) + mean( fullBouts$WindSpeed, na.rm = TRUE ), 
          .mu = exp( .fitted ), 
          lo.95_r = exp( lo.95 ), 
          hi.95_r = exp( hi.95 ) )

dur.predict_ws.plot <- ggplot( data = dur.predict_ws, 
                               aes( x = WindSpeed_r, 
                                    y = .mu ) ) + 
  geom_ribbon( aes( ymin = lo.95_r,
                    ymax = hi.95_r ),
               alpha = 0.4 ) +
  geom_line() + 
  geom_point( data = fullBouts, 
              inherit.aes = FALSE, 
              aes( x = WindSpeed, 
                   y = Mins ), 
              alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Wind speed (mph)", 
        y = "Off-bout duration (min)" )

dur.predict_ws.plot

```

-----

```{r DURfixefAICcSets, eval = FALSE, include = FALSE}

distTerms <- c( "Turbine_Distance_m", "Roads_Distance_m", "Water_Distance_m", "Trees_Distance_m" )
envrTerms <- c( "VOR_AVG", "TempDiff", "WindSpeed" )
timeTerms <- c( "fYear", "NestAge", "Jday" )
ranefTerms <- c( "( 1 | fID )", "( NestAge - 1 | fID )" )

dur.fixef_forms.set <- list( int = tMins ~ 1 + ( 1 | fID ) + ( NestAge - 1 | fID ), 
                             dist = reformulate( c( distTerms, ranefTerms ), "tMins"), 
                             env = reformulate( c( envrTerms, ranefTerms ), "tMins"), 
                             time = reformulate( c( timeTerms, ranefTerms ), "tMins"), 
                             de = reformulate( c( distTerms, envrTerms, ranefTerms ), "tMins"), 
                             dt = reformulate( c( distTerms, timeTerms, ranefTerms ), "tMins"), 
                             et = reformulate( c( envrTerms, timeTerms, ranefTerms ), "tMins"), 
                             det = reformulate( c( distTerms, envrTerms, timeTerms, ranefTerms ), "tMins") )

dur.fixef_fits.set <- lapply( X = dur.fixef_forms.set, 
                             FUN = function( .ff ) lmer( .ff, 
                                                         data = csfullBouts, 
                                                         control = lmerControl( optimizer = "Nelder_Mead", 
                                                                                optCtrl = list( maxfun = 2e4 ) ), 
                                                         REML = FALSE ) )

dur.fixef_aicc.set <- sapply( X = dur.fixef_fits.set, FUN = AICc )
dur.fixef_delt.set <- dur.fixef_aicc.set - min( dur.fixef_aicc.set )
dur.fixef_wgts.set <- exp( -0.5 * dur.fixef_delt.set )
dur.fixef_wgts.set <- dur.fixef_wgts.set / sum( dur.fixef_wgts.set )
dur.fixef_FEs.set <- sapply( X = dur.fixef_fits.set, FUN = function( .mm ) fetch.FE( .mm ) )
dur.fixef_nFE.set <- sapply( X = dur.fixef_fits.set, FUN = function( .mm ) length( getME( .mm, "fixef" ) ) )
dur.fixef_nRE.set <- sapply( X = dur.fixef_fits.set, FUN = function( .mm ) length( getME( .mm, "theta" ) ) )

dur.fixef_selection.set <- data.frame( Model = names( dur.fixef_fits.set ), 
                                       FE = dur.fixef_FEs.set, 
                                       AICc = dur.fixef_aicc.set, 
                                       DeltaAICc = dur.fixef_delt.set, 
                                       AWt = dur.fixef_wgts.set, 
                                       nFE = dur.fixef_nFE.set, 
                                       nRE = dur.fixef_nRE.set )[ order( dur.fixef_delt.set ), ]

```

```{r DURfixefAvgR, eval = FALSE, include = FALSE}

dur.fixef_ests <- map2_df( .x = dur.fixef_fits.set, 
                           .y = names( dur.fixef_fits.set ), 
                           .f = tidy_w_name ) %>% 
  complete( term, name ) %>% 
  left_join( dur.fixef_selection.set[ , c( "Model", "AWt" ) ], by = c( "name" = "Model" ) )

dur.fixef_ests[ is.na( dur.fixef_ests$estimate ), c( "estimate", "std.error" ) ] <- 0

dur.fixef_ests <- dur.fixef_ests %>%
  group_by( term ) %>%
  mutate( wnorm = AWt / sum( AWt ),
          var_est = std.error^2 ) %>%
  summarize( avg_est = sum( estimate * wnorm ),
             avg_var = sum( wnorm * ( var_est + ( estimate - avg_est )^2 ) ), 
             avg_SE = sqrt( avg_var ), 
             tstat = avg_est / avg_SE, 
             p.val = 2 * pt( q = abs( tstat ), 
                             df = min( sapply( X = dur.fixef_fits.set, 
                                               FUN = df.residual ) ), 
                             lower.tail = FALSE ) )

```

```{r DURfixefAvgPredictRtempDiff, eval = FALSE, include = FALSE}

nd <- data.frame( TempDiff = ( seq( from = floor( min( fullBouts$TempDiff, na.rm = TRUE ) ), 
                                    to = ceiling( max( fullBouts$TempDiff, na.rm = TRUE ) ), 
                                    by = 0.5 ) - mean( fullBouts$TempDiff, na.rm = TRUE ) ) / sd( fullBouts$TempDiff, na.rm = TRUE ), 
                  WindSpeed = 0, 
                  fYear = factor( 2014, levels = levels( fullBouts$fYear ) ), 
                  Jday = 0, 
                  NestAge = 0, 
                  Roads_Distance_m = 0, 
                  Trees_Distance_m = 0, 
                  Turbine_Distance_m = 0, 
                  Water_Distance_m = 0, 
                  VOR_AVG = 0 )

dur.avg_pred.td <- AICcmodavg::modavgPred( cand.set = dur.fixef_fits.set, 
                                           newdata = nd )
dur.avg_pred.td <- nd %>% 
  mutate( .fitted = dur.avg_pred.td$mod.avg.pred, 
          uncond.se = dur.avg_pred.td$uncond.se, 
          hi.95 = dur.avg_pred.td$upper.CL, 
          lo.95 = .fitted - ( hi.95 - .fitted ), 
          TempDiff = seq( from = floor( min( fullBouts$TempDiff, na.rm = TRUE ) ), 
                                    to = ceiling( max( fullBouts$TempDiff, na.rm = TRUE ) ), 
                                    by = 0.5 ), 
          WindSpeed = mean( fullBouts$WindSpeed, na.rm = TRUE ), 
          Jday = mean( fullBouts$Jday, na.rm = TRUE ), 
          NestAge = mean( fullBouts$NestAge, na.rm = TRUE ), 
          Roads_Distance_m = mean( fullBouts$Roads_Distance_m, na.rm = TRUE ), 
          Trees_Distance_m = mean( fullBouts$Trees_Distance_m, na.rm = TRUE ), 
          Turbine_Distance_m = mean( fullBouts$Turbine_Distance_m, na.rm = TRUE ), 
          Water_Distance_m = mean( fullBouts$Water_Distance_m, na.rm = TRUE ), 
          VOR_AVG = mean( fullBouts$VOR_AVG, na.rm = TRUE ), 
          .mu = exp( .fitted ), 
          hi.95_r = exp( hi.95 ), 
          lo.95_r = exp( lo.95 ) )

dur.avg_pred.td.plot <- ggplot( data = dur.avg_pred.td, 
                                aes( x = TempDiff, 
                                     y = .mu ) ) + 
  geom_ribbon( aes( ymin = lo.95_r, 
                    ymax = hi.95_r ), 
               alpha = 0.4 ) + 
  geom_line() + 
  geom_point( data = fullBouts, 
              inherit.aes = FALSE, 
              aes( x = TempDiff, 
                   y = Mins ), 
              alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Temperature difference (°C)", 
        y = "Off-bout duration (min)" )

dur.avg_pred.td.plot

```

```{r DURfixefAvgPredictRwindSpeed, eval = FALSE, include = FALSE}

nd <- data.frame( TempDiff = 0, 
                  WindSpeed = ( seq( from = floor( min( fullBouts$WindSpeed, na.rm = TRUE ) ), 
                                     to = ceiling( max( fullBouts$WindSpeed, na.rm = TRUE ) ), 
                                     by = 0.5 ) - mean( fullBouts$WindSpeed, na.rm = TRUE ) ) / sd( fullBouts$WindSpeed, na.rm = TRUE ), 
                  fYear = factor( 2014, levels = levels( fullBouts$fYear ) ), 
                  Jday = 0, 
                  NestAge = 0, 
                  Roads_Distance_m = 0, 
                  Trees_Distance_m = 0, 
                  Turbine_Distance_m = 0, 
                  Water_Distance_m = 0, 
                  VOR_AVG = 0 )

dur.avg_pred.ws <- AICcmodavg::modavgPred( cand.set = dur.fixef_fits.set, 
                                           newdata = nd )
dur.avg_pred.ws <- nd %>% 
  mutate( .fitted = dur.avg_pred.ws$mod.avg.pred, 
          uncond.se = dur.avg_pred.ws$uncond.se, 
          hi.95 = dur.avg_pred.ws$upper.CL, 
          lo.95 = .fitted - ( hi.95 - .fitted ), 
          TempDiff = mean( fullBouts$TempDiff, na.rm = TRUE ), 
          WindSpeed = seq( from = floor( min( fullBouts$WindSpeed, na.rm = TRUE ) ), 
                           to = ceiling( max( fullBouts$WindSpeed, na.rm = TRUE ) ), 
                           by = 0.5 ), 
          Jday = mean( fullBouts$Jday, na.rm = TRUE ), 
          NestAge = mean( fullBouts$NestAge, na.rm = TRUE ), 
          Roads_Distance_m = mean( fullBouts$Roads_Distance_m, na.rm = TRUE ), 
          Trees_Distance_m = mean( fullBouts$Trees_Distance_m, na.rm = TRUE ), 
          Turbine_Distance_m = mean( fullBouts$Turbine_Distance_m, na.rm = TRUE ), 
          Water_Distance_m = mean( fullBouts$Water_Distance_m, na.rm = TRUE ), 
          VOR_AVG = mean( fullBouts$VOR_AVG, na.rm = TRUE ), 
          .mu = exp( .fitted ), 
          hi.95_r = exp( hi.95 ), 
          lo.95_r = exp( lo.95 ) )

dur.avg_pred.ws.plot <- ggplot( data = dur.avg_pred.ws, 
                                aes( x = WindSpeed, 
                                     y = .mu ) ) + 
  geom_ribbon( aes( ymin = lo.95_r, 
                    ymax = hi.95_r ), 
               alpha = 0.4 ) + 
  geom_line() + 
  geom_point( data = fullBouts, 
              inherit.aes = FALSE, 
              aes( x = WindSpeed, 
                   y = Mins ), 
              alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Wind speed (mph)", 
        y = "Off-bout duration (min)" )

dur.avg_pred.ws.plot

```

-----

*Off-bout frequency*.—

```{r FREQranef}

# removing AmbientTemp, Precipitation, and WindSpeed (all have sig. corr. w/ blockID)
globalBoutsMod <- "numBouts ~ fYear + NestAge + VOR_AVG + Turbine_Distance_m * blockID + Roads_Distance_m + Water_Distance_m * Jday"

freqData.preserve <- freqData
freqData$numBouts <- ifelse( freqData$numBouts >= 1, 1, 0 )

freq.ranef_forms <- list( int = as.formula( paste( globalBoutsMod, " + ( 1 | fID )", sep = "" ) ), 
                          year = as.formula( paste( globalBoutsMod, " + ( fYear - 1 | fID )", sep = "" ) ), 
                          year.int = as.formula( paste( globalBoutsMod, " + ( fYear | fID )", sep = "" ) ), 
                          year_int = as.formula( paste( globalBoutsMod, " + ( 1 | fID ) + ( fYear - 1 | fID )", sep = "" ) ), 
                          age = as.formula( paste( globalBoutsMod, " + ( NestAge - 1 | fID )", sep = "" ) ), 
                          age.int = as.formula( paste( globalBoutsMod, " + ( NestAge | fID )", sep = "" ) ), 
                          age_int = as.formula( paste( globalBoutsMod, " + ( 1 | fID ) + ( NestAge - 1 | fID )", sep = "" ) ), 
                          # age.temp = as.formula( paste( globalBoutsMod, " + ( NestAge * AmbientTemp - 1 | fID )", sep = "" ) ), 
                          # age.temp.int = as.formula( paste( globalBoutsMod, " + ( NestAge * AmbientTemp | fID )", sep = "" ) ), 
                          # age.temp_int = as.formula( paste( globalBoutsMod, " + ( 1 | fID ) + ( NestAge * AmbientTemp - 1 | fID )", sep = "" ) ), 
                          # temp = as.formula( paste( globalBoutsMod, " + ( AmbientTemp - 1 | fID )", sep = "" ) ), 
                          # temp.int = as.formula( paste( globalBoutsMod, " + ( AmbientTemp | fID )", sep = "" ) ), 
                          # temp_int = as.formula( paste( globalBoutsMod, " + ( 1 | fID ) + ( AmbientTemp - 1 | fID )", sep = "" ) ), 
                          # precip = as.formula( paste( globalBoutsMod, " + ( Precipitation - 1 | fID )", sep = "" ) ), 
                          # precip.int = as.formula( paste( globalBoutsMod, " + ( Precipitation | fID )", sep = "" ) ), 
                          # precip_int = as.formula( paste( globalBoutsMod, " + ( 1 | fID ) + ( Precipitation - 1 | fID )", sep = "" ) ), 
                          vor = as.formula( paste( globalBoutsMod, " + ( VOR_AVG - 1 | fID )", sep = "" ) ), 
                          vor.int = as.formula( paste( globalBoutsMod, " + ( VOR_AVG | fID )", sep = "" ) ), 
                          vor_int = as.formula( paste( globalBoutsMod, " + ( 1 | fID ) + ( VOR_AVG - 1 | fID )", sep = "" ) ), 
                          # wind = as.formula( paste( globalBoutsMod, " + ( WindSpeed - 1 | fID )", sep = "" ) ), 
                          # wind.int = as.formula( paste( globalBoutsMod, " + ( WindSpeed | fID )", sep = "" ) ), 
                          # wind_int = as.formula( paste( globalBoutsMod, " + ( 1 | fID ) + ( WindSpeed - 1 | fID )", sep = "" ) ), 
                          turb = as.formula( paste( globalBoutsMod, " + ( Turbine_Distance_m - 1 | fID )", sep = "" ) ), 
                          turb.int = as.formula( paste( globalBoutsMod, " + ( Turbine_Distance_m | fID )", sep = "" ) ), 
                          turb_int = as.formula( paste( globalBoutsMod, " + ( 1 | fID ) + ( Turbine_Distance_m - 1 | fID )", sep = "" ) ), 
                          blck = as.formula( paste( globalBoutsMod, " + ( blockID - 1 | fID )", sep = "" ) ), 
                          blck.int = as.formula( paste( globalBoutsMod, " + ( blockID | fID )", sep = "" ) ), 
                          blck_int = as.formula( paste( globalBoutsMod, " + ( 1 | fID ) + ( blockID - 1 | fID )", sep = "" ) ), 
                          road = as.formula( paste( globalBoutsMod, " + ( Roads_Distance_m - 1 | fID )", sep = "" ) ), 
                          road.int = as.formula( paste( globalBoutsMod, " + ( Roads_Distance_m | fID )", sep = "" ) ), 
                          road_int = as.formula( paste( globalBoutsMod, " + ( 1 | fID ) + ( Roads_Distance_m - 1 | fID )", sep = "" ) ), 
                          h2o = as.formula( paste( globalBoutsMod, " + ( Water_Distance_m - 1 | fID )", sep = "" ) ), 
                          h2o.int = as.formula( paste( globalBoutsMod, " + ( Water_Distance_m | fID )", sep = "" ) ), 
                          h2o_int = as.formula( paste( globalBoutsMod, " + ( 1 | fID ) + ( Water_Distance_m - 1 | fID )", sep = "" ) ), 
                          # h2o.Jday = as.formula( paste( globalBoutsMod, " + ( Water_Distance_m * Jday - 1 | fID )", sep = "" ) ), 
                          # h2o.Jday.int = as.formula( paste( globalBoutsMod, " + ( Water_Distance_m * Jday | fID )", sep = "" ) ),
                          # h2o.Jday_int = as.formula( paste( globalBoutsMod, " + ( 1 | fID ) + ( Water_Distance_m * Jday - 1 | fID )", sep = "" ) ),
                          Jday = as.formula( paste( globalBoutsMod, " + ( Jday - 1 | fID )", sep = "" ) ), 
                          Jday.int = as.formula( paste( globalBoutsMod, " + ( Jday | fID )", sep = "" ) ), 
                          Jday_int = as.formula( paste( globalBoutsMod, " + ( 1 | fID ) + ( Jday - 1 | fID )", sep = "" ) ) )

# # Throws a fatal error: "Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate" Also 4 convergence warnings; consider scaling.
# freq.ranef <- lapply( X = freq.ranef_forms,
#                       FUN = function( .ff ) glmer( .ff,
#                                                    data = freqData,
#                                                    family = binomial( link = "logit" ) ) )

csFreqData <- freqData %>% 
  mutate( Mins = ( Mins - mean( Mins, na.rm = TRUE ) ) / sd( Mins, na.rm = TRUE ), 
          AmbientTemp = ( AmbientTemp - mean( AmbientTemp, na.rm = TRUE ) ) / sd( AmbientTemp, na.rm = TRUE ), 
          WindSpeed = ( WindSpeed - mean( WindSpeed, na.rm = TRUE ) ) / sd( WindSpeed, na.rm = TRUE ), 
          AirPressure = ( AirPressure - mean( AirPressure, na.rm = TRUE ) ) / sd( AirPressure, na.rm = TRUE ), 
          Precipitation = ( Precipitation - mean( Precipitation, na.rm = TRUE ) ) / sd( Precipitation, na.rm = TRUE ), 
          VPD = ( VPD - mean( VPD, na.rm = TRUE ) ) / sd( VPD, na.rm = TRUE ), 
          Jday = ( Jday - mean( Jday, na.rm = TRUE ) ) / sd( Jday, na.rm = TRUE ), 
          NestAge = ( NestAge - mean( NestAge, na.rm = TRUE ) ) / sd( NestAge, na.rm = TRUE ), 
          Turbine_Distance_m = ( Turbine_Distance_m - mean( Turbine_Distance_m, na.rm = TRUE ) ) / sd( Turbine_Distance_m, na.rm = TRUE ), 
          Roads_Distance_m = ( Roads_Distance_m - mean( Roads_Distance_m, na.rm = TRUE ) ) / sd( Roads_Distance_m, na.rm = TRUE ), 
          Trees_Distance_m = ( Trees_Distance_m - mean( Trees_Distance_m, na.rm = TRUE ) ) / sd( Trees_Distance_m, na.rm = TRUE ), 
          Water_Distance_m = ( Water_Distance_m - mean( Water_Distance_m, na.rm = TRUE ) ) / sd( Water_Distance_m, na.rm = TRUE ), 
          VOR_AVG = ( VOR_AVG - mean( VOR_AVG, na.rm = TRUE ) ) / sd( VOR_AVG, na.rm = TRUE ) )
contrasts( csFreqData$blockID ) <- contr.sum( length( levels( csFreqData$blockID ) ) )

# freq.ranef_cs <- lapply( X = freq.ranef_forms,
#                          FUN = function( .ff ) glmer( .ff,
#                                                       data = csFreqData,
#                                                       family = binomial( link = "logit" ) ) )
# 
# # CC <- convCheckR( freq.ranef_cs ) # 12 warnings
# # UnID        : NONE!
# # LargeMaxGrad: turb.int, all blck
# # LargeParGrad: turb.int, all blck
# # Singular    : 20/25

if( !exists( "freq.ranef_cs.plus.bobyqa" ) ){
  
  if( length( fl <- list.files( pattern = "freq.ranef_cs.plus.bobyqa.RData", recursive = TRUE ) ) > 0 ){
    load( fl )
  } else {
    # Okay. Try the bobyqa optimizer.
    freq.ranef_cs.plus.bobyqa <- lapply( X = freq.ranef_forms, 
                                         FUN = function( .ff ) glmer( .ff, 
                                                                      data = csFreqData, 
                                                                      family = binomial( link = "logit" ), 
                                                                      control = glmerControl( optimizer = "bobyqa", 
                                                                                              optCtrl = list( maxfun = 2e4 ) ) ) )
    save( freq.ranef_cs.plus.bobyqa, file = "data/freq.ranef_cs.plus.bobyqa.RData" )
  }
}

# CC <- convCheckR( freq.ranef_cs.plus.bobyqa ) # 3 warnings
# UnID        : NONE!
# LargeMaxGrad: NONE!
# LargeParGrad: NONE!
# Singular    : all :(

# freq.ranef_cs.plus.neldermead <- lapply( X = freq.ranef_forms, 
#                                          FUN = function( .ff ) glmer( .ff, 
#                                                                       data = csFreqData, 
#                                                                       family = binomial( link = "logit" ), 
#                                                                       control = glmerControl( optimizer = "Nelder_Mead", 
#                                                                                               optCtrl = list( maxfun = 2e4 ) ) ) )
# 
# # CC <- convCheckR( freq.ranef_cs.plus.neldermead ) # 24 warnings in 8 hours
# # UnID        : NONE!
# # LargeMaxGrad: all temp, all vor, turb, turb_int, all blck
# # LargeParGrad: all temp, all vor, turb, turb_int, all blck
# # Singular    : a slew (but not all)

freq.ranef_fit <- freq.ranef_cs.plus.bobyqa

```

```{r FREQranefSelection}

freq.ranef_aicc <- sapply( X = freq.ranef_fit, FUN = AICc )
freq.ranef_delt <- freq.ranef_aicc - min( freq.ranef_aicc )
freq.ranef_wgts <- exp( -0.5 * freq.ranef_delt )
freq.ranef_wgts <- freq.ranef_wgts / sum( freq.ranef_wgts )
freq.ranef_LL <- sapply( X = freq.ranef_fit, FUN = logLik )
freq.ranef_K <- sapply( X = freq.ranef_fit, FUN = function( .mm ) nobs( .mm ) - df.residual( .mm ) )
freq.ranef_REs <- sapply( X = freq.ranef_fit, FUN = function( .mm ) fetch.RE( .mm, as.form = TRUE ) )
freq.ranef_nFE <- sapply( X = freq.ranef_fit, FUN = function( .mm ) length( getME( .mm, "fixef" ) ) )
freq.ranef_nRE <- sapply( X = freq.ranef_fit, FUN = function( .mm ) length( getME( .mm, "theta" ) ) )

freq.ranef_selection <- data.frame( Model = names( freq.ranef_aicc ), 
                                    RE = freq.ranef_REs, 
                                    AICc = freq.ranef_aicc, 
                                    DeltaAICc = freq.ranef_delt, 
                                    AWt = freq.ranef_wgts, 
                                    LL = freq.ranef_LL, 
                                    K = freq.ranef_K, 
                                    nFE = freq.ranef_nFE, 
                                    nRE = freq.ranef_nRE )[ order( freq.ranef_delt ), ]

freq.ranef_selection.abbrev <- freq.ranef_selection %>% 
  filter( DeltaAICc <= 10 )

freq.ranef_topMod <- freq.ranef_fit[[ which.min( freq.ranef_delt ) ]]

```

```{r FREQfixefSelection}

freq.fixef_forms <- list( int = numBouts ~ 1 + ( blockID | fID ), 
                          fyr = numBouts ~ fYear + ( blockID | fID ), 
                          nag = numBouts ~ NestAge + ( blockID | fID ), 
                          vor = numBouts ~ VOR_AVG + ( blockID | fID ), 
                          trb = numBouts ~ Turbine_Distance_m + ( blockID | fID ), 
                          blk = numBouts ~ blockID + ( blockID | fID ), 
                          rdd = numBouts ~ Roads_Distance_m + ( blockID | fID ), 
                          wtd = numBouts ~ Water_Distance_m + ( blockID | fID ), 
                          jdy = numBouts ~ Jday + ( blockID | fID ), 
                          td.bk = numBouts ~ Turbine_Distance_m * blockID + ( blockID | fID ), 
                          td_bk = numBouts ~ Turbine_Distance_m + blockID + ( blockID | fID ), 
                          wtd.jdy = numBouts ~ Water_Distance_m * Jday + ( blockID | fID ), 
                          wtd_jdy = numBouts ~ Water_Distance_m + Jday + ( blockID | fID ), 
                          time = numBouts ~ NestAge + blockID + Jday + ( blockID | fID ), 
                          dist = numBouts ~ Turbine_Distance_m + Roads_Distance_m + Water_Distance_m + ( blockID | fID ), 
                          whole = numBouts ~ NestAge + Turbine_Distance_m * blockID + ( blockID | fID ), 
                          whnint = numBouts ~ NestAge + Turbine_Distance_m + blockID + ( blockID | fID ), 
                          no.int = numBouts ~ fYear + NestAge + VOR_AVG + Turbine_Distance_m + blockID + Roads_Distance_m + Water_Distance_m + Jday + ( blockID | fID ), 
                          global = numBouts ~ fYear + NestAge + VOR_AVG + Turbine_Distance_m * blockID + Roads_Distance_m + Water_Distance_m * Jday + ( blockID | fID ) )

if( !exists( "freq.fixef_fits" ) ){
  if( length( fl <- list.files( pattern = "freq.fixef_fits.RData", recursive = TRUE ) ) > 0 ){
    load( fl )
  } else {
    freq.fixef_fits <- lapply( X = freq.fixef_forms, 
                               FUN = function( .ff ) glmer( .ff, 
                                                            family = binomial( link = "logit" ), 
                                                            data = csFreqData, 
                                                            control = glmerControl( optimizer = "bobyqa", 
                                                                                    optCtrl = list( maxfun = 2e4 ) ) ) )
    save( freq.fixef_fits, file = "data/freq.fixef_fits.RData" )
  }
  
}

freq.fixef_aicc <- sapply( X = freq.fixef_fits, FUN = AICc )
freq.fixef_delt <- freq.fixef_aicc - min( freq.fixef_aicc )
freq.fixef_wgts <- exp( -0.5 * freq.fixef_delt )
freq.fixef_wgts <- freq.fixef_wgts / sum( freq.fixef_wgts )
freq.fixef_LL <- sapply( X = freq.fixef_fits, FUN = logLik )
freq.fixef_K <- sapply( X = freq.fixef_fits, FUN = function( .mm ) nobs( .mm ) - df.residual( .mm ) )
freq.fixef_FEs <- sapply( X = freq.fixef_fits, FUN = function( .mm ) fetch.FE( .mm ) )
freq.fixef_nFE <- sapply( X = freq.fixef_fits, FUN = function( .mm ) length( getME( .mm, "fixef" ) ) )
freq.fixef_nRE <- sapply( X = freq.fixef_fits, FUN = function( .mm ) length( getME( .mm, "theta" ) ) )

freq.fixef_selection <- data.frame( Model = names( freq.fixef_aicc ), 
                                    FE = freq.fixef_FEs, 
                                    AICc = freq.fixef_aicc, 
                                    DeltaAICc = freq.fixef_delt, 
                                    AWt = freq.fixef_wgts, 
                                    LL = freq.fixef_LL, 
                                    K = freq.fixef_K, 
                                    nFE = freq.fixef_nFE, 
                                    nRE = freq.fixef_nRE )[ order( freq.fixef_delt ), ]

freq.fixef_selection.abbrev <- freq.fixef_selection %>% 
  filter( DeltaAICc <= 10 )

freq.mod_aicc <- freq.fixef_fits[[ which.min( freq.fixef_delt ) ]]

```

-----

```{r FREQfixefAICcSets, eval = FALSE, include = FALSE}

freq.sets <- c( A = "fYear", 
                B = "NestAge * AmbientTemp", 
                C = "Precipitation + VOR_AVG", 
                D = "( WindSpeed + Turbine_Distance_m + blockID )^2", 
                E = "Roads_Distance_m + Water_Distance_m * Jday" )
ranf <- "( blockID | fID )"

freq.set_forms <- lapply( X = unlist( list( t0 = "1", 
                                            t1 = lapply( X = combn( freq.sets, m = 1, simplify = FALSE ), 
                                                         FUN = function( .f ) paste( .f, collapse = " + " ) ), 
                                            t2 = lapply( X = combn( freq.sets, m = 2, simplify = FALSE ), 
                                                         FUN = function( .f ) paste( .f, collapse = " + " ) ), 
                                            t3 = lapply( X = combn( freq.sets, m = 3, simplify = FALSE ), 
                                                         FUN = function( .f ) paste( .f, collapse = " + " ) ), 
                                            t4 = lapply( X = combn( freq.sets, m = 4, simplify = FALSE ), 
                                                         FUN = function( .f ) paste( .f, collapse = " + " ) ), 
                                            t5 = lapply( X = combn( freq.sets, m = 5, simplify = FALSE ), 
                                                         FUN = function( .f ) paste( .f, collapse = " + " ) ) ), 
                                      recursive = FALSE ), 
                          FUN = function( .ff ) reformulate( paste( .ff, ranf, sep = " + " ), 
                                                             response = "numBouts" ) )

if( !exists( "freq.set_fits" ) ){
  if( length( fl <- list.files( pattern = "freq.set_fits.RData", recursive = TRUE ) ) > 0 ){
    load( fl )
  } else {
    freq.set_fits <- lapply( X = freq.set_forms, 
                             FUN = function( .ff ) glmer( .ff, 
                                                          family = binomial( link = "logit" ), 
                                                          data = csFreqData, 
                                                          control = glmerControl( optimizer = "bobyqa", 
                                                                                  optCtrl = list( maxfun = 2e4 ) ) ) )
    save( freq.set_fits, file = "data/freq.set_fits.RData" )
  }
}

freq.set_aicc <- sapply( X = freq.set_fits, FUN = AICc )
freq.set_delt <- freq.set_aicc - min( freq.set_aicc )
freq.set_wgts <- exp( -0.5 * freq.set_delt )
freq.set_wgts <- freq.set_wgts / sum( freq.set_wgts )
freq.set_FEs <- sapply( X = freq.set_fits, FUN = fetch.FE )
freq.set_nFE <- sapply( X = freq.set_fits, FUN = function( .mm ) length( getME( .mm, "fixef" ) ) )
freq.set_nRE <- sapply( X = freq.set_fits, FUN = function( .mm ) length( getME( .mm, "theta" ) ) )

freq.set_selection <- data.frame( Model = names( freq.set_aicc ), 
                                  FE = freq.set_FEs, 
                                  AICc = freq.set_aicc, 
                                  DeltaAICc = freq.set_delt, 
                                  AWt = freq.set_wgts, 
                                  nFE = freq.set_nFE, 
                                  nRE = freq.set_nRE )[ order( freq.set_delt ), ]

```

```{r FREQfixefAvgR, eval = FALSE, include = FALSE}

freq.fixef_ests <- map2_df( .x = freq.set_fits, 
                            .y = names( freq.set_fits ), 
                            .f = tidy_w_name ) %>% 
  complete( term, name ) %>% 
  left_join( freq.set_selection[ , c( "Model", "AWt" ) ], by = c( "name" = "Model" ) )

freq.fixef_ests[ is.na( freq.fixef_ests$estimate ), c( "estimate", "std.error" ) ] <- 0

freq.fixef_ests <- freq.fixef_ests %>%
  group_by( term ) %>%
  mutate( wnorm = AWt / sum( AWt ),
          var_est = std.error^2 ) %>%
  summarize( avg_est = sum( estimate * wnorm ),
             avg_var = sum( wnorm * ( var_est + ( estimate - avg_est )^2 ) ), 
             avg_SE = sqrt( avg_var ), 
             tstat = avg_est / avg_SE, 
             p.val = 2 * pt( q = abs( tstat ), 
                             df = min( sapply( X = freq.set_fits, 
                                               FUN = df.residual ) ), 
                             lower.tail = FALSE ) )

```

-----

```{r FREQpredictRnestAge}

nd <- expand.grid( NestAge = ( 0:28 - mean( freqData$NestAge, na.rm = TRUE ) ) / sd( freqData$NestAge, na.rm = TRUE ), 
                   Jday = ( seq( from = min( freqData$Jday, na.rm = TRUE ), 
                                 to = max( freqData$Jday, na.rm = TRUE ), 
                                 by = 28 ) - mean( freqData$Jday, na.rm = TRUE ) ) / sd( freqData$Jday, na.rm = TRUE ), 
                   blockID = factor( levels( freqData$blockID ), levels = levels( freqData$blockID ) ) )
contrasts( nd$blockID ) <- contr.sum( length( levels( nd$blockID ) ) )


if( !exists( "freq.predict_aicc.boot" ) ){
  if( length( fl <- list.files( pattern = "freq.predict_aicc.boot.RData", recursive = TRUE ) ) > 0 ){
    load( fl )
  } else {
    freq.predict_aicc.boot <- bootMer( x = freq.mod_aicc, 
                                       FUN = boot.fitter, 
                                       nsim = 1000 )
    
    save( freq.predict_aicc.boot, file = "data/freq.predict_aicc.boot.RData" )
  }
}

freq.predict_aicc.bootCI <- t( apply( X = freq.predict_aicc.boot$t, 
                                         MARGIN = 2, 
                                         FUN = quantile, 
                                         probs = c( 0.025, 0.975 ) ) )

freq.predict.age <- nd %>%
  mutate( .mu = predict( freq.mod_aicc, 
                         newdata = nd, 
                         re.form = ~0, 
                         type = "response" ), 
          lo.95 = freq.predict_aicc.bootCI[ , 1 ],
          hi.95 = freq.predict_aicc.bootCI[ , 2 ],
          NestAge_r = ( NestAge * sd( freqData$NestAge, na.rm = TRUE ) ) + mean( freqData$NestAge, na.rm = TRUE ), 
          Jday_r = ( Jday * sd( freqData$Jday, na.rm = TRUE ) ) + mean( freqData$Jday, na.rm = TRUE ), 
          lo.95_r = exp( lo.95 ) / ( 1 + exp( lo.95 ) ),
          hi.95_r = exp( hi.95 )/ ( 1 + exp( hi.95 ) ) )

freq.predict.age_plot <- ggplot( data = freq.predict.age, 
                             aes( x = NestAge_r, 
                                  y = .mu, 
                                  linetype = factor( Jday_r ) ) ) + 
  geom_ribbon( inherit.aes = FALSE, 
               aes( x = NestAge_r, 
                    ymin = lo.95_r, 
                    ymax = hi.95_r, 
                    group = factor( Jday_r ) ), 
               alpha = 0.4 ) + 
  geom_line() + 
  # geom_rug( data = filter( freqData, numBouts > 0 ), 
  #           inherit.aes = FALSE, 
  #           aes( x = NestAge, 
  #                y = numBouts ), 
  #           sides = "t", 
  #           alpha = 0.4 ) + 
  # geom_rug( data = filter( freqData, numBouts == 0 ), 
  #           inherit.aes = FALSE, 
  #           aes( x = NestAge, 
  #                y = numBouts ), 
  #           sides = "b", 
  #           alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Nest age (d)", 
        y = "Probability of off-bout initiation", 
        linetype = "Ordinal date" ) + 
  facet_wrap( ~blockID, 
              labeller = labeller( blockID = c( "1" = "01:30--04:29", 
                                                "4" = "04:30--74:29", 
                                                "7" = "07:30--10:29", 
                                                "10" = "10:30--13:29", 
                                                "13" = "13:30--16:29", 
                                                "16" = "16:30--19:29", 
                                                "19" = "19:30--22:29", 
                                                "22" = "22:30--01:29" ) ) ) + 
  scale_linetype( labels = c( "124" = "4 May", 
                              "152" = "1 June", 
                              "180" = "29 June" ) ) + 
  theme( legend.position = c( 5/6, 1/6 ), 
         text = element_text( size = 12 ) )

freq.predict.age_plot

# ggsave( "freq_age.pred.pdf", plot = freq.predict.age_plot, device = "pdf", path = "figures/",
#         width = 15, height = 15, units = "cm" )

```

```{r FREQpredictRtime}

freq.predict.time_plot <- ggplot( data = filter( freq.predict.age, Jday_r == 152, NestAge_r == 14 ), 
                                  aes( x = blockID, 
                                       y = .mu ) ) + 
  geom_point() + 
  geom_linerange( aes( ymin = lo.95_r, 
                       ymax = hi.95_r ) ) + 
  theme_classic() + 
  labs( x = "Time block", 
        y = "Probability of off-bout initiation" ) + 
  scale_x_discrete( labels = c( "1" = "01:30--04:29", 
                                "4" = "04:30--74:29", 
                                "7" = "07:30--10:29", 
                                "10" = "10:30--13:29", 
                                "13" = "13:30--16:29", 
                                "16" = "16:30--19:29", 
                                "19" = "19:30--22:29", 
                                "22" = "22:30--01:29" ) ) + 
  theme( text = element_text( size = 12 ), 
         axis.text.x = element_text( angle = 40, 
                                     vjust = 0.95, 
                                     hjust = 0.975 ) )

freq.predict.time_plot

ggsave( "freq_time.pred.pdf", plot = freq.predict.time_plot, device = "pdf", path = "figures/", 
        width = 15, height = 15, units = "cm" )

```


###**RESULTS** {#results}

```{r RESULTSnotes, eval = FALSE, include = FALSE}
# --characteristics
# ----past tense
# ----clear, concise, organized
# ----not repetetive of methods
# ----describe qualitatively rather than quantitatively only
# ----avoids synthesis more properly included in discussion
# --includes
# ----quantitative presentation of results
# ----parallels presentation in methods

# --# obs/group, etc.
```

```{r summaRystats}

# Finds min, max, mean, sd, and n of off-bout durations, tempdiffs, and windspeeds.
dur.sum <- fullBouts %>% 
  summarize_at( .cols = vars( Mins, 
                              WindSpeed, 
                              TempDiff ), 
                .funs = funs( N = sum( !is.na( . ) ), 
                              Mean = mean( ., na.rm = TRUE ), 
                              SD = sd( ., na.rm = TRUE ), 
                              Min = min( ., na.rm = TRUE ), 
                              Max = max( ., na.rm = TRUE ) ) ) %>% 
  gather( key = Variable_Statistic, 
          value = Value, 
          everything() ) %>% 
  separate( col = Variable_Statistic, 
            into = c( "Variable", "Statistic" ), 
            sep = "_" ) %>% 
  spread( key = Statistic, 
          value = Value )

# Finds min, max, mean, sd, and n of (1) dist to road, (2) dist to trees, (3) dist to turbine, (3) dist to water, and (4) VOR of nests
nest.sum <- nests %>% 
  ungroup() %>% 
  rename( VOR = VOR_AVG, 
          Turbine = Turbine_Distance_m, 
          Roads = Roads_Distance_m, 
          Trees = Trees_Distance_m, 
          Water = Water_Distance_m ) %>% 
  summarize_at( .cols = vars( VOR, 
                              Turbine, 
                              Roads, 
                              Trees, 
                              Water ), 
                .funs = funs( N = sum( !is.na( . ) ), 
                              Mean = mean( ., na.rm = TRUE ), 
                              SD = sd( ., na.rm = TRUE ), 
                              Min = min( ., na.rm = TRUE ), 
                              Max = max( ., na.rm = TRUE ) ) ) %>% 
  gather( key = Variable_Statistic, 
          value = Value, 
          everything() ) %>% 
  separate( col = Variable_Statistic, 
            into = c( "Variable", "Statistic" ), 
            sep = "_" ) %>% 
  spread( key = Statistic, 
          value = Value )

# For each nest, lists every date from the first to the last recorded off-bout (even if none were recorded from a particular day).
dates <- bouts %>% 
  group_by( id ) %>% 
  summarize( Start = min( Date ), 
             End = max( Date ) ) %>% 
  plyr::ddply( .variables = "id", 
               .fun = function( .df ){
                 data.frame( id = .df$id, 
                             Date = seq( .df$Start, 
                                         .df$End, 
                                         "day" ), 
                             stringsAsFactors = FALSE )
               })

# Finds min, max, mean, and sd of number of bouts/day, as well as total number of nest-days observed.
freq.sum <- bouts %>% 
  group_by( id, Date ) %>% 
  summarize( NumPDay = n() ) %>% 
  right_join( y = dates, 
              by = c( "id", "Date" ) ) %>% 
  ungroup() %>% 
  # mutate( NumPDay = plyr::mapvalues( NumPDay, NA, 0 ) ) %>%  # if this is included, days during the incubation period with no recorded off-bouts are included in the calculation, else they are omitted (adds 8 nest-days, changes min NumPDay to 0)
  summarize( N = sum( !is.na( NumPDay ) ), 
             Mean = mean( NumPDay, na.rm = TRUE ), 
             SD = sd( NumPDay, na.rm = TRUE ), 
             Min = min( NumPDay, na.rm = TRUE ), 
             Max = max( NumPDay, na.rm = TRUE ) )

# # Test whether the bout duration or the average number of bouts taken per day by individual hens are associated with nest success.
# # OMITTED---BETTER to AVERAGE DURATION for EACH NEST
# wilcox.nestSuccess_dur <- wilcox.test( Mins ~ Nest_Success, data = fullBouts )
# wilcox.nestSuccess_freq <- wilcox.test( MeanBouts ~ Nest_Success, data = nests )

temp.sum <- iTemps %>% 
  filter( onNest ) %>% 
  summarize_at( .cols = vars( Temperature ), 
                .funs = funs( Mean = mean( ., na.rm = TRUE ), 
                              SD = sd( ., na.rm = TRUE ), 
                              Min = min( ., na.rm = TRUE ), 
                              Max = max( ., na.rm = TRUE ), 
                              N = sum( !is.na( . ) ) ) )

```

```{r paRameteRs}

# Re-fit the duration model using lmerTest to extract the p-values.
m.call <- dur.mod_aicc@call
dur.mod_aicc.p <- lmerTest::lmer( m.call$formula, 
                                  data = eval( m.call$data ), 
                                  REML = m.call$REML, 
                                  control = lmerControl( optimizer = m.call$control$optimizer, 
                                                         optCtrl = list( maxfun = m.call$control$optCtrl$maxfun ) ) )

dur.mod_aicc2 <- dur.fixef_fits[[ as.character( dur.fixef_selection$Model[ 2 ] ) ]]
m2.call <- dur.mod_aicc2@call
dur.mod_aicc2.p <- lmerTest::lmer( m2.call$formula, 
                                   data = eval( m2.call$data ), 
                                   REML = m2.call$REML, 
                                   control = lmerControl( optimizer = m2.call$control$optimizer, 
                                                          optCtrl = list( maxfun = m2.call$control$optCtrl$maxfun ) ) )

dur.mod_aicc3 <- dur.fixef_fits[[ as.character( dur.fixef_selection$Model[ 3 ] ) ]]
m3.call <- dur.mod_aicc3@call
dur.mod_aicc3.p <- lmerTest::lmer( m3.call$formula, 
                                   data = eval( m3.call$data ), 
                                   REML = m3.call$REML, 
                                   control = lmerControl( optimizer = m3.call$control$optimizer, 
                                                          optCtrl = list( maxfun = m3.call$control$optCtrl$maxfun ) ) )

blockKey <- c( "blockID1" = "01:30--04:29", 
               "blockID2" = "04:30--07:29",
               "blockID3" = "07:30--10:29",
               "blockID4" = "10:30--13:29",
               "blockID5" = "13:30--16:29",
               "blockID6" = "16:30--19:29",
               "blockID7" = "19:30--22:29" )

# Extract fixed-effect coefficient estimates and significance values (for dur.table, p values are based on Satterthwaite approx. for denominator degrees of freedom).
dur.table <- data.frame( summary( dur.mod_aicc.p )$coefficients ) %>% 
  rename_( "beta" = "Estimate", 
           "SE" = "Std..Error", 
           "df" = "df", 
           "t" = "t.value", 
           "p" = "Pr...t.." ) %>% 
  mutate( term = rownames( . ), 
          eBeta = exp( beta ), 
          eSE = exp( SE ) )
freq.table <- data.frame( summary( freq.mod_aicc )$coefficients ) %>% 
  rename_( "beta" = "Estimate", 
           "SE" = "Std..Error", 
           "z" = "z.value", 
           "p" = "Pr...z.." ) %>% 
  mutate( term = plyr::mapvalues( x = rownames( . ), from = names( blockKey ), to = blockKey ), 
          eBeta = exp( beta ), 
          eSE = exp( SE ), 
          inv.logitBeta = exp( beta ) / ( 1 + exp( beta ) ), 
          inv.logitSE = exp( SE ) / ( 1 + exp( SE ) ) )

dur.table2 <- data.frame( summary( dur.mod_aicc2.p )$coefficients ) %>% 
  rename_( "beta" = "Estimate", 
           "SE" = "Std..Error", 
           "df" = "df", 
           "t" = "t.value", 
           "p" = "Pr...t.." ) %>% 
  mutate( term = rownames( . ), 
          eBeta = exp( beta ), 
          eSE = exp( SE ) )

dur.ranfs <- data.frame( VarCorr( dur.mod_aicc.p ) )

blockMap <- c( "blockID1" = "04:30--07:29",
               "blockID2" = "07:30--10:29",
               "blockID3" = "10:30--13:29",
               "blockID4" = "13:30--16:29",
               "blockID5" = "16:30--19:29",
               "blockID6" = "19:30--22:29",
               "blockID7" = "22:30--01:29" )

```

```{r nestCalcs}

aged.nests <- nests %>% filter( !is.na( Date_Incubation_Initiated ) ) # select just the nests whose ages could be estimated (and which were used in analysis)
aged.fullBouts <- fullBouts %>% filter( id %in% aged.nests$NestID )

# predation.freqData <- freqData %>% filter( numBouts != 0 ) %>% group_by( Nest_Predated ) # select just the time blocks in which off-bouts were initiated
# success.freqData <- freqData %>% filter( numbBouts != 0 ) %>% group_by( Nest_Success )

# Test whether bout duration or #bouts/day was different between hatched vs. failed nests:
dur.test_success <- wilcox.test( MeanMins_bout ~ Nest_Success, data = nests, alternative = "two.sided" )
freq.test_success <- wilcox.test( MeanBouts ~ Nest_Success, data = nests, alternative = "two.sided" )
# time.test_success <- fisher.test( x = pos.freqData$blockID, y = pos.freqData$Nest_Success, simulate.p.value = TRUE, B = 1e6 )

# and between depredated and non-depredated nests:
dur.test_predation <- wilcox.test( MeanMins_bout ~ Nest_Predated, data = nests, alternative = "two.sided" )
freq.test_predation <- wilcox.test( MeanBouts ~ Nest_Predated, data = nests, alternative = "two.sided" )
# time.test_predation <- fisher.test( x = pos.freqData$blockID, y = pos.freqData$Nest_Predated, simulate.p.value = TRUE, B = 1e6 )

predation_dur <- nests %>% 
  group_by( Nest_Predated ) %>% 
  summarize( Mean_Dur = mean( MeanMins_bout ), 
             SD_Dur = sd( MeanMins_bout ), 
             N_Dur = n() )

success_dur <- nests %>% 
  group_by( Nest_Success ) %>% 
  summarize( Mean_Dur = mean( MeanMins_bout ), 
             SD_Dur = sd( MeanMins_bout ), 
             N_Dur = n() )

predation_freq <- nests %>% 
  group_by( Nest_Predated ) %>% 
  summarize( Mean_Freq = mean( MeanBouts ), 
             SD_Freq = sd( MeanBouts ), 
             N_Freq = n() )

success_freq <- nests %>% 
  group_by( Nest_Success ) %>% 
  summarize( Mean_Freq = mean( MeanBouts ), 
             SD_Freq = sd( MeanBouts ), 
             N_Freq = n() )

predation <- left_join( predation_dur, predation_freq, by = "Nest_Predated" ) %>% 
  gather( Stat_Measure, Value, -Nest_Predated ) %>% 
  separate( Stat_Measure, c( "Stat", "Measure" ), "_" ) %>% 
  spread( Stat, Value )

success <- left_join( success_dur, success_freq, by = "Nest_Success" ) %>% 
  gather( Stat_Measure, Value, -Nest_Success ) %>% 
  separate( Stat_Measure, c( "Stat", "Measure" ), "_" ) %>% 
  spread( Stat, Value )

# freqData.abridged <- freqData %>% 
#   filter( numBouts != 0 )
# 
# fisher.test( freqData.abridged$blockID, freqData.abridged$Nest_Predated, simulate.p.value = TRUE, B = 1e7 )

```

```{r tempCalcs}

weather.sum_block <- freqData.preserve %>% 
  group_by( blockID ) %>% 
  summarize_at( .cols = vars( AmbientTemp, NestTemp, TempDiff, WindSpeed, Precipitation ), 
                .funs = funs( Mean = mean( ., na.rm = TRUE ), 
                              SD = sd( ., na.rm = TRUE ), 
                              Min = min( ., na.rm = TRUE ), 
                              Max = max( ., na.rm = TRUE ), 
                              N.bouts = sum( numBouts ), 
                              N.blocks = sum( !is.na( . ) ) ) ) %>% 
  gather( key = Variable_Statistic, 
          value = Value, 
          -blockID ) %>% 
  separate( col = Variable_Statistic, 
            into = c( "Variable", "Statistic" ), 
            sep = "_" ) %>% 
  spread( key = Statistic, 
          value = Value ) %>% 
  arrange( Variable )

weather.sum_bout <- fullBouts %>% 
  summarize_at( .cols = vars( AmbientTemp, preBoutNestTemp, WindSpeed, TempDiff ), 
                .funs = funs( Mean = mean( ., na.rm = TRUE ), 
                              SD = sd( ., na.rm = TRUE ), 
                              Min = min( ., na.rm = TRUE ), 
                              Max = max( ., na.rm = TRUE ), 
                              N = sum( !is.na( . ) ) ) ) %>% 
  gather( key = Variable_Statistic, 
          value = Value, 
          everything() ) %>% 
  separate( col = Variable_Statistic, 
            into = c( "Variable", "Statistic" ), 
            sep = "_" ) %>% 
  spread( key = Statistic, 
          value = Value )

ggplot( data = weather.sum_block, 
        aes( x = blockID, 
             y = Mean ) ) + 
  geom_errorbar( aes( ymin = Mean - SD, 
                      ymax = Mean + SD ) ) + 
  geom_point() + 
  theme_classic() + 
  facet_wrap( ~Variable, scales = "free" )
  

```


We recorded `r nrow(bouts)` incubation off-bouts at `r length(unique(bouts$id))` nests. On average, hens took `r round(mean(nests$MeanBouts),2)` ± `r round(sd(nests$MeanBouts),2)` [SD] off-bouts per day (range: `r round(min(nests$MeanBouts),2)`--`r round(max(nests$MeanBouts),2)`) during incubation. The mean duration of off-bouts was `r round(mean(fullBouts$Mins),2)` ± `r round(sd(fullBouts$Mins),2)` min (range: `r round(min(fullBouts$Mins),2)`--`r round(max(fullBouts$Mins),2)` min). Eight nests (representing `r sum(is.na(bouts$NestAge))` off-bouts) could not be reliably aged, as they were not located until after clutch completion and failed prior to hatching. Because we considered nest age a potentially important factor for hens making behavioral decisions regarding incubation, data from those nests was not considered in the modelling analysis. Neither the duration (Wilcoxon's *W* = `r round(dur.test$statistic,2)`, *P* = `r round(dur.test$p.value,3)`) nor the frequency (as the number of off-bouts taken per day; *W* = `r round(freq.test$statistic,2)`, *P* = `r round(freq.test$p.value,3)`) differed between successful (*N* = `r sum(nests$Nest_Success)`) and unsuccessful (*N* = `r sum(nests$Nest_Success==0)`) nests.

None of the continuous covariates was strongly correlated with any others (all |Spearman's $\rho$| < 0.5). The time block during which an off-bout was initiated was associated with ambient temperature ($\chi^2_{`r Ttests_FREQ[["AmbientTemp"]]$parameter`}$ = `r round(Ttests_FREQ[["AmbientTemp"]]$statistic,3)`, *P* < 0.001), wind speed ($\chi^2_{`r Ttests_FREQ[["WindSpeed"]]$parameter`}$ = `r round(Ttests_FREQ[["WindSpeed"]]$statistic,3)`, *P* < 0.001), and precipitation ($\chi^2_{`r Ttests_FREQ[["Precipitation"]]$parameter`}$ = `r round(Ttests_FREQ[["Precipitation"]]$statistic,3)`, *P* < 0.001). To avoid the potentially confounding effects of multicollinearity in the model matrix, and because we were particularly interested in temporal effects, we eliminated the latter three covariates from consideration in the off-bout frequency model.

The top-ranked (*i.e.*, $\Delta$AIC$_c$ = 0) random-effects structure for off-bout duration bore `r paste(round(dur.ranef_selection$AWt[1]*100,1),"%",sep="")` of the weight of evidence, and included both a random intercept and an uncorrelated random slope of the effect of nest age on the duration of incubation off-bouts. The only other random-effects structure that performed similarly at explaining the data ($\Delta$AIC$_c$ = `r round(dur.ranef_selection$DeltaAICc[2],3)`, Akaike weight = `r round(dur.ranef_selection$AWt[2],3)`) added a correlation estimate between the two random-effects components, which we understood to represent an uninformative parameter [@arnold2010]. We therefore used the top-ranked random-effects structure in our selection of the best fixed-effects structure.

Both stepwise backwards elimination and AIC$_c$-based selection identified the same fixed-effects structure as best at explaining our off-bout duration data. This model had a residual variance of `r with(dur.ranfs,round(vcov[which(grp=="Residual")],3))` and predicted negative effects of both wind speed ($\beta$ = `r with(dur.table,round(beta[term=="WindSpeed"],4))` ± `r with(dur.table,round(SE[term=="WindSpeed"],4))` [SE], *P* = `r with(dur.table,round(p[term=="WindSpeed"],4))`) and the difference between the ambient and nest temperatures at the time of off-bout initiation ($\beta$ = `r with(dur.table,round(beta[term=="TempDiff"],4))` ± `r with(dur.table,round(SE[term=="TempDiff"],4))`, *P* < `r with(dur.table,sprintf("%.4f",round(p[term=="TempDiff"],4)))`). We therefore expect hens to decrease the duration of incubation off-bouts during windy conditions and at times when there is a relatively large ambient--nest temperature gradient (*i.e.*, at low ambient temperatures). Our top-ranked duration model predicted a global intercept of $\beta$ = `r with(dur.table,round(beta[term=="(Intercept)"],4))` ± `r with(dur.table,round(SE[term=="(Intercept)"],4))` (*P* < 0.0001) with a random population-level variance of `r with(dur.ranfs,round(vcov[which(var1=="(Intercept)")],3))`. The global intercept prediction suggests that under average conditions (*i.e.*, at wind speeds of around `r round(mean(fullBouts$WindSpeed,na.rm=TRUE),1)` mph and when the ambient temperature is approximately `r round(mean(fullBouts$TempDiff,na.rm=TRUE),1)`°C below nest temperature), we expect a mean off-bout duration of `r with(dur.table,round(exp(beta[term=="(Intercept)"]),1))` ± `r with(dur.table,round(exp(SE[term=="(Intercept)"]),2))` min. Although not included in the fixed-effects structure, the top-ranked model also predicted variation among hens with respect to the effect of nest age on off-bout duration (variance = `r with(dur.ranfs,round(vcov[which(var1=="NestAge")],3))`), suggesting that while there is on average no effect of nest age on off-bout duration, individual hens may adjust the amount of time they spend off the nest on the basis of the incubation stage of their nest.

The best random-effects structure for explaining off-bout frequency bore `r paste(round(freq.ranef_selection$AWt[1]*100,1),"%",sep="")` of the weight of evidence, and included a random slope of the effect of time block on the likelihood of off-bout initiation. Other contenders included uncorrelated ($\Delta$AIC$_c$ = `r round(freq.ranef_selection$DeltaAICc[2],3)`, Akaike weight = `r round(freq.ranef_selection$AWt[2],3)`) and correlated ($\Delta$AIC$_c$ = `r round(freq.ranef_selection$DeltaAICc[3],3)`, Akaike weight = `r round(freq.ranef_selection$AWt[3],3)`) random intercepts in addition to the random slope of the time block effect.

The best fixed-effects structure for explaining the likelihood of off-bout initiation included terms for nest age ($\beta$ = `r with(freq.table,round(beta[term=="NestAge"],4))` ± `r with(freq.table,round(SE[term=="NestAge"],4))`, *P* = `r with(freq.table,round(p[term=="NestAge"],4))`), ordinal date($\beta$ = `r with(freq.table,round(beta[term=="Jday"],4))` ± `r with(freq.table,round(SE[term=="Jday"],4))`, *P* = `r with(freq.table,round(p[term=="Jday"],4))`), and time block, with a baseline probability of off-bout initiation (for the reference block between 22:30 and 01:29) of `r with(freq.table,paste(round((exp(beta[term=="(Intercept)"])/(1+exp(beta[term=="(Intercept)"])))*100,1),"%",sep=""))` ($\beta_0$ = `r with(freq.table,round(beta[term=="(Intercept)"],4))` ± `r with(freq.table,round(SE[term=="(Intercept)"],4))`, *P* < 0.0001). Hens were most likely to leave the nest between 07:30 and 10:29 (*N* = `r with(freqData.preserve,sum(numBouts[blockID=="7"]))`; probability of departure = `r with(freq.table,paste(round((exp(beta[term=="blockID3"])/(1+exp(beta[term=="blockID3"])))*100,1),"%",sep=""))`, $\beta$ = `r with(freq.table,round(beta[term=="blockID3"],4))` ± `r with(freq.table,round(SE[term=="blockID3"],4))`, *P* < 0.0001) and between 19:30 and 22:29 (*N* = `r with(freqData.preserve,sum(numBouts[blockID=="19"]))`; probability of departure = `r with(freq.table,paste(round((exp(beta[term=="blockID7"])/(1+exp(beta[term=="blockID7"])))*100,1),"%",sep=""))`, $\beta$ = `r with(freq.table,round(beta[term=="blockID7"],4))` ± `r with(freq.table,round(SE[term=="blockID7"],4))`, *P* < 0.0001), and were least likely to leave between 01:30 and 04:30 (*N* = `r with(freqData.preserve,sum(numBouts[blockID=="1"]))`; probability of departure = `r with(freq.table,paste(round((exp(beta[term=="blockID1"])/(1+exp(beta[term=="blockID1"])))*100,1),"%",sep=""))`, $\beta$ = `r with(freq.table,round(beta[term=="blockID1"],4))` ± `r with(freq.table,round(SE[term=="blockID1"],4))`, *P* < 0.0001).

###**DISCUSSION** {#discussion}

```{r DISCUSSIONnotes, eval = FALSE, include = FALSE}
# --characteristics
# ----concise
# ----follows order set out in methods and results
# ----highlights most important/significant findings
# ----interpretations of results
# ----comparison of results to literature
# --include
# ----synthesize results w.r.t. objectives
# ----relate relevant findings to published literature/research
# ----may include reasonable speculation and logical extensions/new hypotheses/questions
```

```{r fReqHist}

histData <- freqData.preserve %>% 
  filter( numBouts != 0 ) %>% 
  group_by( blockID ) %>% 
  summarize( N = sum( numBouts ) )

histPlot <- ggplot( data = histData, 
                    aes( x = seq( 3, 24, 3 ), 
                         y = N ) ) + 
  geom_col() + 
  theme_classic() + 
  labs( x = "Time", 
        y = "Number of off-bouts initiated" ) + 
  scale_x_continuous( breaks = seq( 1.5, 25.5, 3 ), 
                      labels = c( "01:30", "04:30", "07:30", "10:30", "13:30", "16:30", "19:30", "22:30", "01:30" ) ) + 
  theme( text = element_text( size = 12 ) )

histPlot

# ggsave( "time_hist.pdf", plot = histPlot, device = "pdf", path = "figures/",
#         width = 15, height = 15, units = "cm" )

```

###**MANAGEMENT IMPLICATIONS** {#managementimplications}

```{r IMPLICATIONSnotes, eval = FALSE, include = FALSE}
# --characteristics
# ----short (~1paragraph)
# ----direct
# ----specific
# --include
# ----management/conservations issues derived directly from results
# ----DO NOT restate information from results or discussion
# ----DO NOT make recommendations beyond scope of study
```

###**ACKNOWLEDGMENTS** {#acknowledgments}

```{r ACKNOWLEDGMENTSnotes, eval = FALSE, include = FALSE}
# --brief
# --initials
```

###**APPENDIX** {#appendix}

####**Model Selection**

```{r duRranef}

duRranef_table <- dur.ranef_selection %>% 
  dplyr::select( -c( Model, nFE, nRE ) )

duRranef_kable <- knitr::kable( x = duRranef_table, 
                                format = "latex", 
                                digits = 3, 
                                row.names = FALSE, 
                                col.names = c( "Random-effects structure", 
                                               "AIC$_c$", 
                                               "$\\Delta$AIC$_c$", 
                                               "Akaike weight", 
                                               "$\\log{\\mathcal{L}}$", 
                                               "K" ) )

```

```{r duRfixef}

duRfixef_table <- dur.fixef_selection %>% 
  dplyr::select( -c( Model, nFE, nRE ) )

duRfixef_kable <- knitr::kable( x = duRfixef_table, 
                                format = "latex", 
                                digits = 3, 
                                row.names = FALSE, 
                                col.names = c( "Fixed-effects structure", 
                                               "AIC$_c$", 
                                               "$\\Delta$AIC$_c$", 
                                               "Akaike weight", 
                                               "$\\log{\\mathcal{L}}$", 
                                               "K" ) )

```

```{r fReqRanef}

fReqRanef_table <- freq.ranef_selection %>% 
  dplyr::select( -c( Model, nFE, nRE ) )

fReqRanef_kable <- knitr::kable( x = fReqRanef_table, 
                                 format = "latex", 
                                 digits = 3, 
                                 row.names = FALSE, 
                                 col.names = c( "Random-effects structure", 
                                                "AIC$_c$", 
                                                "$\\Delta$AIC$_c$", 
                                                "Akaike weight", 
                                                "$\\log{\\mathcal{L}}$", 
                                                "K" ) )

```

```{r fReqFixef}

fReqFixef_table <- freq.fixef_selection %>% 
  dplyr::select( -c( Model, nFE, nRE ) )

fReqFixef_kable <- knitr::kable( x = fReqFixef_table, 
                                 format = "latex", 
                                 digits = 3, 
                                 row.names = FALSE, 
                                 col.names = c( "Fixed-effects structure", 
                                                "AIC$_c$", 
                                                "$\\Delta$AIC$_c$", 
                                                "Akaike weight", 
                                                "$\\log{\\mathcal{L}}$", 
                                                "K" ) )

```

####**Model Validation**

```{r DURvalidatRtrial}

dur.test_aicc <- augment( dur.mod_aicc ) %>% 
  mutate( NestAge = round( ( NestAge * sd( fullBouts$NestAge, na.rm = TRUE ) ) + mean( fullBouts$NestAge, na.rm = TRUE ), digits = 0 ), 
          TempDiff = ( TempDiff * sd( fullBouts$TempDiff, na.rm = TRUE ) ) + mean( fullBouts$TempDiff, na.rm = TRUE ), 
          WindSpeed = ( WindSpeed * sd( fullBouts$WindSpeed, na.rm = TRUE ) ) + mean( fullBouts$WindSpeed, na.rm = TRUE ), 
          Mins = exp( tMins ), 
          .mu = exp( .fitted ), 
          .std.resid = std.resid.glmer( dur.mod_aicc ), 
          .hat = hatvalues( dur.mod_aicc ) ) %>% 
  dplyr::select( -.rownames )
ests <- influence.ME::influence( dur.mod_aicc, obs = TRUE )
dur.test_aicc$.cooksd <- cooks.distance( ests )[ which( !is.na( fullBouts$NestAge ) ) ]

rVf_dur_aicc <- ggplot( data = dur.test_aicc, 
                        aes( x = .fitted, 
                             y = .resid ) ) + 
  geom_smooth( colour = "seashell4" ) + 
  geom_hline( yintercept = 0, 
              linetype = "dashed" ) + 
  geom_point( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Fitted values", 
        y = "Residuals" ) + 
  theme( text = element_text( size = 12 ) )

y <- quantile( x = dur.test_aicc$.std.resid, probs = c( 0.25, 0.75 ) )
x <- qnorm( p = c( 0.25, 0.75 ) )
slope <- diff( y ) / diff( x )
int <- y[ 1L ] - ( slope * x[ 1L ] )

qq_dur_aicc <- ggplot( data = dur.test_aicc, 
                       aes( sample = .std.resid ) ) + 
  geom_abline( slope = slope, 
               intercept = int, 
               colour = "tomato" ) + 
  stat_qq( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Theoretical quantiles", 
        y = "Standardized residuals" ) + 
  theme( text = element_text( size = 12 ) )

sl_dur_aicc <- ggplot( data = dur.test_aicc, 
                       aes( x = .fitted, 
                            y = sqrt( abs( .std.resid ) ) ) ) + 
  geom_smooth( colour = "seashell4" ) + 
  geom_hline( yintercept = 1, 
              linetype = "dashed" ) + 
  geom_point( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Fitted values", 
        y = "√|Standardized residuals|" ) + 
  theme( text = element_text( size = 12 ) )

lev_dur_aicc <- ggplot( data = dur.test_aicc, 
                        aes( x = .hat, 
                             y = .std.resid, 
                             size = .cooksd ) ) + 
  geom_hline( yintercept = 0,
              size = 1,
              colour = "grey" ) +
  geom_vline( xintercept = 0,
              size = 1,
              colour = "grey" ) +
  geom_point() +
  theme_classic() +
  labs( x = "Leverage",
        y = "Standardized residuals",
        size = expression( "Cook's distance" ) ) +
  theme( legend.position = "bottom" )

cowplot::plot_grid( rVf_dur_aicc, qq_dur_aicc, sl_dur_aicc, lev_dur_aicc, nrow = 2, labels = "AUTO" )

```

```{r DURcheckRtrial}

rVna_aicc <- ggplot( data = dur.test_aicc, 
                     aes( x = NestAge, 
                          y = .resid ) ) + 
  geom_point( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Nest age (d)", 
        y = "Residuals" )

rVtd_aicc <- ggplot( data = dur.test_aicc, 
                     aes( x = TempDiff, 
                          y = .resid ) ) + 
  geom_point( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Temperature difference (°C)", 
        y = "Residuals" )

rVws_aicc <- ggplot( data = dur.test_aicc, 
                     aes( x = WindSpeed, 
                          y = .resid ) ) + 
  geom_point( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Wind speed (mph)", 
        y = "Residuals" )

dur_fVo_aicc <- ggplot( data = dur.test_aicc, 
                        aes( x = Mins, 
                             y = .mu ) ) + 
  geom_abline( slope = 1, 
               intercept = 0 ) + 
  geom_point( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Observed off-bout duration (min)", 
        y = "Predicted off-bout duration (min)" )

cowplot::plot_grid( rVna_aicc, rVtd_aicc, rVws_aicc, dur_fVo_aicc, nrow = 2, labels = "AUTO" )

```

```{r DURvalidatR, eval = FALSE, include = FALSE}

dur.test <- augment( dur.mod_be ) %>% 
  mutate( NestAge = round( ( NestAge * sd( fullBouts$NestAge, na.rm = TRUE ) ) + mean( fullBouts$NestAge, na.rm = TRUE ), digits = 0 ), 
          TempDiff = ( TempDiff * sd( fullBouts$TempDiff, na.rm = TRUE ) ) + mean( fullBouts$TempDiff, na.rm = TRUE ), 
          WindSpeed = ( WindSpeed * sd( fullBouts$WindSpeed, na.rm = TRUE ) ) + mean( fullBouts$WindSpeed, na.rm = TRUE ), 
          Mins = exp( tMins ), 
          .mu = exp( .fitted ), 
          .std.resid = std.resid.glmer( dur.mod_be ), 
          .hat = hatvalues( dur.mod_be ) ) %>% 
  dplyr::select( -.rownames )
ests <- influence.ME::influence( dur.mod_be, obs = TRUE )
dur.test$.cooksd <- cooks.distance( ests )[ which( !is.na( fullBouts$NestAge ) ) ]

rVf_dur <- ggplot( data = dur.test, 
                   aes( x = .fitted, 
                        y = .resid ) ) + 
  geom_smooth( colour = "seashell4" ) + 
  geom_hline( yintercept = 0, 
              linetype = "dashed" ) + 
  geom_point( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Fitted values", 
        y = "Residuals" ) + 
  theme( text = element_text( size = 12 ) )

y <- quantile( x = dur.test$.std.resid, probs = c( 0.25, 0.75 ) )
x <- qnorm( p = c( 0.25, 0.75 ) )
slope <- diff( y ) / diff( x )
int <- y[ 1L ] - ( slope * x[ 1L ] )

qq_dur <- ggplot( data = dur.test, 
                  aes( sample = .std.resid ) ) + 
  geom_abline( slope = slope, 
               intercept = int, 
               colour = "tomato" ) + 
  stat_qq( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Theoretical quantiles", 
        y = "Standardized residuals" ) + 
  theme( text = element_text( size = 12 ) )

sl_dur <- ggplot( data = dur.test, 
                  aes( x = .fitted, 
                       y = sqrt( abs( .std.resid ) ) ) ) + 
  geom_smooth( colour = "seashell4" ) + 
  geom_hline( yintercept = 1, 
              linetype = "dashed" ) + 
  geom_point( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Fitted values", 
        y = "√|Standardized residuals|" ) + 
  theme( text = element_text( size = 12 ) )

lev_dur <- ggplot( data = dur.test, 
                   aes( x = .hat, 
                        y = .std.resid, 
                        size = .cooksd ) ) + 
  geom_hline( yintercept = 0,
              size = 1,
              colour = "grey" ) +
  geom_vline( xintercept = 0,
              size = 1,
              colour = "grey" ) +
  geom_point() +
  theme_classic() +
  labs( x = "Leverage",
        y = "Standardized residuals",
        size = expression( "Cook's distance" ) ) +
  theme( legend.position = "bottom" )

cowplot::plot_grid( rVf_dur, qq_dur, sl_dur, lev_dur, nrow = 2, labels = "AUTO" )

```

```{r DURcheckR, eval = FALSE, include = FALSE}

rVna <- ggplot( data = dur.test, 
                aes( x = NestAge, 
                     y = .resid ) ) + 
  geom_point( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Nest age (d)", 
        y = "Residuals" )

rVtd <- ggplot( data = dur.test, 
                aes( x = TempDiff, 
                     y = .resid ) ) + 
  geom_point( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Temperature difference (°C)", 
        y = "Residuals" )

rVws <- ggplot( data = dur.test, 
                aes( x = WindSpeed, 
                     y = .resid ) ) + 
  geom_point( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Wind speed (mph)", 
        y = "Residuals" )

dur_fVo <- ggplot( data = dur.test, 
                   aes( x = Mins, 
                        y = .mu ) ) + 
  geom_abline( slope = 1, 
               intercept = 0 ) + 
  geom_point( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Observed off-bout duration (min)", 
        y = "Predicted off-bout duration (min)" )

cowplot::plot_grid( rVna, rVtd, rVws, dur_fVo, nrow = 2, labels = "AUTO" )

```

```{r DURfixefAvgValidatR, eval = FALSE, include = FALSE}

od <- csfullBouts %>% 
  dplyr::select( one_of( c( "tMins", distTerms, envrTerms, timeTerms, "fID" ) ) ) %>% 
  filter( complete.cases( . ) )

dur.avg_test <- AICcmodavg::modavgPred( cand.set = dur.fixef_fits.set, 
                                        newdata = od )

dur.avg_test <- od %>% 
  mutate( .fitted = dur.avg_test$mod.avg.pred, 
          uncond.se = dur.avg_test$uncond.se, 
          hi.95 = dur.avg_test$upper.CL, 
          lo.95 = .fitted - ( hi.95 - .fitted ), 
          TempDiff = ( TempDiff * sd( od$TempDiff, na.rm = TRUE ) ) + mean( od$TempDiff, na.rm = TRUE ), 
          Jday = ( Jday * sd( od$Jday, na.rm = TRUE ) ) + mean( od$Jday, na.rm = TRUE ), 
          NestAge = ( NestAge * sd( od$NestAge, na.rm = TRUE ) ) + mean( od$NestAge, na.rm = TRUE ), 
          Roads_Distance_m = ( Roads_Distance_m * sd( od$Roads_Distance_m, na.rm = TRUE ) ) + mean( od$Roads_Distance_m, na.rm = TRUE ), 
          Trees_Distance_m = ( Trees_Distance_m * sd( od$Trees_Distance_m, na.rm = TRUE ) ) + mean( od$Trees_Distance_m, na.rm = TRUE ), 
          WindSpeed = ( WindSpeed * sd( od$WindSpeed, na.rm = TRUE ) ) + mean( od$WindSpeed, na.rm = TRUE ), 
          Turbine_Distance_m = ( Turbine_Distance_m * sd( od$Turbine_Distance_m, na.rm = TRUE ) ) + mean( od$Turbine_Distance_m, na.rm = TRUE ), 
          Water_Distance_m = ( Water_Distance_m * sd( od$Water_Distance_m, na.rm = TRUE ) ) + mean( od$Water_Distance_m, na.rm = TRUE ), 
          VOR_AVG = ( VOR_AVG * sd( od$VOR_AVG, na.rm = TRUE ) ) + mean( od$VOR_AVG, na.rm = TRUE ), 
          Mins = exp( tMins ), 
          .mu = exp( .fitted ), 
          hi.95_r = exp( hi.95 ), 
          lo.95_r = exp( lo.95 ), 
          .wrk.resid = .fitted - tMins )

rVf_avg <- ggplot( data = dur.avg_test, 
                   aes( x = .fitted, 
                        y = .wrk.resid ) ) + 
  geom_smooth( colour = "seashell4" ) + 
  geom_hline( yintercept = 0, 
              linetype = "dashed" ) + 
  geom_point( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Fitted values", 
        y = "Working residuals" ) + 
  theme( text = element_text( size = 12 ) )

y <- quantile( x = dur.avg_test$.wrk.resid, probs = c( 0.25, 0.75 ) )
x <- qnorm( p = c( 0.25, 0.75 ) )
slope <- diff( y ) / diff( x )
int <- y[ 1L ] - ( slope * x[ 1L ] )

qq_avg <- ggplot( data = dur.avg_test, 
                  aes( sample = .wrk.resid ) ) + 
  geom_abline( slope = slope, 
               intercept = int, 
               colour = "tomato" ) + 
  stat_qq( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Theoretical quantiles", 
        y = "Working residuals" ) + 
  theme( text = element_text( size = 12 ) )

sl_avg <- ggplot( data = dur.avg_test, 
                  aes( x = .fitted, 
                       y = sqrt( abs( .wrk.resid ) ) ) ) + 
  geom_smooth( colour = "seashell4" ) + 
  geom_point( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Fitted values", 
        y = "√|Working residuals|" ) + 
  theme( text = element_text( size = 12 ) )

```

```{r FREQvalidatR}

freq.test_aicc <- augment( freq.mod_aicc ) %>% 
  mutate( NestAge = ( NestAge * sd( freqData$NestAge, na.rm = TRUE ) ) + mean( freqData$NestAge, na.rm = TRUE ), 
          Jday = ( Jday * sd( freqData$Jday, na.rm = TRUE ) ) + mean( freqData$Jday, na.rm = TRUE ), 
          .std.resid = std.resid.glmer( freq.mod_aicc ), 
          .qresid = qres2( freq.mod_aicc ), 
          .hat = hatvalues( freq.mod_aicc ) ) %>% 
  dplyr::select( -.rownames )
# ests <- influence.ME::influence( freq.mod_aicc, obs = TRUE )
# freq.test_aicc$.cooksd <- cooks.distance( ests )[ which( !is.na( freqData$WindSpeed ) & !is.na( freqData$NestAge ) ) ]

rVf_freq.aicc <- ggplot( data = freq.test_aicc, 
                         aes( x = .fitted, 
                              y = .qresid ) ) + 
  geom_smooth( colour = "seashell4" ) + 
  geom_hline( yintercept = 0, 
              linetype = "dashed" ) + 
  geom_point( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Fitted values", 
        y = "Randomized quantile residuals" ) + 
  theme( text = element_text( size = 12 ) )

y <- quantile( x = freq.test_aicc$.qresid, probs = c( 0.25, 0.75 ) )
x <- qnorm( p = c( 0.25, 0.75 ) )
slope <- diff( y ) / diff( x )
int <- y[ 1L ] - ( slope * x[ 1L ] )

qq_freq.aicc <- ggplot( data = freq.test_aicc, 
                        aes( sample = .qresid ) ) + 
  geom_abline( slope = slope, 
               intercept = int, 
               colour = "tomato" ) + 
  stat_qq( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Theoretical quantiles", 
        y = "Randomized quantile r residuals" ) + 
  theme( text = element_text( size = 12 ) )

sl_freq.aicc <- ggplot( data = freq.test_aicc, 
                        aes( x = .fitted, 
                             y = sqrt( abs( .qresid ) ) ) ) + 
  geom_smooth( colour = "seashell4" ) + 
  geom_hline( yintercept = 1, 
              linetype = "dashed" ) + 
  geom_point( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Fitted values", 
        y = "√|Randomized quantile residuals|" ) + 
  theme( text = element_text( size = 12 ) )

lev_freq.aicc <- ggplot( data = freq.test_aicc, 
                         aes( x = .hat, 
                              y = .qresid ) ) + 
  geom_hline( yintercept = 0,
              size = 1,
              colour = "grey" ) +
  geom_vline( xintercept = 0,
              size = 1,
              colour = "grey" ) +
  geom_point( alpha = 0.4 ) +
  theme_classic() +
  labs( x = "Leverage",
        y = "Randomized quantile residuals" )

cowplot::plot_grid( rVf_freq.aicc, qq_freq.aicc, sl_freq.aicc, lev_freq.aicc, nrow = 2, labels = "AUTO" )

```

```{r FREQcheckR}

rVna_freq.aicc <- ggplot( data = freq.test_aicc, 
                          aes( x = NestAge, 
                               y = .qresid ) ) + 
  geom_hline( yintercept = 0, 
              linetype = "dashed" ) + 
  geom_point( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Nest age (d)", 
        y = "Randomized quantile residuals" )

rVbk_freq.aicc <- ggplot( data = freq.test_aicc, 
                          aes( x = blockID, 
                               y = .qresid ) ) + 
  geom_boxplot( fill = "grey24", 
                outlier.alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Time block", 
        y = "Randomized quantile residuals" )

rVjd_freq.aicc <- ggplot( data = freq.test_aicc, 
                          aes( x = Jday, 
                               y = .qresid ) ) + 
  geom_hline( yintercept = 0, 
              linetype = "dashed" ) + 
  geom_point( alpha = 0.4 ) + 
  theme_classic() + 
  labs( x = "Ordinal date", 
        y = "Randomized quantile residuals" )

fVo_freq.aicc <- ggplot( data = freq.test_aicc, 
                         aes( x = as.factor( numBouts ), 
                              y = .mu ) ) + 
  geom_boxplot( outlier.alpha = 0.4, 
                fill = "grey24" ) + 
  theme_classic() + 
  labs( x = "Observed off-bout occurrence", 
        y = "Predicted probability of off-bout occurrence" )

cowplot::plot_grid( rVna_freq.aicc, rVbk_freq.aicc, rVjd_freq.aicc, fVo_freq.aicc, nrow = 2, labels = "AUTO" )

```

####**Variables**

```{r vaRiables, eval = FALSE, include = FALSE}

vaRs <- data.frame( Variable = c( "Year", 
                                  "Nest age", 
                                  "Ambient temperature", 
                                  "Temperature difference", 
                                  "Precipitation", 
                                  "VOR", 
                                  "Wind speed", 
                                  "Distance to nearest turbine", 
                                  "Distance to nearest road", 
                                  "Distance to nearest water source", 
                                  "Ordinal date", 
                                  "Time block" ), 
                    Explanation = c( "Categorical; year during which observations for the nest occurred (2013, 2014)", 
                                     "Interval; days after initiation of incubation (0--28)", 
                                     "Interval; °C temperature recorded at the Ainsworth Regional Airport", 
                                     "Interval; °C difference between the ambient temperature and the temperature recorded on the nest just prior to the start of the off-bout", 
                                     "Interval; inches of precipitation falling during the 20-minute period encompassing the start of the off-bout", 
                                     "Interval; ", 
                                     "Interval", 
                                     "Interval; straight-line distance in meters between the nest and the nearest wind turbine", 
                                     "Interval; straight-line distance in meters between the nest and the nearest road", 
                                     "Interval; straight-line distance in meters between the nest and the nearest water source", 
                                     "Interval; number day of the year", 
                                     "Categorical; time block during which the observation occurred (01:30--04:30, 04:30--07:30, 07:30--10:30...)" ), 
                    Duration = c( "X", "X", "", "X", "", "X", "X", "X", "X", "X", "X", "" ), 
                    Frequency = c( "X", "X", "X", "", "X", "X", "X", "X", "X", "X", "X", "X" ) )

```

###**CODE** {#code}

```{r ref.label = knitr::all_labels(), echo = TRUE, eval = FALSE}
```

###**LITERATURE CITED** {#literaturecited}